{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMgCs3/u6bLzTTxFfYxyPbD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["###**Traduction automatique en Python**\n","+ *4 heures*\n","+ *16 vidéos*\n","+ *58 exercices*\n","+ *3 284 participants*\n","+ *4 950 XP*\n","\n","####**Description du cours**\n","\n","+ ***La nécessité d'emporter un dictionnaire bilingue pour vos vacances en Europe ou d'en garder un sur votre bureau pour faire vos devoirs de langue étrangère appartient au passé***. \n","\n","+ ***Il suffit de se connecter à Internet et d'utiliser un service de traduction pour comprendre rapidement la signification d'un panneau de signalisation ou pour savoir comment saluer et remercier un étranger dans sa langue***. \n","\n","+ *Derrière les services de traduction linguistique se cachent des modèles complexes de traduction automatique. Vous êtes-vous déjà demandé comment ces modèles fonctionnent ?* \n","\n","+ *Ce cours vous permettra d'explorer les rouages d'un modèle de traduction automatique.* \n","\n","+ *Vous utiliserez Keras, une puissante bibliothèque d'apprentissage profond basée sur Python, pour mettre en œuvre un modèle de traduction.* \n","\n","+ *Vous entraînerez ensuite le modèle à effectuer une traduction de l'anglais vers le français, et des techniques vous seront présentées pour améliorer votre modèle.* \n","\n","+ *À la fin de ce cours, vous aurez acquis une compréhension approfondie des modèles de traduction automatique et vous les apprécierez encore davantage !*\n","\n","####**1) Introduction à la traduction automatique**\n","\n","+ ***Dans ce chapitre, vous comprendrez ce qu'est l'architecture codeur-décodeur et comment elle est utilisée pour la traduction automatique. Vous découvrirez également les GRU (Gated Recurrent Units) et leur utilisation dans l'architecture encodeur-décodeur.***\n","\n","|OBJECTIFS|\n","|---------|\n","Introduction à la traduction automatique\n","Comprendre les vecteurs à un coup\n","Partie 1 : Exploration de la fonction to_categorical()\n","Partie 2 : Exploration de la fonction to_categorical()\n","Architecture de l'encodeur-décodeur\n","Partie 1 : Modèle d'inversion de texte - Encodeur\n","Partie 2 : Modèle d'inversion de texte - Encodeur\n","Modèle complet d'inversion de texte\n","Comprendre les modèles séquentiels\n","Partie 1 : Comprendre les modèles GRU\n","Partie 2 : Comprendre les modèles GRU\n","Comprendre les résultats des modèles séquentiels\n","\n","####**2) Implémentation d'un modèle encodeur-décodeur avec Keras**\n","\n","+ ***Dans ce chapitre, vous allez implémenter le modèle encodeur-décodeur avec l'API fonctionnelle de Keras. Ce faisant, vous apprendrez plusieurs couches Keras utiles, telles que les couches RepeatVector et TimeDistributed.***\n","\n","|OBJECTIFS|\n","|---------|\n","Mise en œuvre de l'encodeur\n","Partie 1 : exploration de l'ensemble de données\n","Partie 2 : exploration de l'ensemble de données\n","Définition de l'encodeur\n","Implémentation du décodeur\n","Comprendre la couche RepeatVector\n","La forme de la sortie d'une couche RepeatVector\n","Définition du décodeur\n","Couches denses et réparties dans le temps\n","Partie 1 : participez pour gagner des prix incroyables\n","Partie 2 : Jouons à d'autres jeux\n","Implémentation du modèle codeur-décodeur complet\n","Partie 1 : Définir le modèle complet\n","Partie 2 : Définir le modèle complet\n","\n","\n","####**3) Entraînement et génération de traductions**\n","\n","+ ***Dans ce chapitre, vous allez entraîner le modèle défini précédemment, puis utiliser un modèle bien entraîné pour générer des traductions. Vous verrez que notre modèle fait du bon travail lors de la traduction de phrases.***\n","\n","|OBJECTIFS|\n","|---------|\n","|Partie 1 : Prétraitement des données\n","Tokenisation des phrases avec Keras\n","Contrôle du vocabulaire avec le tokeniseur\n","Partie 2 : Prétraitement des données\n","Ajout de tokens spéciaux\n","Remplissage des phrases\n","Inversion de phrases\n","Entraînement du modèle NMT\n","Entraînement du modèle\n","Division des données en ensembles de formation et de validation\n","Entraînement du modèle avec validation\n","Génération de traductions avec le modèle NMT\n","Partie 1 : Chasse au trésor\n","Partie 2 : Chasse au trésor\n","Génération de traductions anglais-français\n","\n","####**4) Forçage de l'enseignant (Teacher Forcing) et intégration des mots**\n","\n","+ ***Dans ce chapitre, vous allez découvrir une technique connue sous le nom de Teacher Forcing, qui permet d'entraîner les modèles de traduction mieux et plus rapidement. Vous apprendrez ensuite comment utiliser les intégrations de mots pour améliorer encore le modèle.***\n","\n","|OBJECTIFS|\n","|---------|\n","Introduction au Forçage de l'enseignant(Teacher Forcing) \n","Définition des couches du modèle Teacher Forcing\n","Définition du modèle Teacher Forcing\n","Prétraitement des données\n","Entraînement du modèle avec Teacher Forcing\n","Entraînement du modèle\n","Séparation des données de formation et de validation\n","Formation du modèle avec validation\n","Générer des traductions à partir du modèle\n","Définition du décodeur du modèle d'inférence\n","Lien entre le modèle d'apprentissage et le modèle d'inférence\n","Génération de traductions\n","Utilisation de l'intégration de mots pour la traduction automatique\n","Mesure de la similarité des vecteurs de mots\n","Définition du modèle d'incorporation\n","Formation du modèle basé sur l'incorporation de mots\n","Récapitulation et épreuve finale\n","\n"],"metadata":{"id":"yaOW3RVSrvCi"}},{"cell_type":"markdown","source":["###**Introduction à la traduction automatique**\n","\n","####**1. Introduction à la traduction automatique**\n","\n","+ *Bonjour! Hallo!, Je suis Thushan Ganegedara et dans ce cours, vous apprendrez à mettre en œuvre des modèles de traduction automatique en utilisant la populaire bibliothèque d’apprentissage profond **Keras**.*\n","\n","####**2. Traduction automatique**\n","+ La capacité de communiquer dans des langues étrangères nous aide dans de nombreux cas, par exemple lorsque nous voyageons à l’étranger.\n","\n","####**3. Traduction automatique**\n","\n","+ Les services de traduction automatique tels que le service de traduction Google peuvent vous aider à comprendre des centaines de langues en appuyant simplement sur un bouton. \n","\n","+ Dans ce cours, vous apprendrez le fonctionnement interne des modèles qui renforcent ces services.\n","\n","####**4. Plan du cours**\n","\n","+ *Dans le chapitre 1, vous découvrirez la traduction automatique et l’architecture codeur-décodeur, qui est une architecture d’apprentissage profond courante utilisée pour les modèles de traduction automatique.* \n","\n","+ *Ensuite, dans le chapitre 2, vous allez implémenter un modèle d’encodeur-décodeur à l’aide de l’API fonctionnelle Keras.*\n","\n","+ *Dans le chapitre 3, vous apprendrez à former un modèle et à générer des traductions à l’aide du modèle formé.* \n","\n","+ *Enfin, vous apprendrez et mettrez en œuvre plusieurs techniques qui améliorent les performances des modèles de traduction automatique tels que le Teacher Forcing.*\n","\n","####**5. Dataset (corpus de phrases Français anglais)**\n","\n","+ Le jeu de données que vous utiliserez dans ce cours se compose de deux fichiers texte. Un fichier contient un ensemble de phrases en anglais, où chaque ligne du fichier contient une seule phrase. \n","\n","+ Et l’autre fichier contient les traductions Français correspondantes des phrases anglaises.\n","\n","  + https://github.com/udacity/deep-learning/tree/master/language-translation/data\n","\n","\n","####**6. Traduction automatique - Vue d’ensemble**\n","\n","+ Ici, vous pouvez voir un exemple de tâche de traduction automatique. \n","\n","+ Nous voulons traduire la phrase anglaise « I like cats » en Français.\n","\n","####**7. Traduction automatique - Vue d’ensemble**\n","+ \n","Dans la terminologie de la traduction automatique, la langue anglaise, la langue de la phrase à traduire, est appelée la langue source. \n","\n","+ La langue Français, la langue de la phrase traduite, est appelée la langue cible.\n","\n","####**8. Traduction automatique - Vue d’ensemble**\n","\n","+ Voyons maintenant comment un modèle de traduction automatique peut être utilisé pour traduire une phrase. \n","\n","+ Tout d’abord, les mots de la phrase source sont introduits dans le modèle un par un, séquentiellement.\n","\n","####**9. Traduction automatique - Vue d’ensemble**\n","\n","+ Ensuite, le modèle produit la traduction prédite mot par mot de manière séquentielle.\n","\n","####**10. Vecteurs codés à chaud**\n","\n","+ ***Lors de l’alimentation de mots vers un modèle de traduction automatique, les mots doivent être convertis en une représentation numérique.***\n","\n","+ ***Un encodage à chaud est l’une des transformations couramment utilisées. Dans un codage à chaud, un mot est représenté comme un vecteur de zéros et de uns.*** \n","\n","+ Par exemple dans la phrase « J’aime les chats », le mot « je » peut être représenté avec un vecteur de longueur cinq et le premier élément étant un. \n","\n","+ ***La longueur du vecteur est déterminée par la taille du vocabulaire.***\n","\n","+ ***Le vocabulaire est la collection de mots uniques utilisés dans l’ensemble de données pour une langue spécifique.***\n","\n","####**11. Vecteurs codés à chaud**\n","\n","+ ***Dans Keras, vous pouvez utiliser la fonction to_categorical pratique pour convertir des mots en vecteurs codés onehot.*** \n","\n","+ Cependant, pour utiliser cette fonction, vous devez d’abord convertir des mots individuels en entiers ou en ID. \n","\n","+ Pour ce faire, vous définissez un dictionnaire Python qui mappe les mots aux entiers. Ensuite, vous créez une liste appelée word_ids qui mappe itérativement chaque mot à un ID.\n","\n","####**12. Vecteurs codés à chaud**\n","\n","\n","+ ***En transmettant ces ID de mots à la fonction to_categorical, vous pouvez obtenir les vecteurs à une seule pression.*** \n","\n","+ Si vous ne transmettez pas le nombre de classes ou la longueur du vecteur, Keras le détectera automatiquement à partir des données que vous transmettez. \n","\n","+ Mais vous pouvez fixer la longueur du vecteur en passant l’argument num_classes à la fonction. \n","\n","+ C’est généralement une bonne pratique de fixer la longueur. \n","\n","+ Dans les situations où vos données d’entraînement et de test ont des mots différents, laisser la longueur non fixée peut entraîner des erreurs et des comportements inattendus.\n","\n","####**13. Entraînons-nous!**\n","+ Génial! Maintenant, amusons-nous avec des vecteurs à une seule chaleur."],"metadata":{"id":"9ZRdNpmWt_Fn"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Comprendre les vecteurs à un coup**\n","\n","+ *Vous apprendrez ici à générer des vecteurs codés à un coup à partir de mots. L'encodage one-hot est une transformation courante appliquée aux mots pour les représenter numériquement.*\n","\n","+ ***Vous utiliserez la fonction Keras to_categorical() pour créer des vecteurs à un coup.*** \n","\n","+ ***La fonction to_categorical() attend une séquence d'entiers en entrée. Par conséquent, un dictionnaire word2index est fourni et peut être utilisé pour convertir un mot en un nombre entier.***\n","\n","+ Pour réussir cet exercice, vous devrez également utiliser **la fonction intégrée Python zip()**. \n","\n","+ **La fonction zip() vous permet d'itérer plusieurs choses à la fois**. \n","\n","+ *Par exemple, si vous avez deux listes xx et yy de même longueur, en appelant x,y dans zip(xx,yy) vous pouvez accéder à chaque élément x et y des listes de manière itérative.*\n","\n","####**Instructions** \n","\n","+ Créez une liste de mots I, like, cats et convertissez chaque mot en un nombre entier en utilisant word2index. Imprimez les entiers résultants.\n","\n","+ Convertissez les mots en vecteurs à un coup en utilisant la fonction Keras to_categorical().\n","\n","\n","+ Imprimez les mots et leurs vecteurs à un coup correspondants à l'aide de la fonction zip().\n","\n","\n","+ Convertir les mots en vecteurs à un coup en utilisant le nombre de classes comme 5, l'assigner à la variable onehot_2 et imprimer le résultat."],"metadata":{"id":"sy3i-SMI1evZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7DPKwsZrsV9"},"outputs":[],"source":["word2index = {'I': 0, 'cats': 2, 'like': 1}"]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","# Create a list of words and convert them to indices\n","words = [\"I\", \"like\", \"cats\"]\n","word_ids = [word2index[w] for w in words]\n","print(word_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kRi-q8i72H61","executionInfo":{"status":"ok","timestamp":1672434555529,"user_tz":-60,"elapsed":235,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"9d367f03-8818-4a38-9530-cacd4c87de7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 1, 2]\n"]}]},{"cell_type":"code","source":["# Create onehot vectors using to_categorical function\n","onehot_1 = to_categorical(word_ids)\n","# Print words and their corresponding onehot vectors\n","print([(w,ohe.tolist()) for w,ohe in zip(words, onehot_1)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8X3ZovbF2I2P","executionInfo":{"status":"ok","timestamp":1672434557622,"user_tz":-60,"elapsed":204,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"a86bbd80-b3f5-4cd6-d72a-1c4934604727"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('I', [1.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0]), ('cats', [0.0, 0.0, 1.0])]\n"]}]},{"cell_type":"code","source":["# Create onehot vectors with a fixed number of classes\n","onehot_2 = to_categorical(word_ids, num_classes=5)\n","print([(w,ohe.tolist()) for w,ohe in zip(words, onehot_2)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBcTtkbp2I-N","executionInfo":{"status":"ok","timestamp":1672434560104,"user_tz":-60,"elapsed":231,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"8cdd1285-362d-4442-95de-2f2e7a44ba5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('I', [1.0, 0.0, 0.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0, 0.0, 0.0]), ('cats', [0.0, 0.0, 1.0, 0.0, 0.0])]\n"]}]},{"cell_type":"markdown","source":["####**Partie 1 : Exploration de la fonction to_categorical()**\n","\n","\n","+ *Saviez-vous que dans les problèmes du monde réel, la taille du vocabulaire peut devenir très importante (par exemple, plus de cent mille) ?*\n","\n","+ ***Cet exercice est divisé en deux parties et vous apprendrez l'importance de définir l'argument num_classes de la fonction to_categorical().*** \n","\n","+ ***Dans la première partie, vous implémenterez la fonction compute_onehot_length() qui génère des vecteurs one-hot pour une liste de mots donnée et calcule la longueur de ces vecteurs.***\n","\n","+ *La fonction to_categorical() a déjà été importée.*\n","\n","####**Instructions**\n","\n","+ Créez les IDs des mots en utilisant words et word2index dans compute_onehot_length().\n","\n","\n","+ Créer des vecteurs onehot en utilisant la fonction to_categorical() en utilisant les IDs des mots.\n","\n","+ Retourner la longueur d'un seul vecteur onehot en utilisant la syntaxe <array>.shape.\n","\n","+ Calculer et imprimer la longueur des vecteurs onehot en utilisant la fonction compute_onehot_length() pour la liste de mots He, drank, milk."],"metadata":{"id":"BbCCabE_2vOS"}},{"cell_type":"code","source":["def compute_onehot_length(words, word2index):\n","  # Create word IDs for words\n","  word_ids = [word2index[w] for w in words]\n","  # Convert word IDs to onehot vectors\n","  onehot = to_categorical(word_ids)\n","  # Return the length of a single one-hot vector\n","  return onehot.shape[1]"],"metadata":{"id":"-SZDweK-3C9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word2index = {\"He\":0, \"drank\": 1, \"milk\": 2}\n","# Compute and print onehot length of a list of words\n","print(compute_onehot_length([\"He\", \"drank\", \"milk\"], word2index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g1nba8b63DAp","executionInfo":{"status":"ok","timestamp":1672434566783,"user_tz":-60,"elapsed":203,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"828ed849-6db4-472e-a80d-1d295cd4b2d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n"]}]},{"cell_type":"markdown","source":["####**Partie 2 : Exploration de la fonction to_categorical()**\n","\n","+ ***Dans la partie 1, vous avez implémenté la fonction compute_onehot_length() qui n'utilisait pas l'argument num_classes lors du calcul des vecteurs onehot.***\n","\n","+ L'argument **num_classes** contrôle la longueur des vecteurs codés à un coup produits par **la fonction to_categorical()**. \n","\n","+ Vous verrez que dans les situations où vous avez deux corpus différents (c'est-à-dire des collections de textes) avec des vocabulaires différents, laisser l'argument num_classes non défini peut donner des vecteurs one-hot de longueur variable.\n","\n","+ *Pour cet exercice, la fonction compute_onehot_length() et le dictionnaire word2index ont été fournis.*\n","\n","####**Instructions**\n","\n","+ Appelez compute_onehot_length() sur les words_1.\n","\n","+ Appelez compute_onehot_length() sur les words_2.\n","\n","+ Imprimez les longueurs des vecteurs one-hot obtenus pour les words_1 et les words_2."],"metadata":{"id":"hdCEhhQS4pil"}},{"cell_type":"code","source":["word2index = {'He': 6, 'I': 0, 'We': 3, 'cats': 2, 'dogs': 5, 'hates': 7, 'like': 4,'rabbits': 8}"],"metadata":{"id":"_iFmUYpe58pG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words_1 = [\"I\", \"like\", \"cats\", \"We\", \"like\", \"dogs\", \"He\", \"hates\", \"rabbits\"]\n","\n","# Call compute_onehot_length on words_1\n","length_1 = compute_onehot_length(words_1, word2index)\n","\n","words_2 = [\"I\", \"like\", \"cats\", \"We\", \"like\", \"dogs\", \"We\", \"like\", \"cats\"]\n","# Call compute_onehot_length on words_2\n","length_2 = compute_onehot_length(words_2, word2index)\n","\n","# Print length_1 and length_2\n","print(\"length_1 =>\", length_1, \" and length_2 => \", length_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vI2YOC743DDs","executionInfo":{"status":"ok","timestamp":1672434573504,"user_tz":-60,"elapsed":346,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"6c35833e-0216-4893-c5db-f7d806971515"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["length_1 => 9  and length_2 =>  6\n"]}]},{"cell_type":"markdown","source":["###**Architecture du décodeur d’encodeur**\n","\n","####**1. Architecture du décodeur d’encodeur**\n","\n","+ Vous allez maintenant en apprendre davantage sur l’architecture du décodeur d’encodeur.\n","\n","####**2. Modèle de décodeur d’encodeur**\n","\n","+ *Un modèle de traduction automatique fonctionne d’abord en consommant les mots de la langue source de manière séquentielle, puis en prédisant séquentiellement les mots correspondants dans la langue cible.*\n","\n","####**3. Encodeur**\n","\n","+ Cependant, sous le capot, il s’agit en fait de deux modèles différents; un codeur et un décodeur. \n","\n","+ Regardons d’abord l’encodeur. \n","\n","+ Dans notre exemple, l’encodeur prend en entrée des vecteurs à une chaleur de mots anglais et produit une représentation compressée des entrées connue sous le nom de vecteur de contexte.\n","\n","####**4. Encodeur et décodeur**\n","\n","+ Ensuite, le décodeur consomme le vecteur de contexte en entrée et produit des prédictions probabilistes pour chaque pas de temps. \n","\n","+ Le mot pour un pas de temps donné est sélectionné comme le mot avec la probabilité la plus élevée. \n","\n","+ Notez que, bien que les entrées du codeur soient des uns et des zéros, le décodeur produit des sorties probabilistes continues. \n","\n","+ ***Ces modèles sont également appelés modèles de séquence à séquence parce qu’ils mappent une séquence, c’est-à-dire une phrase anglaise à une autre séquence, c’est-à-dire une phrase Français***.\n","\n","####**5. Analogie : architecture du décodeur de l’encodeur**\n","\n","+ Comprenons cela à travers une analogie. \n","\n","+ Un enseignant explique ce qu’est un éléphant et vous n’en avez jamais vu. \n","\n","+ L’enseignant l’explique comme « il est grand, a de grandes oreilles et un tronc ». \n","\n","+ Ensuite, vous créez une image mentale d’un éléphant. Ce serait le processus d’encodage. Puis votre ami demande « à quoi ressemble un éléphant ? ». \n","\n","+ Ensuite, vous décodez cette image mentale de l’éléphant en expliquant les caractéristiques d’un éléphant ou peut-être en en dessinant un. C’est le processus de décodage.\n","\n","####**6. Phrases inversées - modèle de décodeur d’encodeur**\n","\n","+ Pour mieux comprendre l’architecture du décodeur d’encodeur, implémentons un modèle simple qui inverse une phrase. \n","\n","+ Tout d’abord, l’encodeur reçoit une représentation à chaud de la phrase et la convertit en ID de mots. \n","\n","+ Ensuite, le décodeur prend les ID de mots, les inverse et convertit les ID inversés en représentation à une seule heure, ce qui donne la phrase inversée.\n","\n","####**7. Écriture de l’encodeur**\n","\n","+ Afin d’implémenter l’encodeur, vous allez d’abord implémenter **une fonction appelée words2onehot** qui convertira une liste donnée de mots **en vecteurs one-hot**. \n","\n","+ Le vecteur uni-chaud résultant aura la forme nombre de mots par num_classes. \n","+ num_classes est trois dans notre exemple. \n","\n","+ La fonction encodeur est une fonction simple, qui prend un tableau de vecteurs à une seule pression comme argument et renvoie les ID de mots correspondant aux vecteurs à une seule chaleur. \n","\n","+ Pour obtenir les ID de mots à partir des vecteurs one-hot, vous pouvez utiliser **la fonction np dot argmax**. \n","\n","+ **np.argmax** calcule l’indice de l’élément maximum le long d’un axe donné. \n","\n","+ Étant donné que les vecteurs à une pression sont disposés le long de l’axe 1, vous pouvez utiliser l’axe égal à 1.\n","\n","####**8. Écriture de l’encodeur**\n","+ Après avoir défini les deux fonctions, vous pouvez encoder une phrase donnée. \n","\n","+ Pour ce faire, appelez d’abord **la fonction words2onehot** avec une liste de chaînes comme premier argument et **word2index** comme deuxième argument pour obtenir les vecteurs **one-hot**. \n","\n","+ Appelez ensuite la fonction encodeur avec les vecteurs one-hot comme argument pour obtenir le vecteur de contexte. \n","\n","+ Enfin, imprimez le vecteur de contexte. \n","\n","+ Le contexte contient les ID de mots correspondants des mots.\n","\n","####**9. Écriture du décodeur**\n","\n","+ Le décodeur prendra les ID de mots, inversera les ID, puis retournera les vecteurs à une chaleur des mots inversés. \n","\n","+ Ensuite, vous écrivez le décodeur comme une fonction qui prend le vecteur de contexte produit par l’encodeur et produit des vecteurs à chaud unique des mots inversés. \n","\n","+ La fonction décodeur inverse d’abord les mots ID dans le vecteur de contexte. \n","\n","+ Dans numpy, un tableau 1D peut être inversé en ajoutant deux-points moins 1 entre crochets. \n","\n","+ Après avoir inversé les mots ID, les vecteurs à un chaud sont obtenus en appelant **la fonction to_categorical.** \n","\n","+ Vous avez également besoin d’une fonction d’assistance **onehot2words** qui convertira un ensemble de vecteurs one-hot en mots lisibles par l’homme. \n","\n","+ Pour ce faire, **la fonction onehot2words** prend en charge un tableau de vecteurs **one-hot et un dictionnaire, index2word, qui mappe un ID de mot à un mot**. \n","\n","+ Par conséquent, index2word est le dictionnaire inversé de word2index utilisé dans l’encodeur.\n","\n","####**10. Écriture du décodeur**\n","+ Enfin, vous pouvez calculer la sortie du décodeur en appelant la fonction décodeur avec le vecteur de contexte comme argument. \n","\n","+ Et obtenez les mots inversés en appelant la fonction onehot2words avec les arguments corrects.\n","\n","####**11. Entraînons-nous!**\n","+ Mettons maintenant en œuvre le modèle d’inversion de phrase.\n"],"metadata":{"id":"1RUS5lT-6Q5O"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Partie 1 : Modèle d'inversion de texte - Encodeur**\n","\n","+ La création d'un modèle simple d'inversion de texte est une excellente méthode pour comprendre les mécanismes des modèles encodeur-décodeur et la façon dont ils sont connectés. \n","\n","+ Vous allez maintenant implémenter la partie encodeur d'un modèle d'inversion de texte.\n","\n","+ ***L'implémentation de l'encodeur a été répartie sur deux exercices. Dans cet exercice, vous allez définir la fonction auxiliaire words2onehot(). La fonction words2onehot() doit prendre une liste de mots et un dictionnaire word2index et convertir la liste de mots en un tableau de vecteurs one-hot. Le dictionnaire word2index est disponible dans l'espace de travail.***\n","\n","![image.png](data:image/png;base64,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)\n","\n","####**Instructions**\n","\n","+ Convertir les mots en IDs en utilisant le dictionnaire word2index dans **la fonction words2onehot()**\n","\n","+ Convertir les IDs des mots en vecteurs onehot de longueur 3 (en utilisant l'argument num_classes) et retourner le tableau résultant.\n","\n","+ Appelez **la fonction words2onehot()** avec les mots I, like et cats et assignez le résultat à onehot.\n","\n","+ Imprimez les mots et leurs vecteurs onehot correspondants en utilisant les fonctions **print() et zip()**. \n","\n","+ **La fonction zip()** vous permet d'itérer plusieurs listes en même temps."],"metadata":{"id":"uMeOrS7xYWFz"}},{"cell_type":"code","source":["word2index = {'I': 0, 'cats': 2, 'like': 1}"],"metadata":{"id":"92Jg0S_idI6O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def words2onehot(word_list, word2index):\n","  # Convert words to word IDs\n","  word_ids = [word2index[w] for w in word_list]\n","  # Convert word IDs to onehot vectors and return the onehot array\n","  onehot = to_categorical(word_ids, num_classes=3)\n","  return onehot"],"metadata":{"id":"sOsgaQv75BeH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words = [\"I\", \"like\", \"cats\"]\n","# Convert words to onehot vectors using words2onehot\n","onehot = words2onehot(words, word2index)\n","# Print the result as (<word>, <onehot>) tuples\n","print([(w,ohe.tolist()) for w,ohe in zip(words, onehot)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1ijTfB05Bhu","executionInfo":{"status":"ok","timestamp":1672434588111,"user_tz":-60,"elapsed":238,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"072a56ad-7b00-4814-ff31-a804f4593c06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('I', [1.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0]), ('cats', [0.0, 0.0, 1.0])]\n"]}]},{"cell_type":"markdown","source":["####**Partie 2 : Modèle d'inversion de texte - Encodeur**\n","\n","\n","+ ***Vous allez maintenant implémenter le reste de l'encodeur du modèle d'inversion de texte.*** \n","\n","+ ***L'encodeur se nourrit des vecteurs one-hot produits par la fonction words2onehot() que vous avez implémentée précédemment.***\n","\n","+ Ici, vous allez implémenter ***la fonction encoder()***. \n","\n","+ ***La fonction encoder() prend un ensemble de vecteurs one-hot et les convertit en une liste d'identifiants de mots.***\n","\n","+ *Pour cet exercice, la fonction words2onehot() et le dictionnaire word2index (contenant les mots We, like et dogs) ont été fournis.*\n","\n","![image.png](data:image/png;base64,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)\n","\n","\n","####**Instructions**\n","\n","+ Convertir onehot en un tableau d'identifiants de mots en utilisant **la fonction np.argmax()** et retourner les identifiants de mots.\n","\n","+ Définissez une liste de mots avec les mots ***We, like, dogs.***\n","\n","+ Convertissez la liste de mots en vecteurs onehot en utilisant ***la fonction words2onehot()***. \n","\n","+ Rappelez-vous que **words2onehot()** prend une liste de mots et un dictionnaire Python comme arguments.\n","\n","+ Obtenez le vecteur de contexte des vecteurs onehot en utilisant ***la fonction encoder()***.\n"],"metadata":{"id":"34LBdoJ8doIE"}},{"cell_type":"code","source":["word2index = {'We': 0, 'dogs': 2, 'like': 1}"],"metadata":{"id":"dU6RKgMiuqus"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encoder(onehot):\n","  # Get word IDs from onehot vectors and return the IDs\n","  word_ids = np.argmax(onehot, axis=1)\n","  return word_ids"],"metadata":{"id":"8IOLi1b43DGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define \"we like dogs\" as words\n","words = [\"We\", \"like\", \"dogs\"]\n","# Convert words to onehot vectors using words2onehot\n","onehot = words2onehot(words, word2index)\n","# Get the context vector by using the encoder function\n","context = encoder(onehot)\n","print(context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BA4sFhLkuhnL","executionInfo":{"status":"ok","timestamp":1672434597943,"user_tz":-60,"elapsed":208,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"35f59aad-bbd5-4991-cceb-f5b0d3ddbcb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2]\n"]}]},{"cell_type":"markdown","source":["####**Modèle complet d'inversion de texte**\n","\n","+ Vous allez maintenant implémenter la partie décodeur du modèle d'inversion de texte, qui convertira le vecteur de contexte de l'encodeur en mots inversés.\n","\n","+ Vous allez définir deux fonctions **onehot2words() et decoder()**. \n","\n","+ ***La fonction onehot2words() prend une liste d'ids et un dictionnaire index2word et convertit un tableau de vecteurs one-hot en une liste de mots.*** \n","\n","+ ***La fonction decoder() prend le vecteur de contexte (c'est-à-dire la liste des mots) et le convertit en une liste de mots inversée.***\n","\n","+ *Pour cet exercice, le dictionnaire index2word, le vecteur contextuel context, la fonction encoder() et les fonctions words2onehot() seront fournis.*\n","\n","####**Instructions** \n","\n","+ Définir la fonction onehot2words(), qui obtient les IDs des mots à partir des vecteurs one-hot et ensuite convertit les IDs en mots.\n","\n","+ Définir la fonction decoder() qui inverse les ID des mots dans le vecteur de contexte et convertit les ID des mots inversés en vecteurs à un coup.\n","\n","+ Obtenir les vecteurs à un coup des mots ID inversés en utilisant la fonction decoder().\n","\n","+ Obtenir les mots inversés à partir des vecteurs one-hot en utilisant la fonction onehot2words().\n","\n","+ Obtenez les vecteurs à un coup des ID des mots inversés à l'aide de la fonction decoder().\n","\n","+ Obtenir les mots inversés à partir des vecteurs one-hot en utilisant la fonction onehot2words()."],"metadata":{"id":"RlwNdt1tyrUx"}},{"cell_type":"code","source":["# Define the onehot2words function that returns words for a set of onehot vectors\n","def onehot2words(onehot, index2word):\n","  ids = np.argmax(onehot, axis=1)\n","  res = [index2word[id] for id in ids]\n","  return res"],"metadata":{"id":"JzZvWtVQy50b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the decoder function that returns reversed onehot vectors\n","def decoder(context_vector):\n","  word_ids_rev = context_vector[::-1]\n","  onehot_rev = to_categorical(word_ids_rev, num_classes=3)\n","  return onehot_rev"],"metadata":{"id":"8-oWbnXmy57K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index2word = {0: 'We', 1: 'like', 2: 'dogs'}"],"metadata":{"id":"Nfgh4iLdzw78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert context to reversed onehot vectors using decoder\n","onehot_rev = decoder(context)\n","# Get the reversed words using the onehot2words function\n","reversed_words = onehot2words(onehot_rev, index2word)\n","print(reversed_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1QC0iiFy59G","executionInfo":{"status":"ok","timestamp":1672434608766,"user_tz":-60,"elapsed":216,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"41028d03-4e23-4643-c7f2-b3b5e606cb6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['dogs', 'like', 'We']\n"]}]},{"cell_type":"markdown","source":["###**Comprendre les modèles séquentiels**\n","\n","####**1. Comprendre les modèles séquentiels**\n","\n","+ *Ici, vous découvrirez le modèle d’apprentissage automatique utilisé pour implémenter l’encodeur et le décodeur du traducteur automatique.*\n","\n","####**2. Entrées de séries chronologiques et modèles séquentiels**\n","\n","+ ***Une phrase est une entrée de série chronologique, ce qui signifie que chaque mot de la phrase est affecté par les mots précédents.*** \n","\n","+ ***L’encodeur et le décodeur utilisent un modèle d’apprentissage automatique qui peut apprendre à partir de séries chronologiques ou d’entrées séquentielles telles que des phrases.*** \n","\n","+ ***Le modèle d’apprentissage automatique est appelé modèle séquentiel.***\n","\n","####**3. Modèles séquentiels**\n","\n","+ Les modèles séquentiels vont d’une entrée à l’autre tout en produisant une sortie à chaque pas de temps.\n","\n","+  Pendant l’étape de temps 1, le premier mot est traité et pendant l’étape de temps 2, le deuxième mot est traité. Le même modèle traite chaque entrée.\n","\n","####**4. L’encodeur comme modèle séquentiel**\n","\n","+ *Vous utiliserez un type de modèles séquentiels appelés unité récurrente fermée, ou GRU, dans votre traducteur.* \n","\n","+ Par exemple, les entrées de l’encodeur sont une séquence de mots anglais codés en tant que vecteurs à une seule pression.\n","\n","####**5. Introduction à la couche GRU**\n","+ Prenons un exemple. Au temps égal à 1, le modèle GRU prend en compte le mot d’entrée « Nous » et un état caché initial qui sont tous des zéros. Ensuite, le modèle produit un nouvel état caché 0.8 et 0.3.\n","\n","####**6. Introduction à la couche GRU**\n","\n","+ Dans l’étape de temps suivante, le modèle GRU voit le mot suivant « comme » et l’état caché précédent 0,8 et 0,3. \n","\n","+ Le GRU prend ces deux entrées pour produire un nouvel état caché, et continue de cette façon jusqu’à la fin de la phrase. \n","\n","+ L’état masqué obtenu à partir de l’étape précédente agit comme mémoire de ce que le modèle a vu précédemment. \n","\n","+ Ces états cachés sont calculés à l’aide des paramètres internes du modèle GRU qui sont appris lors de l’apprentissage du modèle.\n","\n","####**7. Actualisation Keras (API fonctionnelle)**\n","+  Revisitons rapidement l’API fonctionnelle Keras. \n","\n","+ Keras a deux objets importants : **les calques et les modèles**. \n","\n","+ Vous pouvez définir une couche d’entrée à l’aide de l’objet Input. \n","\n","+  Vous pouvez également définir un calque masqué comme un calque GRU à l’aide de l’objet Keras GRU. \n","\n","+ Ensuite, vous pouvez obtenir la sortie de ce calque en passant inp au calque. \n","\n","+ Enfin, vous pouvez définir un objet de modèle en spécifiant les entrées et les sorties du modèle.\n","\n","####**8. Comprendre la forme des données**\n","\n","+ Avant de passer à la mise en œuvre des GRU, vous devez comprendre que les données séquentielles ont trois dimensions. \n","\n","+ Les séquences sont généralement traitées en groupes ou en lots. \n","\n","+ La dimension de lot spécifie le nombre de séquences dans un lot. \n","\n","+ La dimension temporelle décrit la longueur des séquences ou des phrases. \n","\n","+ La dimension d’entrée décrit la longueur des vecteurs à un chaud. La couche d’entrée d’un modèle GRU doit avoir cette forme en 3 dimensions.\n","\n","####**9. Mise en œuvre des GRU avec Keras**\n","\n","+ Lorsque vous utilisez Keras pour implémenter un modèle GRU, vous devez d’abord définir une couche d’entrée qui peut absorber les données. \n","\n","+ Dans cet exemple, vous avez une entrée de taille de lot 2, de longueur de séquence 3 et de dimensionnalité d’entrée 4. \n","\n","+ Ici, la longueur de la séquence est le nombre de mots dans la phrase. \n","\n","+ Ensuite, vous définissez une couche GRU qui a 10 unités cachées. \n","\n","+ La taille masquée détermine la taille de l’état masqué produit par le GRU. \n","\n","+ Enfin, ces couches sont enveloppées dans un modèle keras qui produit la sortie du GRU en tant que sortie du modèle.\n","\n","####**10. Mise en œuvre des GRU avec Keras**\n","\n","+ Vous pouvez ensuite utiliser le modèle pour prédire à l’aide de la prédiction par points du modèle et transmettre des données dont la forme exacte est définie dans la couche d’entrée.\n","\n","####**11. Mise en œuvre des GRU avec Keras**\n","\n","+ Vous pouvez également définir la couche d’entrée en définissant la taille du lot sur Aucun. \n","\n","+ Pour ce faire, utilisez l’argument shape au lieu de batch_shape et définissez uniquement la longueur de séquence et la dimensionnalité d’entrée. \n","\n","+ Dans Keras, cela signifie que la couche d’entrée acceptera n’importe quel lot de données de taille arbitraire. \n","\n","+ Cela permet de définir le modèle Keras une seule fois et d’expérimenter différentes tailles de lots sans changer le modèle.\n","\n","####**12. L’argument return_state de la couche GRU**\n","\n","+ Une couche GRU a deux autres arguments importants return_state et return_sequences. \n","\n","+ Si vous définissez l’argument return_state sur True, le modèle renvoie deux sorties au lieu d’une, l’une est le dernier état masqué et l’autre est la dernière sortie. \n","\n","+ Pour une couche GRU, elles sont identiques.\n","\n","####**13. L’argument return_sequences de la couche GRU**\n","E+ nsuite, si vous définissez return_sequences sur True, le modèle affichera toutes les sorties de la séquence au lieu de la dernière sortie. \n","\n","+ Il s’agira d’une taille de lot par longueur de séquence par sortie en forme de taille cachée.\n","\n","####**14. Entraînons-nous!**\n","+ Génial! Amusons-nous avec les couches GRU à Keras."],"metadata":{"id":"ingG02Nhz9ks"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Partie 1 : Comprendre les modèles GRU**\n","\n","+ Saviez-vous que ces modèles peuvent mémoriser jusqu'à des milliers de pas de temps, alors que les réseaux neuronaux récurrents standard ne peuvent mémoriser que moins de cent pas de temps ? \n","\n","+ Il est essentiel de comprendre les modèles GRU pour les utiliser efficacement dans la mise en œuvre de modèles de traduction automatique.\n","\n","+ Dans cet exercice, vous allez mettre en œuvre un modèle simple comportant une couche d'entrée et une couche GRU. \n","\n","+ Vous utiliserez ensuite le modèle pour produire des valeurs de sortie pour un tableau d'entrée aléatoire.\n","\n","+ *Ne soyez pas découragé par le fait que vous utilisez des données aléatoires. L'objectif de cet exercice est de comprendre la forme des sorties produites par la couche GRU. Dans les chapitres suivants, vous fournirez des phrases réelles aux couches GRU pour effectuer la traduction.*\n","\n","####**Instructions** \n","\n","+ Définissez une couche d'entrée Keras avec une taille de lot 2, une longueur de séquence 3 et une dimensionnalité d'entrée 4. \n","\n","+ Rappelez-vous que vous pouvez définir une couche d'entrée en utilisant la syntaxe keras.layers.Input(<argument>=<value>).\n","\n","\n","+ Définissez une couche Keras GRU qui possède 10 unités cachées et se nourrit de la couche d'entrée précédente. \n","\n","+ Vous pouvez utiliser la syntaxe keras.layers.GRU(<parameter>) pour définir une couche GRU.\n","\n","+ Définissez un modèle Keras appelé modèle où l'entrée est la couche d'entrée et la sortie est la sortie de la couche GRU.\n","\n","+ Générez les prédictions pour un ensemble donné de valeurs aléatoires $x$."],"metadata":{"id":"I3C_GzMwcBRH"}},{"cell_type":"code","source":["import tensorflow.keras as keras\n","import numpy as np\n","# Define an input layer\n","inp = keras.layers.Input(batch_shape=(2,3,4))"],"metadata":{"id":"qp8z1Ua4bFGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a GRU layer that takes in the input\n","gru_out = keras.layers.GRU(10)(inp)"],"metadata":{"id":"0sQbcyiAbFJp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a model that outputs the GRU output\n","model = keras.models.Model(inputs=inp, outputs=gru_out)\n","\n","x = np.random.normal(size=(2,3,4))\n","# Get the output of the model and print the result\n","y = model.predict(x)\n","print(\"shape (y) =\", y.shape, \"\\ny = \\n\", y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0dIGAFYbFRf","executionInfo":{"status":"ok","timestamp":1672434630487,"user_tz":-60,"elapsed":599,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"7e4b91a6-5733-420a-cee5-45698ddaa74d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f550dd7a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 412ms/step\n","shape (y) = (2, 10) \n","y = \n"," [[-0.33316627 -0.07640333  0.40575525 -0.3911105  -0.02054859  0.3880269\n","   0.2879269  -0.09599441  0.01534262 -0.31370032]\n"," [-0.21464378  0.12720858  0.23101754 -0.27271467 -0.05088519  0.3372832\n","   0.37126023  0.01574332  0.01715324 -0.15911949]]\n"]}]},{"cell_type":"markdown","source":["####**Partie 2 : Comprendre les modèles GRU**\n","\n","+ Vous allez maintenant voir comment vous pouvez utiliser les modèles Keras pour accepter des lots d'entrées de taille arbitraire. \n","\n","+ La possibilité d'accepter des lots de taille arbitraire est importante pour de nombreuses raisons. \n","\n","+ Par exemple, cela vous permet de définir un seul modèle Keras et d'expérimenter différentes tailles de lots pendant l'étape de formation du modèle, sans avoir à modifier quoi que ce soit dans le modèle.\n","\n","+ *Pour cet exercice, keras et numpy (en tant que np) ont déjà été importés.*\n","\n","####**Instructions**\n","\n","+ Définissez une couche d'entrée qui accepte un lot de données de taille arbitraire ayant une longueur de séquence de 3 et une taille d'entrée de 4.\n","\n","+ Définissez une couche GRU avec 10 unités cachées qui consomme l'entrée précédente et produit une sortie.\n","\n","+ Définissez un modèle appelé model qui prend la couche d'entrée comme entrée et produit la sortie de la couche GRU comme sortie. \n","+ Rappelez-vous que vous pouvez utiliser la syntaxe keras.models.Model(<argument>=<value>) pour définir un modèle.\n","\n","+ Prédisez la sortie du modèle pour $x1$ et $x2$."],"metadata":{"id":"ydf3-p8Uc-wd"}},{"cell_type":"code","source":["# Define an input layer\n","inp = keras.layers.Input(shape=(3,4))\n","# Define a GRU layer that takes in the input\n","gru_out = keras.layers.GRU(10)(inp)\n","# Define a model that outputs the GRU output\n","model = keras.models.Model(inputs=inp, outputs=gru_out)\n","\n","x1 = np.random.normal(size=(2,3,4))\n","x2 = np.random.normal(size=(5,3,4))\n","\n","# Get the output of the model and print the result\n","y1 = model.predict(x1)\n","y2 = model.predict(x2)\n","print(\"shape (y1) = \", y1.shape, \" shape (y2) = \", y2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pujjvdDubFUM","executionInfo":{"status":"ok","timestamp":1672434639911,"user_tz":-60,"elapsed":967,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"b5774065-f42c-4b51-edbf-16bba2a96401"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 462ms/step\n","1/1 [==============================] - 0s 20ms/step\n","shape (y1) =  (2, 10)  shape (y2) =  (5, 10)\n"]}]},{"cell_type":"markdown","source":["####**Comprendre la sortie d'un modèle séquentiel**\n","\n","+ Dans cet exercice, vous apprendrez à utiliser la couche ***keras.layers.GRU***. \n","\n","+ ***keras.layers.GRU enveloppe joliment la fonctionnalité d'un GRU dans un objet Layer.***\n","\n","+ Vous allez explorer la forme de la sortie d'une couche GRU et comment elle change lorsque différents arguments sont fournis. \n","\n","+ Il est rare de voir les vecteurs numériques produits par un GRU dans la vie réelle, mais afin d'utiliser ces couches dans des modèles plus complexes, vous devez avoir une bonne compréhension des formes des sorties et de la façon d'obtenir la sortie souhaitée en utilisant différents arguments.\n","\n","+ *Ici, vous aurez déjà chargé keras, et numpy (comme np). Vous pouvez accéder aux couches en appelant keras.layers.<Layer> ou à un modèle en appelant keras.models.Model.*\n","\n","####**Instructions** \n","\n","+ Créez une couche Input de taille 3, 20 pas de temps et 5 dimensions et appelez-la inp.\n","Créez une couche GRU de taille cachée 10, passez l'inp à cette couche et imprimez la forme de la sortie.\n","\n","+ Créez une nouvelle couche GRU avec 10 unités cachées, qui renvoie l'état et passez inp comme entrée, assignez l'état à gru_state, et imprimez la forme de gru_out2 et gru_state.\n","\n","+ Créez une nouvelle couche GRU avec return_sequences=True, passez inp comme entrée et imprimez la forme de la sortie."],"metadata":{"id":"q4rVr8qedvT4"}},{"cell_type":"code","source":["# Define the Input layer\n","inp = keras.layers.Input(batch_shape=(3,20,5))\n","# Define a GRU layer that takes in inp as the input\n","gru_out1 = keras.layers.GRU(10)(inp)\n","print(\"gru_out1.shape = \", gru_out1.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-ausCK0dNaf","executionInfo":{"status":"ok","timestamp":1672434646630,"user_tz":-60,"elapsed":371,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"b770c591-a612-46d1-ddab-fca251ea5811"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gru_out1.shape =  (3, 10)\n"]}]},{"cell_type":"code","source":["# Define the second GRU and print the shape of the outputs\n","gru_out2, gru_state = keras.layers.GRU(10, return_state=True)(inp)\n","print(\"gru_out2.shape = \", gru_out2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5UulKaSdNd4","executionInfo":{"status":"ok","timestamp":1672434650442,"user_tz":-60,"elapsed":350,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"7d3976dd-b514-4f4a-9138-d8b11a9cfdb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gru_out2.shape =  (3, 10)\n"]}]},{"cell_type":"code","source":["print(\"gru_state.shape = \", gru_state.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJMRPF5keTDH","executionInfo":{"status":"ok","timestamp":1672434652559,"user_tz":-60,"elapsed":218,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"cecff3cf-2e4f-4b1b-f5fe-4c4c748e3b8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gru_state.shape =  (3, 10)\n"]}]},{"cell_type":"code","source":["# Define the third GRU layer which will return all the outputs\n","gru_out3 = keras.layers.GRU(10, return_sequences=True)(inp)\n","print(\"gru_out3.shape = \", gru_out3.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Bck-K2py5_K","executionInfo":{"status":"ok","timestamp":1672434655319,"user_tz":-60,"elapsed":604,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"9f92b841-cfe1-460b-bac8-36cca4a02704"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gru_out3.shape =  (3, 20, 10)\n"]}]},{"cell_type":"markdown","source":["###**Mise en œuvre de l’encodeur**\n","\n","####**1. Mise en œuvre de l’encodeur**\n","\n","+ Apprenons maintenant à implémenter l’encodeur du modèle de traduction automatique.\n","\n","####**2. Comprendre les données**\n","\n","+ Mais, avant cela, explorons et comprenons l’ensemble de données. \n","+ Le jeu de données se compose de deux listes de chaînes. \n","+ Une liste contient les phrases anglaises et l’autre liste contient les phrases Français correspondantes. \n","+ Vous pouvez imprimer quelques-unes des phrases et voir à quoi elles ressemblent. \n","+ Ici, nous imprimons les 3 premières phrases des ensembles de données anglais et Français.\n","\n","####**3. Tokeniser les phrases**\n","\n","+ Examinons maintenant certains attributs de l’ensemble de données, tels que le nombre moyen de mots ou la longueur moyenne des phrases et la taille du vocabulaire. \n","\n","+ Ces paramètres sont nécessaires pour définir la couche d’entrée du codeur. \n","\n","+ La première étape du calcul de ces attributs consiste à tokeniser les phrases. \n","\n","+ La tokenisation est le processus d’extraction de jetons individuels, par exemple des mots individuels. \n","\n","+ Vous pouvez tokeniser une phrase à l’aide du caractère espace. \n","\n","+ Pour cela, vous pouvez utiliser la fonction de division Python et passer le caractère d’espace comme délimiteur. Cela renverra une liste de mots extraits de la phrase.\n","\n","####**4. Calcul de la durée des peines**\n","\n","+ Vous pouvez calculer la durée moyenne de la phrase comme suit. \n","\n","+ Vous itérez à travers la liste des phrases tout en symbolisant chaque phrase en mots. \n","\n","+ Ensuite, vous calculez la longueur de la liste de mots résultante, en utilisant la fonction len. \n","\n","+ Bien que cela ressemble à un ensemble complexe d’opérations, cela peut être fait avec une seule ligne en utilisant la syntaxe de compréhension de liste Python. \n","\n","+ Vous utilisez ensuite **la fonction np.mean** pour calculer la longueur moyenne.\n","\n","####**5. Calcul de la taille du vocabulaire**\n","\n","+ Pour calculer la taille du vocabulaire, vous pouvez à nouveau tokeniser toutes les phrases. \n","\n","\n","+ Et créez une liste contenant tous les mots du jeu de données appelée all_words. \n","\n","+ Ensuite, vous convertissez cela en un objet défini. \n","\n","+ Un objet défini ne contiendra que des éléments uniques dans la liste, il ne contiendra donc que les mots uniques du vocabulaire. \n","\n","+ Enfin, nous obtenons la longueur de cet ensemble pour calculer la taille du vocabulaire.\n","\n","####**6. L’encodeur**\n","\n","+ Utilisons maintenant ces informations pour implémenter l’encodeur.\n","\n","+ Rappelez-vous que le codeur est fabriqué à partir d’un modèle GRU qui signifie Gated Recurrent Units. \n","\n","+ Le modèle GRU passe d’une entrée à l’autre séquentiellement, tout en produisant une sortie (et un état) à chaque pas de temps. \n","\n","+ Le vecteur d’état produit au temps est égal à t devient un état d’entrée du modèle au temps égal à t plus 1.\n","\n","####**7. Implémentation de l’encodeur avec Keras**\n","\n","+ L’encodeur sera très similaire au modèle que vous avez implémenté lors de l’apprentissage de la couche GRU. \n","\n","+ Connaître le nombre moyen de mots nous aide à définir en_len. \n","\n","+ La taille du vocabulaire nous aide à définir en_vocab. \n","\n","+ Ceux-ci sont essentiels pour définir la couche d’entrée. \n","\n","+ Vous choisirez ces valeurs pour être proches de ce que vous avez découvert en analysant le jeu de données. \n","\n","+ Ensuite, vous définissez une couche GRU qui renvoie le dernier état. \n","\n","+ Le dernier état de la couche GRU sera ensuite transmis au décodeur en entrée. \n","\n","+ Notez que, bien que la sortie et l’état soient identiques pour une couche GRU, vous les traiterez comme deux choses distinctes car elles peuvent être différentes dans d’autres modèles séquentiels. \n","\n","+ Avec cela, vous définissez un modèle Keras représentant le codeur, dont l’entrée est la couche d’entrée et la sortie est l’état obtenu à partir de la couche GRU.\n","\n","####**8. Comprendre le résumé du modèle Keras**\n","\n","+ Vous pouvez également imprimer un résumé du modèle que vous avez défini à l’aide de la fonction de résumé des points du modèle. \n","\n","+ Vous pouvez voir trois colonnes dans la sortie, le nom et le type de la couche, les formes des sorties et le nombre de paramètres dans chaque couche. \n","\n","+ Par exemple, vous pouvez voir que la longueur de la séquence est définie sur 15 alors que la taille d’entrée est définie sur 150 pour la couche d’entrée. \n","\n","+ La couche GRU comporte 48 unités cachées et produit deux sorties, chacune ayant 48 valeurs.\n","\n","####**9. Entraînons-nous!**\n","+ Maintenant que vous avez appris sur les données et l’encodeur, amusons-nous!"],"metadata":{"id":"NpnqdQWKe83j"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Partie 1 : Exploration de l'ensemble de données**\n","\n","+ Vous allez maintenant explorer un peu l'ensemble de données. \n","\n","+ Vous allez d'abord vous faire une idée de l'aspect des données. \n","\n","+ Vous allez imprimer une partie des données et apprendre à tokeniser les phrases des données en mots individuels. \n","\n","+ Pour la langue anglaise, la tokenisation semble être une tâche triviale, cependant, il existe des langues comme le japonais, qui ne sont pas délimitées de manière aussi cohérente que l'anglais.\n","\n","+ *Pour cet exercice, deux jeux de données vous ont été fournis : en_text et fr_text. Le en_text contient une liste de phrases anglaises, tandis que le fr_text contient la liste correspondante de phrases françaises.*\n","\n","####**Instructions**\n","\n","+ Ecrivez une fonction zip() qui itère à travers les 5 premières phrases des phrases anglaises (en_text) et des phrases françaises (fr_text).\n","\n","\n","+ Obtenez la première phrase anglaise de en_text.\n","\n","\n","+ Tokeniser la phrase obtenue en utilisant la fonction split() et le caractère espace et l'assigner à first_words.\n","\n","+ Imprimer les mots tokénisés."],"metadata":{"id":"uEmPK4enjLgo"}},{"cell_type":"code","source":["# load text\n","filename = '/content/vocab_en.txt'\n","file = open(filename, 'rt')\n","en_text = file.read()"],"metadata":{"id":"-PA0vXBql3Rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_text"],"metadata":{"id":"Snn-c-4ZmA_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load text\n","filename = '/content/vocab_fr.txt'\n","file = open(filename, 'rt')\n","fr_text = file.read()"],"metadata":{"id":"QBoJLqw8l6dS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fr_text"],"metadata":{"id":"DXhNZl0Cmo8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Iterate through the first 5 English and French sentences in the dataset\n","for en_sent, fr_sent in zip(en_text[:5], fr_text[:5]):  \n","  print(\"English: \", en_sent)\n","  print(\"\\tFrench: \", fr_sent)\n","\n","# Get the first sentence of the English dataset\n","first_sent = en_text[0]\n","print(\"First sentence: \", first_sent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmS_i8cwi047","executionInfo":{"status":"ok","timestamp":1672434689141,"user_tz":-60,"elapsed":220,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"39ab7a79-b5b8-420f-982d-0939d7d1cfa0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["English:  n\n","\tFrench:  n\n","English:  e\n","\tFrench:  e\n","English:  w\n","\tFrench:  w\n","English:   \n","\tFrench:   \n","English:  j\n","\tFrench:  j\n","First sentence:  n\n"]}]},{"cell_type":"code","source":["# Tokenize the first sentence\n","first_words = first_sent.split(\" \")\n","# Print the tokenized words\n","print(\"\\tWords: \", first_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07zu9iI0i085","executionInfo":{"status":"ok","timestamp":1672434692702,"user_tz":-60,"elapsed":229,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"0e1abf92-9fe1-4756-ced6-c82b92dc0cca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\tWords:  ['n']\n"]}]},{"cell_type":"markdown","source":["####**Partie 2 : exploration de l'ensemble de données**\n","\n","+ ***Vous allez maintenant explorer certains attributs de l'ensemble de données. Plus précisément, vous allez déterminer la longueur moyenne (c'est-à-dire le nombre de mots) de toutes les phrases et la taille du vocabulaire pour le jeu de données anglais.***\n","\n","+ *Pour cet exercice, le jeu de données anglais en_text contenant une liste de phrases anglaises a été fourni. Dans cet exercice, vous utiliserez une fonction Python relative aux listes appelée <list>.extend() qui est une variante différente de la fonction <list>.append(). Comprenons la différence à travers un exemple. Disons que a=[1,2,3] et b=[4,5]. a.append(b) donnerait une liste [1,2,3,[4,5]] alors que a.extend(b) donnerait [1,2,3,4,5].*\n","\n","####**Instructions**\n","\n","+ Calculez la longueur de chaque phrase en utilisant la fonction split() et la fonction len(), tout en itérant dans en_text.\n","\n","+ Calculez la longueur moyenne des phrases en utilisant numpy.\n","\n","+ Remplir la liste all_words, dans le corps de la boucle for, en ajoutant tous les mots trouvés dans les phrases après la tokenisation.\n","\n","+ Convertir la liste all_words, en un objet set et calculer la longueur/taille de l'ensemble."],"metadata":{"id":"I3GthffXkByC"}},{"cell_type":"code","source":["# Compute length of sentences\n","sent_lengths = [len(en_sent.split(\" \")) for en_sent in en_text]\n","# Compute the mean of sentences lengths\n","mean_length = np.mean(sent_lengths)\n","print('(English) Mean sentence length: ', mean_length)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNIJlhIyi1Dj","executionInfo":{"status":"ok","timestamp":1672434699963,"user_tz":-60,"elapsed":2804,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"fd03dd1b-6421-47ff-ca49-64d8625f65d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(English) Mean sentence length:  1.185512654718898\n"]}]},{"cell_type":"code","source":["all_words = []\n","for sent in en_text:\n","  # Populate all_words with all the words in sentences\n","  all_words.extend(sent.split(\" \"))\n","# Compute the length of the set containing all_words\n","vocab_size = len(set(all_words))\n","print(\"(English) Vocabulary size: \", vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzi4R3Lfi1FO","executionInfo":{"status":"ok","timestamp":1672434705241,"user_tz":-60,"elapsed":2427,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"60d88513-0012-4cf4-f690-37002c49e4d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(English) Vocabulary size:  32\n"]}]},{"cell_type":"markdown","source":["####**Définition de l'encodeur**\n","\n","+ ***La première étape de la création d'un modèle de traduction automatique est l'implémentation de l'encodeur. ***\n","\n","+ ***L'encodeur que vous allez implémenter est un modèle très simple comparé aux modèles complexes qui sont utilisés dans les applications du monde réel, comme le service de traduction automatique de Google. Mais ne vous inquiétez pas, bien que le modèle soit simple, les concepts sont les mêmes que ceux de ces modèles complexes.***\n","\n","+ *Vous verrez que nous avons choisi que en_vocab soit plus petit (150) que la valeur réelle (228) que nous avons trouvée. En réduisant le vocabulaire, on réduit l'empreinte mémoire du modèle. Réduire légèrement le vocabulaire n'est pas un problème puisque nous supprimons les mots les plus rares. Pour les tâches de traduction automatique, les mots rares ont généralement moins de valeur que les mots courants.*\n","\n","####**Instructions**\n","\n","+ Définissez une couche d'entrée pour une entrée qui a une taille de vocabulaire en_vocab et une longueur de séquence en_len, en utilisant l'argument shape.\n","\n","\n","+ Définir une couche keras.layers.GRU qui a hsize unités cachées et retourne son état.\n","\n","+ Obtenez les sorties de la couche GRU en entrant en_inputs et affectez l'état GRU à en_state et la sortie à en_out.\n","\n","+ Définissez un keras.models.Model dont l'entrée est en_inputs et la sortie est en_state et imprimez le résumé du modèle."],"metadata":{"id":"zwQC8Hp3kfYy"}},{"cell_type":"code","source":["import tensorflow.keras as keras\n","\n","en_len = 15\n","en_vocab = 150\n","hsize = 48\n","\n","# Define an input layer\n","en_inputs = keras.layers.Input(shape=(en_len, en_vocab))\n","# Define a GRU layer which returns the state\n","en_gru = keras.layers.GRU(hsize, return_state=True)\n","# Get the output and state from the GRU\n","en_out, en_state = en_gru(en_inputs)\n","# Define and print the model summary\n","encoder = keras.models.Model(inputs=en_inputs, outputs=en_state)\n","print(encoder.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ve6To4pukvLA","executionInfo":{"status":"ok","timestamp":1672434711034,"user_tz":-60,"elapsed":798,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"d9c1d0c7-d153-47ae-f8ee-634425a4ecdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_10 (InputLayer)       [(None, 15, 150)]         0         \n","                                                                 \n"," gru_12 (GRU)                [(None, 48),              28800     \n","                              (None, 48)]                        \n","                                                                 \n","=================================================================\n","Total params: 28,800\n","Trainable params: 28,800\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","source":["####*Définition du décodeur**\n","\n","####**1. Définition du décodeur**\n","\n","+ *Il est maintenant temps d’apprendre à implémenter le décodeur.*\n","\n","####**2. Modèle codeur-décodeur**\n","\n","+ ***Vous avez déjà implémenté l’encodeur qui consomme la langue source, c’est-à-dire les mots anglais un par un et produit finalement le vecteur de contexte.*** \n","\n","+ ***Maintenant, vous devez implémenter le décodeur qui consomme le vecteur de contexte et produit les mots de la langue cible, c’est-à-dire Français mots un par un.***\n","\n","####**3. Entrée du décodeur**\n","\n","+ Le décodeur sera implémenté de la même manière que l’encodeur à l’aide d’une couche Keras GRU. \n","\n","+ Mais cela pose une question. \n","\n","+ La couche Keras GRU nécessite une entrée pour traiter en plus de l’état masqué. Quel serait cet apport?\n","\n","####**4. Entrée du décodeur**\n","\n","+ Une solution serait de répéter le vecteur de contexte pour l’adapter à la longueur de la phrase Français que vous souhaitez produire. \n","\n","+ Par exemple, si vous avez besoin d’une phrase Français de longueur 10, vous répétez le vecteur de contexte 10 fois. \n","\n","+ Le vecteur de contexte est considéré comme une bonne entrée pour le décodeur, car il s’agit d’une représentation de la phrase anglaise que l’encodeur a vue. \n","\n","+ Pour ce faire, vous pouvez utiliser le calque RepeatVector fourni dans Keras. \n","\n","+ Le calque RepeatVector vous permet de répéter une entrée ou une sortie un nombre donné de fois. \n","\n","+ Notez que ce n’est pas la seule solution et vous verrez une meilleure solution dans le dernier chapitre.\n","\n","####**5. Comprendre la couche RepeatVector**\n","\n","+ Pour utiliser la couche RepeatVector, vous devez fournir un argument qui spécifie la longueur de la séquence ou le nombre de fois que vous souhaitez répéter les données. \n","\n","+ Il prend une entrée de taille de lot taille par taille d’entrée. \n","\n","+ Après la transformation, il produira une sortie de taille de lot taille par longueur de séquence par taille d’entrée, qui est le type d’entrée accepté par une couche GRU.\n","\n","####**6. Définition d’un calque RepeatVector**\n","\n","+ Vous pouvez définir un RepeatVector comme indiqué ici, qui se répétera r_inp 5 fois dans cet exemple. \n","\n","+ Ensuite, vous pouvez définir un modèle Keras simple qui répète une entrée donnée de taille 3, 5 fois. \n","\n","+ Notez que les deux extraits de code suivants sont équivalents et peuvent tous deux être utilisés pour obtenir la sortie d’un calque RepeatVector.\n","\n","####**7. Prédire avec le modèle**\n","\n","+ Vous pouvez maintenant utiliser ce modèle pour voir ce qui se passe dans le calque **RepeatVector**. \n","\n","+ Par exemple, si vous fournissez un tableau de forme 2 par 3, le calque RepeatVector répète le tableau 2 x 3 5 fois et génère un tableau en forme de 2 x 5 x 3.\n","\n","####**8. Mise en œuvre du décodeur**\n","\n","+ Utilisons maintenant le RepeatVector avec d’autres couches pour implémenter le décodeur. \n","\n","+ Vous pouvez d’abord définir l’entrée du décodeur à l’aide de la couche RepeatVector et en répétant l’état de l’encodeur fr_len fois. \n","\n","+ fr_len est la durée moyenne d’une peine Français. \n","\n","+ Ensuite, créons la couche GRU du décodeur. \n","\n","+ N’oubliez pas que, contrairement à l’encodeur, vous avez besoin de toutes les sorties de la couche GRU du décodeur, pas seulement de la dernière sortie. \n","\n","+ En effet, chacune de ces sorties GRU est ensuite utilisée pour prédire le mot Français correct pour chaque position du décodeur.\n","\n","+  Par conséquent, n’oubliez pas de définir l’argument return_sequences sur True. \n","\n","+ Vous devez également fournir le vecteur de contexte produit par l’encodeur comme état initial du décodeur, car nous ne voulons pas que le décodeur démarre sans aucune mémoire de l’encodeur. \n","\n","+ Pour ce faire, lorsque vous passez le de_inputs d’entrée à la couche GRU du décodeur, vous devez définir l’argument initial_state sur en_state, qui est le vecteur de contexte.\n","\n","####**9. Définition du modèle**\n","\n","+ Enfin, vous définissez un modèle Keras qui contient à la fois l’encodeur et le décodeur, où l’entrée est en_inputs ou les mots anglais et sort toutes les sorties GRU pour toutes les positions de séquence du décodeur.\n","\n","####**10. Entraînons-nous!**\n","+ Étape par étape, vous arrivez à la solution finale. \n","\n","+ Implémentons maintenant le décodeur du modèle de décodeur d’encodeur."],"metadata":{"id":"o_pETnVUnBVI"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Comprendre la couche RepeatVector**\n","\n","+ Vous allez maintenant explorer le fonctionnement de la couche RepeatVector. \n","\n","+ La couche RepeatVector ajoute une dimension supplémentaire à votre ensemble de données. \n","\n","+ Par exemple, si vous disposez d'une entrée de forme (taille du lot, taille de l'entrée) et que vous souhaitez la transmettre à une couche GRU, vous pouvez utiliser une couche RepeatVector pour convertir l'entrée en un tenseur de forme (taille du lot, longueur de la séquence, taille de l'entrée).\n","\n","+ *Dans cet exercice, vous allez définir un modèle qui répète une entrée donnée un nombre fixe de fois. Vous alimenterez ensuite le modèle avec un tableau numpy et étudierez comment le modèle modifie la sortie.*\n","\n","####**Instructions**\n","\n","+ Définissez une couche RepeatVector qui répète l'entrée 6 fois.\n","\n","+ Définir un modèle qui prend la couche d'entrée et produit la sortie du vecteur de répétition.\n","\n","+ Définir un objet numpy array qui a des données [[0,1], [2,3]].\n","\n","+ Prédire la sortie du modèle en fournissant $x$ comme entrée.\n","\n"],"metadata":{"id":"-70ZlRr211JF"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, RepeatVector\n","from tensorflow.keras.models import Model\n","import numpy as np\n","\n","inp = Input(shape=(2,))\n","# Define a RepeatVector that repeats the input 6 times\n","rep = RepeatVector(6)(inp)\n","# Define a model\n","model = Model(inputs=inp, outputs=rep)\n","# Define input x\n","x = np.array([[0,1],[2,3]])\n","# Get model prediction y\n","y = model.predict(x)\n","print('x.shape = ',x.shape,'\\ny.shape = ',y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JC0cDaRokvOc","executionInfo":{"status":"ok","timestamp":1672434723216,"user_tz":-60,"elapsed":239,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"8ec6319e-f65f-40e8-ef69-4bdaeef1491f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 50ms/step\n","x.shape =  (2, 2) \n","y.shape =  (2, 6, 2)\n"]}]},{"cell_type":"markdown","source":["####**La forme de la sortie d'une couche RepeatVector**\n","\n","+ Considérons l'utilisation suivante de la couche RepeatVector\n","\n","        inp = Input(shape=(3,))\n","        rep = RepeatVector(10)(inp)\n","        model = Model(inputs=inp, outputs=rep)\n","\n","+ *Si vous passez x de forme 8x3 à la fonction model.predict(), quelle est la forme de la sortie ?*\n","\n","####**Répondez à la question**\n","\n","####**Réponses possibles**\n","\n","+ ***8x10x3***\n","\n","+ 8x3x10\n","\n","+ 8x3\n","\n","+ Aucun de ces exercices"],"metadata":{"id":"vtGWkmPk2sVA"}},{"cell_type":"markdown","source":["####**Définition du décodeur**\n","+ Dans cet exercice, vous allez implémenter le décodeur et définir un modèle de bout en bout allant des entrées de l'encodeur aux sorties du décodeur GRU. Le décodeur utilise le même modèle que l'encodeur. \n","\n","+ Cependant, il existe des différences dans les entrées et les états fournis au décodeur, par rapport à l'encodeur. \n","\n","+ Par exemple, le décodeur consomme le vecteur de contexte produit par l'encodeur comme entrées ainsi que l'état initial du décodeur.\n","\n","+ Pour implémenter le décodeur, vous utiliserez les couches RepeatVector et GRU.\n","\n","+ *Pour cet exercice, on vous a fourni le modèle de l'encodeur et les différentes couches de l'encodeur que vous avez déjà implémentées. Par exemple, les entrées de l'encodeur sont fournies comme en_inputs et le vecteur de contexte comme en_state. Notez également que les objets GRU et Model ont déjà été importés.*\n","\n","####**Instructions**\n","\n","+ Définissez une couche RepeatVector qui prend en_state comme entrée et le répète fr_len fois.\n","\n","+ Définissez une couche GRU, decoder_gru, qui a des unités cachées égales à hsize et retourne toutes les sorties produites.\n","\n","+ Obtenez la sortie de la couche décodeur_gru en entrant de_inputs comme entrée et en_state comme état initial du décodeur.\n","\n","+ Définir un modèle qui prend en_inputs comme entrée et gru_outputs comme sortie."],"metadata":{"id":"wm2whjcI3KMF"}},{"cell_type":"code","source":["from tensorflow.keras.layers import RepeatVector\n","from tensorflow.keras.layers import GRU, Embedding, Bidirectional\n","hsize = 48\n","fr_len = 20\n","# Define a RepeatVector layer\n","de_inputs = RepeatVector(fr_len)(en_state)\n","# Define a GRU model that returns all outputs\n","decoder_gru = GRU(hsize, return_sequences=True)\n","# Get the outputs of the decoder\n","gru_outputs = decoder_gru(de_inputs, initial_state=en_state)\n","# Define a model with the correct inputs and outputs\n","enc_dec = Model(inputs=en_inputs, outputs=gru_outputs)\n","enc_dec.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMtsaNRv3V8v","executionInfo":{"status":"ok","timestamp":1672435451373,"user_tz":-60,"elapsed":728,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"eb3441ad-6d66-400e-a2a9-757fdd4d5df9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_10\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_10 (InputLayer)          [(None, 15, 150)]    0           []                               \n","                                                                                                  \n"," gru_12 (GRU)                   [(None, 48),         28800       ['input_10[0][0]']               \n","                                 (None, 48)]                                                      \n","                                                                                                  \n"," repeat_vector_9 (RepeatVector)  (None, 20, 48)      0           ['gru_12[0][1]']                 \n","                                                                                                  \n"," gru_13 (GRU)                   (None, 20, 48)       14112       ['repeat_vector_9[0][0]',        \n","                                                                  'gru_12[0][1]']                 \n","                                                                                                  \n","==================================================================================================\n","Total params: 42,912\n","Trainable params: 42,912\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["###**Calques denses et distribués dans le temps**\n","\n","####**1. Calques denses et distribués dans le temps**\n","\n","+ *Dans cette leçon, vous découvrirez deux couches importantes qui vous aideront à implémenter la dernière partie du modèle de traduction automatique basé sur un ***encodeur-décodeur*** : ***la couche dense et la couche TimeDistributed***.*\n","\n","####**2. Introduction à la couche dense**\n","\n","+ Une couche dense peut être utilisée pour implémenter une couche entièrement connectée d’un réseau neuronal. \n","\n","+ La partie supérieure du décodeur a besoin d’une couche dense, car vous devez prédire le mot Français correct pour chaque position de décodeur. Un calque dense ressemble à ce qui est montré ici. \n","\n","+ Il prend un vecteur d’entrée et produit un vecteur de sortie, en utilisant des poids et des biais. \n","\n","+ Mais les valeurs de sortie ne feront pas une distribution de probabilité valide. \n","\n","+ Ensuite, pour faire de la sortie une distribution de probabilité valide sur les classes, **une activation softmax est appliquée à la sortie**.\n","\n","####**3. Comprendre la couche dense**\n","\n","+ Vous pouvez facilement créer un calque dense à l’aide de cette syntaxe. \n","\n","+ Le premier argument indique le nombre de classes ou d’étiquettes que vous avez, ce qui correspond à 3 dans cet exemple. \n","\n","+ Pour la traduction automatique, il s’agit de la taille de la langue cible, c’est-à-dire de la taille du vocabulaire Français. \n","\n","+ Chaque classe représenterait alors un seul Français mot. \n","\n","+ Nous définissons l’activation de la couche dense sur softmax pour faire de la sortie une distribution de probabilité valide. \n","\n","+ Vous pouvez fournir des initialisations personnalisées de poids et de biais à un calque dense à l’aide des arguments **kernel_initializer et bias_initializer**.\n","\n","####**4. Entrées et sorties de la couche dense**\n","\n","+ Un calque dense prend une taille de lot par tableau de taille d’entrée, par exemple, un tableau 2 par 3. \n","\n","+ Ensuite, il produit une taille de lot par tableau de classes num. \n","\n","+ Si vous regardez la sortie, cela ressemblerait à une distribution de probabilité valide sur les classes pour chaque entrée. \n","\n","+ Par exemple, l’entrée 1 6 8 a la distribution de probabilité 0,1, 0,3, 0,4 et 0,2 qui est égale à 1. \n","\n","+ Enfin, vous pouvez obtenir les classes prédites pour chaque entrée à l’aide de la fonction np dot argmax avec le dernier axe, représenté par -1. \n","\n","+ En effet, les probabilités sont présentes le long du dernier axe.\n","\n","####**5. Comprendre la couche TimeDistributed**\n","\n","+ Cependant, comme vous l’avez déjà vu, la sortie de la couche GRU du décodeur est une entrée de série chronologique de taille de lot taille par longueur de séquence par taille d’entrée. \n","\n","+ Pour permettre au calque Dense de traiter une entrée de série chronologique, comme la sortie de la couche GRU du décodeur, vous pouvez utiliser un wrapper de calque TimeDistributed. \n","\n","+ Vous pouvez facilement ajouter un calque TimeDistributed comme suit. \n","\n","+ Ensuite, vous pouvez créer un modèle capable de traiter une entrée de série chronologique et de produire des prédictions.\n","\n","####**6. Entrées et sorties de la couche TimeDistributed**\n","\n","+ Une couche dense distribuée dans le temps prend une taille de lot par longueur de séquence par tableau de taille d’entrée et produit une taille de lot par longueur de séquence par nombre de classes de taille de tableau. \n","\n","+ Dans l’exemple ici, vous avez un tableau 2 x 3 x 2. \n","\n","+ La sortie a une distribution de probabilité pour chaque échantillon de l’entrée de la série chronologique. \n","\n","+ Vous pouvez voir que chaque entrée de x est transformée en une distribution de probabilité valide sur les 3 classes, ce qui donne un tableau 2 x 3 x 3. \n","\n","+ Par exemple, l’entrée 1 6 est transformée en 0,1, 0,5 et 0,4. \n","\n","+ Vous pouvez obtenir la classe prédite pour chaque échantillon similaire à la couche dense. \n","\n","+ C’est-à-dire en utilisant np dot argmax et en fournissant le dernier axe comme axe.\n","\n","####**7. Découpage des données en fonction de la dimension temporelle**\n","\n","+ Vous pouvez ensuite itérer dans les données distribuées dans le temps à l’aide de deux boucles « for ». \n","\n","+ Dans la première boucle for, vous itérez à travers la dimension temporelle qui est la taille 3. \n","\n","+ Dans la deuxième boucle for, vous obtenez la t-ième tranche sur la dimension temporelle pour y et classes et imprimez les données. \n","\n","+ Notez qu’il ne s’agit que d’une solution unique et qu’il existe plusieurs façons de le faire.\n","\n","####**8. Entraînons-nous!**\n","+ Vous savez maintenant comment utiliser les calques denses et distribués. Entraînons-nous!"],"metadata":{"id":"BwyLBtM-6hp3"}},{"cell_type":"markdown","source":["####**Partie 1 : participez pour gagner des prix incroyables**\n","\n","+ *Dans cet exercice, vous allez découvrir la couche Dense. Pourquoi ne pas le faire avec un exercice amusant ? Imaginez qu'il existe un jeu télévisé où les prix sont déterminés par un réseau neuronal. Le participant entre*\n","\n","+ *le nombre de frères et sœurs,\n","le nombre de cafés pris aujourd'hui et\n","s'il aime les tomates ou pas,\n","et le modèle prédit ce que le participant va gagner.*\n","\n","+ *Pour mettre en œuvre ce modèle, vous utiliserez Keras. Vous devrez créer un modèle avec une couche d'entrée qui accepte trois caractéristiques (le nombre de frères et sœurs sous forme de nombre entier, le nombre de cafés sous forme de nombre entier et s'ils aiment ou non les tomates sous forme de 0 ou 1). Ensuite, l'entrée passe par une couche dense qui produit 3 probabilités (c'est-à-dire les probabilités de gagner une voiture, un chèque-cadeau ou rien).*\n","\n","+ *Les couches d'entrée et dense ainsi qu'un objet Modèle de Keras sont déjà importés. On vous fournit également un initialisateur de poids appelé init pour initialiser la couche Dense.*\n","\n","####**Instructions**\n","\n","+ Définissez une couche d'entrée qui n'accepte que 3 participants (taille du lot), où chaque participant a 3 entrées : le nombre de frères et sœurs, le nombre de cafés et la préférence pour les tomates (taille de l'entrée).\n","\n","\n","+ Définissez une couche dense qui a 3 sorties, une activation softmax et init comme initialisateur.\n","\n","\n","+ Calculez les prédictions du modèle pour $x$ en utilisant le modèle défini.\n","\n","\n","+ Obtenir le prix le plus probable (sous forme d'un nombre entier) pour chaque participant.\n","\n"],"metadata":{"id":"DItk6OT6Ewif"}},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"sdOnd01zIKdm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.initializers import RandomNormal\n","init = RandomNormal(mean=0.0, stddev=0.05, seed=6000)\n"],"metadata":{"id":"i8zFM21XIIe5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define an input layer with batch size 3 and input size 3\n","inp = Input(batch_shape=(3, 3))\n","# Get the output of the 3 node Dense layer\n","pred = Dense(3, activation='softmax', kernel_initializer=init, bias_initializer=init)(inp)\n","model = Model(inputs=inp, outputs=pred)\n","\n","names = [\"Mark\", \"John\", \"Kelly\"]\n","prizes = [\"Gift voucher\", \"Car\", \"Nothing\"]\n","x = np.array([[5, 0, 1], [0, 3, 1], [2, 2, 1]])\n","# Compute the model prediction for x\n","y = model.predict(x)\n","# Get the most probable class for each sample\n","classes = np.argmax(y, axis=-1)\n","print(\"\\n\".join([\"{} has probabilities {} and wins {}\".format(n,p,prizes[c]) \\\n","                 for n,p,c in zip(names, y, classes)]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCg0jG09EhsZ","executionInfo":{"status":"ok","timestamp":1672440181793,"user_tz":-60,"elapsed":230,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"211afb40-f2f8-4465-81ca-6498c59120d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 51ms/step\n","Mark has probabilities [0.3508269  0.34466726 0.30450585] and wins Gift voucher\n","John has probabilities [0.35618564 0.3246216  0.3191928 ] and wins Gift voucher\n","Kelly has probabilities [0.35548124 0.3310233  0.3134955 ] and wins Gift voucher\n"]}]},{"cell_type":"markdown","source":["####**Partie 2 : Jouons à d'autres jeux**\n","\n","+ Vous avez bien travaillé sur le dernier projet. \n","\n","+ Cette fois, vous devrez simuler plusieurs jeux télévisés organisés sur plusieurs jours. \n","\n","+ Cela signifie que vos données auront une dimension temporelle. \n","\n","+ Plus précisément, vos données auront la forme (nombre de participants, jeux télévisés, taille des entrées).\n","\n","+ Vous devrez étendre votre modèle pour intégrer cette nouvelle caractéristique. \n","\n","+ Pour cela, vous utiliserez une couche TimeDistributed pour permettre à la couche Dense d'accepter les participants de plusieurs jeux télévisés.\n","\n","+ On vous a fourni l'initialisateur de poids init, la liste des prix de l'exercice précédent, une entrée de série temporelle $x$ et les noms qui contiennent les noms des participants. \n","\n","+ $x$ est un tableau numpy (3,2,3) où les noms sont une liste Python (2,3). \n","\n","+ En d'autres termes, vous avez 2 jeux télévisés (c'est-à-dire la longueur de la séquence), chacun avec 3 participants (taille du lot) où chaque participant a 3 attributs (taille de l'entrée).\n","\n","####**Instructions**\n","\n","+ Imprimez les noms, $x$ et la forme de $x$.\n","\n","\n","+ Créez une couche TimeDistributed qui enveloppe une couche Dense à 3 nœuds avec activation softmax.\n","\n","\n","+ Obtenez les classes les plus probables pour tous les échantillons des prédictions.\n","\n","\n","+ Dans la deuxième boucle for, fournir la tième tranche (sur la dimension temporelle) de $y$ et les classes (c'est-à-dire les informations du tième jeu télévisé)."],"metadata":{"id":"FCWnHcdZJLGP"}},{"cell_type":"code","source":["x = np.array([[[5, 0, 1], [1, 1, 0]],[[0, 3, 1],[0, 4, 0]],[[2, 2, 1], [6, 0, 1]]])\n","names = [['Mark', 'John', 'Kelly'], ['Jenny', 'Shan', 'Sarah']]"],"metadata":{"id":"H1nlPPc6KgZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print names and x\n","print('names=\\n',names, '\\nx=\\n',x, '\\nx.shape=', x.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvF_T-7TEhvr","executionInfo":{"status":"ok","timestamp":1672440193479,"user_tz":-60,"elapsed":4,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"39539352-c781-44c2-846a-86a52f661913"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["names=\n"," [['Mark', 'John', 'Kelly'], ['Jenny', 'Shan', 'Sarah']] \n","x=\n"," [[[5 0 1]\n","  [1 1 0]]\n","\n"," [[0 3 1]\n","  [0 4 0]]\n","\n"," [[2 2 1]\n","  [6 0 1]]] \n","x.shape= (3, 2, 3)\n"]}]},{"cell_type":"code","source":["from keras.layers import LSTM\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Input, TimeDistributed, Flatten"],"metadata":{"id":"-LHZ0gLUJv1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp = Input(shape=(2, 3))\n","# Create the TimeDistributed layer (the output of the Dense layer)\n","dense_time = TimeDistributed(Dense(3, activation='softmax', kernel_initializer=init, bias_initializer=init))\n","pred = dense_time(inp)\n","model = Model(inputs=inp, outputs=pred)\n","\n","y = model.predict(x)\n","# Get the most probable class for each sample\n","classes = np.argmax(y, axis=-1)\n","for t in range(2):\n","  # Get the t-th time-dimension slice of y and classes\n","  for n, p, c in zip(names[t], y[:,t,:], classes[:,t]):\n","  \tprint(\"Game {}: {} has probs {} and wins {}\\n\".format(t+1,n,p,prizes[c]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"glMUoVEmEhyx","executionInfo":{"status":"ok","timestamp":1672440198578,"user_tz":-60,"elapsed":209,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"8b53ad9b-f2a0-4896-8ff2-379b003601e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 51ms/step\n","Game 1: Mark has probs [0.4117553  0.2627244  0.32552037] and wins Gift voucher\n","\n","Game 1: John has probs [0.25518313 0.46328828 0.2815286 ] and wins Car\n","\n","Game 1: Kelly has probs [0.3107848  0.38583648 0.30337882] and wins Car\n","\n","Game 2: Jenny has probs [0.3184882  0.3678727  0.31363907] and wins Car\n","\n","Game 2: Shan has probs [0.22459328 0.50584966 0.2695571 ] and wins Car\n","\n","Game 2: Sarah has probs [0.42647755 0.24758707 0.3259354 ] and wins Gift voucher\n","\n"]}]},{"cell_type":"markdown","source":["###**Mise en œuvre du modèle de décodeur complet du codeur**\n","\n","####**1. Mise en œuvre du modèle de décodeur complet du codeur**\n","\n","+ Dans cette vidéo, vous allez implémenter le modèle complet d’encodeur-décodeur.\n","\n","####**2. Ce que vous avez mis en œuvre jusqu’à présent**\n","\n","+ Jusqu’à présent, vous avez implémenté un encodeur qui consomme les mots d’entrée source ou anglais et produit un vecteur de contexte. \n","\n","+ Ensuite, vous avez implémenté un décodeur qui consomme le vecteur de contexte en entrée à l’aide du calque RepeatVector et produit une séquence de sorties à partir de la couche GRU.\n","\n","####**3. Partie supérieure du décodeur**\n","\n","+ Cependant, vous avez toujours besoin d’une couche qui produit les mots Français pour chaque position du décodeur. \n","\n","+ Le mot à chaque position est obtenu à partir d’une sortie probabiliste sur le vocabulaire Français. \n","\n","+ Une couche Keras Dense peut être utilisée pour obtenir cette sortie probabiliste. \n","\n","+ La couche dense consomme une entrée (ici, une seule sortie GRU) et produit une distribution de probabilité de la probabilité que chaque mot Français soit le mot traduit correctement, pour cette position. \n","\n","+ Toutefois, comme le décodeur produit une séquence de sorties GRU, vous devez envelopper le calque Dense avec un calque TimeDistributed permettant au calque Dense de consommer des entrées de séries chronologiques.\n","\n","####**4. Mise en œuvre du modèle complet**\n","\n","+ Vous pouvez maintenant implémenter le modèle complet. \n","\n","+ Vous avez déjà implémenté l’encodeur qui prend en_inputs et produit en_state comme sortie, et le décodeur qui prend de_inputs, qui répète le vecteur de contexte fr_len fois, et produit de_out comme sortie.\n","\n","###**5. Mise en œuvre du modèle complet**\n","\n","+ Vous pouvez ensuite ajouter la fonctionnalité de prédiction de mots Français à l’aide d’un calque dense et d’un calque TimeDistributed comme illustré ici, où fr_vocab est la taille du vocabulaire Français. \n","\n","+ Enfin, de_pred conservera les prédictions de probabilité sur tous les Français mots pour chaque position du décodeur.\n","\n","####**6. Compilation du modèle**\n","\n","+ Ensuite, vous pouvez définir un modèle Keras avec en_inputs comme entrée et de_pred comme sortie. \n","\n","+ de_pred contient les prédictions probabilistes des mots Français pour toutes les positions du décodeur. \n","\n","+ Enfin, vous devez compiler le modèle complet avec un optimiseur et une fonction de perte. \n","\n","+ Un optimiseur et une fonction de perte sont nécessaires pour entraîner un modèle. \n","\n","+ De plus, vous pouvez définir des métriques telles que la précision qui vous permettraient de surveiller le modèle au fur et à mesure de sa formation. \n","\n","+ Lorsque vous définissez une liste de mesures, vous obtenez en fait une métrique supplémentaire à celles que vous avez définies. \n","\n","+ La mesure supplémentaire sera la valeur de la fonction de perte que vous avez définie pour l’argument de perte. \n","\n","+ Dans notre exemple, vous obtiendrez deux mesures, la perte de crossentropie catégorielle et la précision pour un ensemble donné de données.\n","\n","####**7. Entraînons-nous!**\n","+ Génial! Maintenant que vous avez tout appris sur le modèle de décodeur d’encodeur, entraînons-nous!"],"metadata":{"id":"6AsZ8zLTLCjw"}},{"cell_type":"markdown","source":["###**Partie 1 : Définir le modèle complet**\n","\n","+ Ici, vous allez implémenter les dernières couches du modèle d'encodage-décodage. \n","\n","+ Vous utiliserez les couches Dense et TimeDistributed pour obtenir les prédictions finales (c'est-à-dire les probabilités des mots français prédits) du modèle encodeur-décodeur.\n","\n","+ Nous vous fournissons l'encodeur et le décodeur (sans la partie supérieure) que vous avez implémentés jusqu'à présent. La sortie de_out de la couche GRU du décodeur est fournie.\n","\n","####**Instructions**\n","\n","+ Importez les couches Dense et TimeDistributed de Keras.\n","\n","+ Définissez une couche Dense avec activation softmax qui a des sorties fr_vocab.\n","\n","+ Enveloppez la couche Dense dans une couche TimeDistributed.\n","\n","+ Obtenez la prédiction finale du modèle en passant de_out à la couche de_dense_time."],"metadata":{"id":"SvU0wHj_LsPO"}},{"cell_type":"code","source":["fr_vocab =250\n","de_inputs = RepeatVector(fr_len)(en_state)\n","de_gru = GRU(hsize, return_sequences=True)\n","de_out = de_gru(de_inputs, initial_state=en_state)\n","\n","\n","en_inputs = Input(shape=(en_len, en_vocab))\n","en_gru = GRU(hsize, return_state=True)\n","en_out, en_state = en_gru(en_inputs)"],"metadata":{"id":"1TH6dM_NMFPW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import Dense and TimeDistributed layers\n","from tensorflow.keras.layers import Dense, TimeDistributed\n","# Define a softmax dense layer that has fr_vocab outputs\n","de_dense = Dense(fr_vocab, activation='softmax')\n","# Wrap the dense layer in a TimeDistributed layer\n","de_dense_time = TimeDistributed(de_dense)\n","# Get the final prediction of the model\n","de_pred = de_dense_time(de_out)\n","print(\"Prediction shape: \", de_pred.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"na4n_EypOn0o","executionInfo":{"status":"ok","timestamp":1672440618440,"user_tz":-60,"elapsed":220,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"b73ff0f2-6885-4c0a-adb0-01cea9d7496c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction shape:  (None, 20, 250)\n"]}]},{"cell_type":"markdown","source":["####**Partie 2 : définition du modèle complet**\n","\n","+ *Saviez-vous qu'il a fallu environ 6 jours et 96 GPU pour entraîner une variante du traducteur automatique neuronal de Google sur la seule tâche de traduction anglais-français ?*\n","\n","+ *Dans cet exercice, vous allez définir un modèle de traducteur automatique neuronal similaire, mais beaucoup plus simple, basé sur un encodeur-décodeur. Plus précisément, vous utiliserez les entrées et sorties définies précédemment, vous définirez un objet Modèle Keras et vous compilerez le modèle avec une fonction de perte donnée et un optimiseur.*\n","\n","+ *Vous disposez ici de en_inputs (couche d'entrée de l'encodeur), en_out et en_state (sortie GRU de l'encodeur), de_out (sortie GRU du décodeur) et de_pred (prédiction du décodeur) que vous avez définis précédemment.*\n","\n","\n","![image.png](data:image/png;base64,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)\n","\n","####**Instructions**\n","\n","+ Définissez un modèle Keras qui prend les en_inputs comme entrées et les prédictions du décodeur (de_pred) comme sortie.\n","\n","+ Compilez le modèle défini en appelant <model>.compile avec l'optimiseur 'adam', la perte d'entropie croisée et la précision (acc) comme métrique.\n","\n","+ Imprimer le résumé du modèle."],"metadata":{"id":"y_7LsXhsOzev"}},{"cell_type":"code","source":["fr_vocab =250\n","de_inputs = RepeatVector(fr_len)(en_state)\n","de_gru = GRU(hsize, return_sequences=True)\n","de_out = de_gru(de_inputs, initial_state=en_state)\n","\n","\n","en_inputs = Input(shape=(en_len, en_vocab))\n","en_gru = GRU(hsize, return_state=True)\n","en_out, en_state = en_gru(en_inputs)"],"metadata":{"id":"uwJJeoH2P-n2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["de_dense = keras.layers.Dense(fr_vocab, activation='softmax')\n","de_dense_time = keras.layers.TimeDistributed(de_dense)\n","de_pred = de_seq_dense(de_out)#print(de_pred)Tensor(\"time_distributed/Reshape_1:0\", shape=(?, 25, 250), dtype=float32)"],"metadata":{"id":"r2GTcL6oQYyu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","# Define a model with encoder input and decoder output\n","nmt = Model(inputs=en_inputs, outputs=de_pred)\n","\n","# Compile the model with an optimizer and a loss\n","nmt.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n","\n","# View the summary of the model \n","nmt.summary()"],"metadata":{"id":"oJ_-vYMS3WBw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Partie 1 : Prétraitement des données**\n","\n","\n","####**1. Partie 1 : Prétraitement des données**\n","\n","+ ***Voyons quel type de prétraitement est nécessaire avant d’alimenter le modèle en données.***\n","\n","####**2. Introduction aux données**\n","\n","+ Comme vous l’avez déjà vu, le jeu de données se compose de deux listes Python, en_text et fr_text. \n","+ en_text contient une liste de phrases anglaises, où une phrase est une chaîne unique avec des mots séparés par des espaces. \n","+ fr_text contient les traductions correspondantes des phrases anglaises. \n","+ Voici quelques phrases tirées de l’ensemble de données.\n","\n","####**3. Tokenisation de mots**\n","\n","+ L’une des premières étapes de prétraitement est la tokenisation de mots. \n","\n","+ Vous avez déjà jeté un bref coup d’œil à la tokenisation des mots dans le chapitre précédent. \n","\n","+ La tokenisation est le processus de rupture d’une phrase ou d’une phrase en jetons, par exemple des mots individuels. \n","\n","+ La tokenisation en mots individuels est connue sous le nom de tokenisation de mots. \n","\n","+ Par exemple, lorsque la phrase « J’ai regardé un film hier soir » est tokenisée, il en résulte une liste Python, où les éléments sont des mots individuels. \n","\n","+ Notez également comment la tokenisation élimine les signes de ponctuation. \n","\n","+ N’oubliez pas que jusqu’à présent, vous utilisiez un dictionnaire word2index pour convertir des mots en ID. \n","\n","+ Il sera très fastidieux de le faire manuellement, même pour un petit ensemble de données comme celui que vous utilisez. \n","\n","+ Dans Keras, vous pouvez apprendre automatiquement le mappage des mots aux ID à l’aide de l’objet Tokenizer. \n","\n","+ Il se trouve dans le sous-module de texte de point de prétraitement keras dot.\n","\n","+  Vous pouvez définir un objet tokenizer comme suit.\n","\n","####**4. Montage du tokenizer**\n","\n","+ Pour utiliser le Tokenizer, vous devez d’abord l’adapter à du texte. \n","\n","+ Cela peut être fait en utilisant la fonction fit_on_texts et en passant une liste de chaînes comme entrée. \n","\n","+ Cela permettra au tokenizer d’apprendre le mappage des mots aux ID. \n","\n","+ Ensuite, vous pouvez accéder aux ID appris par le tokenizer à l’aide de l’attribut word_index, qui est un dictionnaire Python. \n","\n","+ Vous pouvez également obtenir le mot correspondant à un ID à l’aide de l’attribut index_word.\n","\n","####**5. Transformer des phrases en séquences**\n","\n","+ Après avoir ajusté le tokenizer sur du texte, vous pouvez utiliser la fonction texts_to_sequences pour convertir une chaîne donnée en une séquence d’ID. \n","\n","+ Notez que l’entrée est une liste de chaînes et que le retour est une liste d’ID.\n","\n","####***6. Limiter la taille du vocabulaire**\n","\n","+ Mais vous ne devriez pas laisser le tokenizer tout faire automatiquement. \n","\n","+ Par exemple, si vous ne configurez pas correctement le tokenizer, il apprendra de nombreux mots rares dans le jeu de données qui ne sont pas assez puissants pour améliorer le modèle. \n","\n","+ Par conséquent, il est bon de limiter la taille du vocabulaire. \n","\n","+ Vous pouvez le faire à l’aide de l’argument num_words dans le Tokenizer. \n","\n","+ Dans cet exemple, vous définissez la taille du vocabulaire sur 50. \n","\n","+ Ensuite, le tokenizer ne prendra en compte que les 50 mots les plus courants dans votre texte lors de la conversion d’une chaîne en une séquence d’ID et ignorera les autres mots. \n","\n","+ Maintenant, comment faites-vous face aux mots hors vocabulaire ou aux mots OOV ? \n","\n","+ Ce sont des mots qui n’ont pas été coupés ou qui n’apparaissaient pas du tout dans les données fournies. \n","\n","+ Pensez à un tokenizer formé avec la phrase « J’ai bu du lait ». \n","\n","+ Pour ce tokenizer, « eau » est un mot OOV et sera ignoré si vous essayez de convertir cette phrase en séquence.\n","\n","####**7. Traitement des mots hors vocabulaire**\n","\n","+ Il existe une autre façon de traiter les mots OOV dans Keras. \n","+ Lors de la définition du Tokenizer, vous pouvez passer une chaîne à l’argument oov_token. \n","+ Cela fera que le tokenizer remplacera n’importe quel mot OOV par le jeton donné. \n","+ Par conséquent, les mots inconnus ne seront plus ignorés mais seront remplacés par un jeton spécial.\n","\n","####**8. Entraînons-nous!**\n","+ Super, maintenant que vous savez comment utiliser le Keras Tokenizer, pratiquons-le avec peu d’exercices."],"metadata":{"id":"GduhY56aUQf2"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","+ Tokeniser des phrases avec Keras\n","Ici, vous allez vous salir les mains avec le Tokenizer de Keras. \n","\n","+ Keras Tokenizer est un excellent utilitaire qui vous aide à effectuer un traitement de texte crucial avec quelques lignes de code. \n","\n","+ Par exemple, Keras Tokenizer fait automatiquement correspondre les mots de votre vocabulaire à des identifiants en un seul appel de fonction. \n","\n","+ Vous apprendrez ici ce qu'il en est plus en détail.\n","\n","+ *Vous allez créer un objet Keras Tokenizer et l'adapter à un certain texte, ce qui permettra au Tokenizer de construire un dictionnaire de mots et les identifiants correspondants. Le texte utilisé pour entraîner le Tokenizer est obtenu à partir du Repo Github d'Udacity (https://github.com/udacity/deep-learning/tree/master/language-translation/data).*\n","\n","####**Instructions**\n","\n","+ Définir un objet Keras Tokenizer.\n","\n","+ Ajuster le tokenizer sur en_text.\n","\n","+ Obtenir l'ID du mot pour chaque mot w dans la liste donnée [\"january\", \"apples\", \"summer\"].\n","\n","+ Imprimer le mot et son ID correspondant."],"metadata":{"id":"6fHg22lqWTc4"}},{"cell_type":"code","source":["# load text\n","filename = '/content/pg5200.txt'\n","file = open(filename, 'rt')\n","en_text = file.read()"],"metadata":{"id":"S-iaqAFNX5sm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","# Define a Keras Tokenizer\n","en_tok = Tokenizer()\n","\n","# Fit the tokenizer on some text\n","en_tok.fit_on_texts(en_text)\n","\n","for w in [\"january\", \"apples\", \"summer\"]:\n","  # Get the word ID of word w\n","  id = en_tok.word_index[w]\n","  # Print the word and the word ID\n","  print(w, \" has id: \", id)"],"metadata":{"id":"yWC0vD1C2M9K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Contrôler le vocabulaire avec le Tokenizer**\n","+ Approfondissons un peu plus le fonctionnement du Tokenizer. \n","\n","+ Dans cet exercice, vous apprendrez à convertir une phrase arbitraire en une séquence à l'aide d'un Tokenizer entraîné. \n","\n","+ De plus, vous apprendrez à contrôler la taille du vocabulaire du Tokenizer. Vous étudierez également ce qui arrive aux mots hors vocabulaire (OOV) lorsque vous limitez la taille du vocabulaire d'un Tokenizer.\n","\n","+ *Pour cet exercice, on vous a fourni le Tokenizer en_tok que vous avez implémenté précédemment. Le Tokenizer a été importé pour vous.*\n","\n","####**Instructions**\n","\n","+ Convertissez la phrase suivante en une séquence en utilisant le Tokenizer en_tok précédent : elle aime les pamplemousses, les pêches et les citrons.\n","\n","+ Créez un nouveau Tokenizer, en_tok_new avec une taille de vocabulaire de 50 et un mot hors vocabulaire UNK.\n","\n","+ Ajustez le nouveau tokenizer sur les données en_text.\n","\n","+ Convertir la phrase elle aime les pamplemousses, les pêches et les citrons en une séquence avec le en_tok_new."],"metadata":{"id":"EdFBNd8QXImP"}},{"cell_type":"code","source":["# Convert the sentence to a word ID sequence\n","seq = en_tok.texts_to_sequences(['she likes grapefruit , peaches , and lemons .'])\n","print('Word ID sequence: ', seq)\n","\n","# Define a tokenizer with vocabulary size 50 and oov_token 'UNK'\n","en_tok_new = Tokenizer(num_words=50, oov_token='UNK')\n","\n","# Fit the tokenizer on en_text\n","en_tok_new.fit_on_texts(en_text)\n","\n","# Convert the sentence to a word ID sequence\n","seq_new = en_tok_new.texts_to_sequences(['she likes grapefruit , peaches , and lemons .'])\n","print('Word ID sequence (with UNK): ', seq_new)\n","print('The ID 1 represents the word: ', en_tok_new.index_word[1])"],"metadata":{"id":"A6nFWt476BZa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Partie 2 : Prétraitement du texte**\n","\n","####**1. Partie 2 : Prétraitement du texte**\n","\n","+ *Dans cette leçon, vous découvrirez quelques autres techniques de prétraitement qui doivent être effectuées avant d’alimenter le modèle de traduction automatique en données.*\n","\n","####**2. Ajout de jetons de début / fin spéciaux**\n","+ Vous allez d’abord ajouter un jeton spécial de début et de fin aux phrases de la langue cible. \n","\n","+ Vous pouvez utiliser sos pour indiquer le début d’une phrase Français et eos pour marquer la fin de la phrase. \n","\n","+ Cette étape n’est pas essentielle au modèle actuel que vous avez. \n","\n","+ Mais il sera utile pour un modèle amélioré que vous allez implémenter dans le dernier chapitre.\n","\n","####**3. Remplissage des phrases**\n","\n","+ Jusqu’à présent, toutes les phrases avec lesquelles vous avez travaillé avaient une longueur fixe, c’est-à-dire un nombre fixe de mots. \n","\n","+ Cependant, dans les ensembles de données du monde réel, ce n’est jamais le cas. Une méthode courante pour y faire face consiste à remplir les phrases avec un jeton spécial afin qu’elles aient toutes la même longueur. \n","\n","+ Cela signifie également que les phrases plus longues que la longueur spécifiée seront tronquées. \n","\n","+ Pour ce faire, Keras fournit **la fonction pad_sequences trouvée dans le sous-module de séquence de points de prétraitement de points keras**. \n","\n","+ Comprenons cette fonction à travers un exemple. \n","\n","+ Convertissons d’abord les phrases en une liste de séquences à l’aide de **la fonction texts_to_sequences et enregistrons le résultat dans des séquences**. \n","\n","+ Cela sera utilisé dans la diapositive suivante.\n","\n","####**4. Remplissage des phrases**\n","\n","+ Pour amener ces phrases à la même longueur, vous pouvez appeler **pad_sequences fonction**. \n","\n","+ Lorsque vous appelez pad_sequences fonction, vous devez définir trois arguments importants. \n","\n","+ Le premier argument, **« padding », qui peut être « pre » ou « post », détermine si vous souhaitez remplir le début ou la fin des phrases.** \n","\n","+ Ensuite, **« troncating », qui peut être « pre » ou « post », définit le style de troncation**. \n","\n","+ Enfin, **« maxlen » définit la longueur pour laquelle vous souhaitez pader**. \n","\n","+ Dans notre exemple, nous demandons à la fonction de tamponner à la fin ou de tronquer à partir de l’extrémité de sorte que la longueur finale soit de 12. \n","\n","+ La première séquence, puisqu’elle n’a pas 12 mots, a des 0 ajoutés à la fin. \n","\n","+ La dernière phrase de plus de 12 mots a été tronquée. \n","\n","+ Le tokenizer n’attribuera jamais zéro comme ID de mot, car il est utilisé à des fins spéciales comme les séquences de rembourrage.\n","\n","####**5. Avantage de l’inversion des peines**\n","\n","+ Une autre technique de prétraitement consiste à inverser l’ordre des mots des phrases sources. \n","\n","+ Par exemple, la phrase anglaise « we like dogs » est alimentée comme « dogs like we » lors de l’alimentation de l’encodeur. \n","\n","+ C’est mieux car cela aide à établir une connexion forte entre l’encodeur et le décodeur. \n","\n","+ Lorsque la phrase source est inversée, les mots initiaux des deux langues sont les plus proches l’un de l’autre. \n","\n","+ Par exemple, les mots « nous » et « nous » font référence à la même chose, ce qui contribue au processus d’optimisation du modèle. \n","\n","+ Mais contrairement aux étapes précédentes, il s’agit d’une opération dépendante de la langue, car dans certaines langues, le sujet n’apparaîtra pas comme le premier mot.\n","\n","####**6. Inversion des phrases**\n","\n","+ Pour commencer, convertissons à nouveau les phrases en séquences rembourrées. \n","+ **pad_sequences** renverra un tableau de formes nombre de phrases par longueur de séquence.\n","\n","####**7. Inversion des phrases**\n","\n","+ Par conséquent, la dimension temporelle est le deuxième axe. \n","\n","+ Lors de l’inversion des phrases, le premier axe reste le même que celui indiqué par les deux-points avant la virgule. \n","\n","+ Pour inverser le deuxième axe, passez deux-points -1 pour cette dimension. \n","\n","+ Lorsque vous inversez le texte de l’encodeur, vous devez également faire attention au type de remplissage que vous utilisez. \n","\n","+ Par exemple, il est souhaitable de pré-tamponner le texte de l’encodeur avec des zéros car cela aidera à établir une connexion forte avec le décodeur. \n","\n","+ Vous pouvez corriger la troncation en tant que « post », quelle que soit l’étape inverse. \n","\n","+ Puisque vous inversez les phrases par la suite, vous devez utiliser le post-remplissage, car il devient un pré-remplissage après avoir inversé le texte.\n","\n","####**8. Entraînons-nous!**\n","+ Maintenant, vous connaissez toutes les techniques de prétraitement requises. Mettons en pratique certaines de ces techniques."],"metadata":{"id":"J30L_-1ZVLFk"}},{"cell_type":"markdown","source":["###**EXERCICES**\n","\n","####**Ajouter des marqueurs spéciaux**\n","\n","+ *Vous allez maintenant apprendre à ajouter des jetons sos (marque le début) et eos (marque la fin) aux phrases. Comme nous l'avons déjà dit, cette étape est facultative pour le modèle que vous avez actuellement, mais elle sera nécessaire pour un modèle que vous implémenterez dans un chapitre ultérieur.*\n","\n","+ *Pour ajouter ces tokens spéciaux, vous utiliserez la fonction Python ***string.join()****. \n","\n","+ ***string.join()*** joint une liste de chaînes de caractères à une seule chaîne en utilisant un délimiteur. \n","\n","+ Par exemple, si vous voulez convertir ['datacamp', 'is', 'awesome'] en 'datacamp is awesome', vous pouvez utiliser \" \".join(['datacamp', 'is', 'awesome']), où le \" \" (c'est-à-dire le caractère espace) est le délimiteur.\n","\n","+ *Pour cet exercice, un petit échantillon de 10 phrases françaises a déjà été importé.*\n","\n","####**Instructions**\n","\n","+ Bouclez à travers la liste de phrases françaises (fr_text).\n","+ Ajoutez un jeton \"sos\" pour indiquer le début et un jeton \"eos\" pour indiquer la fin de chaque phrase en utilisant la fonction string.join().\n","+ Ajoutez la phrase modifiée à fr_text_new.\n","+ Imprimez la phrase modifiée sent_new.\n","\n"],"metadata":{"id":"c7gcpGoVWYBK"}},{"cell_type":"code","source":["fr_text_new = []\n","\n","# Loop through all sentences in fr_text\n","for sent in fr_text:\n","  \n","  print(\"Before adding tokens: \", sent)\n","  \n","  # Add sos and eos tokens using string.join\n","  sent_new =  \" \".join(['sos', sent, 'eos'])\n","  # Append the modified sentence to fr_text_new\n","  fr_text_new.append(sent_new)\n","  \n","  # Print sentence after adding tokens\n","  print(\"After adding tokens: \", sent_new, '\\n')"],"metadata":{"id":"Q2bc4iph2NBg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Rembourrage de phrases**\n","\n","+ ***Vous allez maintenant implémenter une fonction appelée sents2seqs() que vous utiliserez plus tard pour transformer commodément les données au format accepté par le modèle de traduction automatique neuronale (NMT). sents2seqs() accepte une liste de chaînes de phrases et***,\n","\n","  + convertit les phrases en une liste de séquences d'identifiants,\n","  + Rembourre les phrases pour qu'elles aient une longueur égale et,\n","  + convertit optionnellement les IDs en vecteurs onehot.\n","\n","+ On vous a fourni en_tok, un Tokenizer déjà entraîné sur des données. \n","\n","+ Une autre chose à noter est que lors de l'implémentation de **la fonction sents2seqs()**, vous verrez un argument inutilisé appelé **input_type**. \n","\n","+ Plus tard, ce type d'entrée sera utilisé pour changer les paramètres dépendant de la langue tels que la longueur de la séquence et la taille du vocabulaire.\n","\n","####**Instructions**\n","\n","+ Convertir les phrases en séquences en utilisant le Tokenizer en_tok.\n","\n","+ Remplir les séquences à une longueur fixe en_len avec un type de remplissage spécifié de pad_type et utiliser la post-troncature.\n","\n","+ Convertir les IDs des mots de preproc_text en vecteurs onehot de longueur en_vocab en utilisant la fonction to_categorical().\n","\n","+ Convertir la phrase en une séquence paddée en utilisant la méthode sents2seqs() en utilisant le pré-padding.\n"],"metadata":{"id":"8kEI_kt3XtTg"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","def sents2seqs(input_type, sentences, onehot=False, pad_type='post'):\n","\t# Convert sentences to sequences      \n","    encoded_text = en_tok.texts_to_sequences(sentences)\n","    # Pad sentences to en_len\n","    preproc_text = pad_sequences(encoded_text, padding=pad_type, truncating='post', maxlen=en_len)\n","    if onehot:\n","\t\t# Convert the word IDs to onehot vectors\n","        preproc_text = to_categorical(preproc_text, num_classes=en_vocab)\n","    return preproc_text\n","sentence = 'she likes grapefruit , peaches , and lemons .'  \n","# Convert a sentence to sequence by pre-padding the sentence\n","pad_seq = sents2seqs('source', [sentence], pad_type='pre')"],"metadata":{"id":"d5QmDY0bkvSy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Inversion de phrases**\n","+ Vous apprendrez ici comment inverser des phrases pour le modèle d'encodeur. \n","\n","+ Comme nous l'avons vu, l'inversion des phrases sources permet de créer une connexion initiale forte entre l'encodeur et le décodeur, ce qui améliore les performances du modèle. \n","\n","+ Cependant, n'oubliez jamais que cet avantage dépend des deux langues entre lesquelles vous traduisez. \n","\n","+ Tant que l'ordre du sujet, du verbe et de l'objet est le même, le modèle en bénéficiera.\n","\n","+ ***Dans cet exercice, vous allez modifier la fonction sents2seqs() pour pouvoir inverser les phrases si nécessaire. L'utilisateur peut spécifier un argument de mot-clé booléen reverse qui permet d'inverser le texte.***\n","\n","####**Instructions**\n","\n","+ Ecrivez la signature de la fonction sents2seqs() en ajoutant un nouvel argument mot-clé reverse qui a la valeur par défaut False.\n","\n","+ Inversez les ID des séquences retournées sur la dimension temporelle (en utilisant la syntaxe ::-1), de sorte que le premier ID de mot devienne le dernier.\n","\n","+ Appelez sents2seqs() et inversez les phrases données et gardez toutes les autres valeurs des paramètres par défaut inchangées.\n","\n"],"metadata":{"id":"360V8V1HYm0m"}},{"cell_type":"code","source":["sentences = [\"california is never rainy during july .\"]\n","# Add new keyword parameter reverse which defaults to False\n","def sents2seqs(input_type, sentences, onehot=False, pad_type='post', reverse=False):     \n","    encoded_text = en_tok.texts_to_sequences(sentences)\n","    preproc_text = pad_sequences(encoded_text, padding=pad_type, truncating='post', maxlen=en_len)\n","    if reverse:\n","      # Reverse the text using numpy axis reversing\n","      preproc_text = preproc_text[:,::-1]\n","    if onehot:\n","        preproc_text = to_categorical(preproc_text, num_classes=en_vocab)\n","    return preproc_text\n","# Call sents2seqs to get the padded and reversed sequence of IDs\n","pad_seq = sents2seqs('source', sentences, reverse=True)\n","rev_sent = [en_tok.index_word[wid] for wid in pad_seq[0][-6:]] \n","print('\\tReversed: ',' '.join(rev_sent))"],"metadata":{"id":"JRfYccbdY4Tw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Formation du modèle NMT**\n","\n","####**1. Formation du modèle NMT**\n","Vous allez maintenant apprendre à former le modèle.\n","\n","####**2. Revisiter le modèle**\n","\n","+ Jusqu’à présent, vous avez un modèle de traducteur automatique neuronal basé sur un décodeur d’encodeur qui a un GRU d’encodeur qui consomme des mots anglais et génère un vecteur de contexte. \n","\n","+ Ensuite, vous avez un décodeur GRU qui consomme le vecteur de contexte et génère une séquence de sorties GRU. \n","\n","+ Enfin, vous avez une couche de prédiction de décodeur qui génère les probabilités de prédiction.\n","\n","####**3. Optimisation des paramètres**\n","\n","+ Lorsque vous implémentez un modèle Keras, il a des paramètres. \n","\n","+ Par exemple, toutes les couches GRU et les couches denses ont des paramètres. \n","\n","+ Ces paramètres sont connus sous le nom de poids et de biais, ce que nous avons vu en discutant de la couche dense. \n","\n","+ Ils sont responsables de la conversion des entrées en une sortie utile. \n","\n","+ Par exemple, convertir les mots anglais codés onehot en distributions probabilistes d’une séquence de mots Français. \n","\n","+ Généralement, ces paramètres sont initialisés de manière aléatoire. Pour rendre ces paramètres utiles, vous devez les former. \n","\n","+ Au cours de laquelle, ces paramètres seront modifiés pour produire des extrants significatifs. \n","\n","\n","+ Pour entraîner correctement le modèle, vous devez définir une fonction de perte et un optimiseur à l’aide de la fonction de compilation. \n","\n","+ L’optimiseur calculera la perte sur les données d’apprentissage. La perte est calculée en générant d’abord des prévisions avec les intrants, puis en mesurant la différence entre les prévisions et les extrants ou cibles réels. \n","\n","+ Enfin, les paramètres sont modifiés de manière à minimiser la perte calculée.\n","\n","####**4. Formation du modèle**\n","\n","+ Pour former le modèle, vous parcourez le jeu de données d’apprentissage par lots. Un seul lot est appelé itération unique. \n","\n","+ Un seul passage à travers tous les lots est appelé une seule époque. \n","\n","+ Ensuite, vous effectuez plusieurs époques sur le jeu de données d’apprentissage. \n","\n","+ Ensuite, à chaque itération, vous obtenez un lot d’entrées et un lot de sorties à l’aide de **la fonction sents2seqs**. \n","\n","+ Notez comment vous spécifiez différents attributs spécifiques à la langue, tels que le tokenizer. \n","\n","+ Cela se fait en utilisant le premier argument, qui peut être « source » ou « cible ». \n","\n","+ Et vous allez inverser le texte de l’encodeur. \n","\n","+ Ensuite, appelez **la fonction train_on_batch **avec le lot d’entrées et de cibles pour former le modèle. \n","\n","+ Enfin, vous pouvez évaluer le modèle en appelant la fonction d’évaluation et obtenir les métriques.\n","\n","+  L’appel d’évaluation donnera lieu à deux mesures : **la perte et l’exactitude**.\n","\n","####**5. Formation du modèle**\n","+ RES sera un tuple avec le premier élément étant la perte et le second étant la précision. \n","\n","+ La précision est calculée comme le nombre total d’échantillons correctement classés divisé par le nombre total d’échantillons multiplié par 100. Rappelez-vous que chaque époque a plusieurs itérations.\n","\n","####**6. Éviter le surajustement**\n","+ Cependant, dans la pratique, vous devez utiliser deux jeux de données. \n","\n","+ Un ensemble d’entraînement pour entraîner le modèle et un ensemble de validation pour surveiller la précision. \n","\n","+ Avec ce mécanisme, vous pouvez arrêter la formation lorsque la précision de validation cesse d’augmenter et éviter le surajustement.\n","\n","####**7. Fractionnement de l’ensemble de données**\n","\n","\n","+ Considérons un ensemble de données de 1000 phrases et divisons-le en 800 échantillons d’apprentissage et 200 échantillons de validation. \n","\n","+ Vous pouvez utiliser la lecture aléatoire pour vous assurer que vous ne biaisez pas les jeux de données. \n","\n","+ Vous pouvez ensuite obtenir les 800 premiers indices en tant qu’indices d’apprentissage et les 200 derniers en tant qu’indices de validation.\n","\n","####**8. Fractionnement de l’ensemble de données**\n","+ Vous divisez ensuite les données en données d’apprentissage et de validation par obtenir les données correspondant aux indices d’entraînement en tant que données d’apprentissage, c’est-à-dire tr_en et tr_fr, et les indices valides en tant que données de validation, v_en et v_fr.\n","\n","####**9. Formation du modèle avec validation**\n","+ Lors de l’entraînement du modèle avec une étape de validation, le bit d’apprentissage reste le même. \n","\n","+ Ensuite, à chaque époque, vous évaluerez le modèle sur un jeu de données de validation qui est v_en_x et v_de_y. \n","\n","+ v_en_x et v_de_y doit être préparé en utilisant les mêmes transformations utilisées pour en_x et de_y. \n","\n","+ Ensuite, vous utilisez la fonction d’évaluation pour obtenir res, qui contient la perte et la précision sur le jeu de données de validation. Puisque vous utilisez un petit jeu de validation, définissons la batch_size sur la taille du jeu de validation.\n","\n","####**10. Entraînons-nous!**\n","+ Vous savez maintenant comment entraîner votre modèle et gardez un œil sur le surajustement. Entraînons-nous!"],"metadata":{"id":"RFgtqgLxZQAB"}},{"cell_type":"markdown","source":["####**Entraînement du modèle**\n","+ Dans cet exercice, vous allez entraîner le modèle précédemment implémenté. \n","\n","+ Savez-vous que l'entraînement du modèle de traduction automatique de Google basé sur un encodeur-décodeur a pris 2 à 4 jours ?\n","\n","+ Pour cet exercice, vous utiliserez un petit ensemble de données de 1500 phrases (c'est-à-dire en_text et fr_text) pour entraîner le modèle. \n","\n","+ Cette quantité sera à peine suffisante pour voir de bonnes performances, mais la méthode restera la même. \n","\n","+ Il s'agit de s'entraîner sur plus de données et plus longtemps. \n","\n","+ On vous a également fourni le modèle nmt, et **la fonction sents2seqs()** que vous avez implémentée précédemment. \n","\n","+ Vous allez inverser le texte de l'encodeur pour obtenir de meilleures performances dans cet exercice.\n","\n","####**Instructions**\n","\n","+ Obtenez un lot unique d'entrées d'encodeur (phrases anglaises de l'index i à i+bsize) en utilisant la fonction sents2seqs(). \n","\n","+ Les entrées doivent être inversées et codées en une seule fois.\n","\n","\n","+ Obtenez un lot unique de sorties de décodeur (phrases françaises de l'index i à i+bsize) en utilisant la fonction sents2seqs(). \n","\n","+ Les entrées doivent être codées en une seule fois.\n","\n","\n","+ Entraîner le modèle sur un lot unique de données contenant en_x et de_y.\n","\n","\n","+ Obtenez les métriques d'évaluation pour en_x et de_y en évaluant le modèle avec une taille de lot de bsize."],"metadata":{"id":"s6fbWNcYobJc"}},{"cell_type":"code","source":["n_epochs, bsize = 3, 250\n","data_size = 1500\n","for ei in range(n_epochs):\n","  for i in range(0,data_size,bsize):\n","    # Get a single batch of encoder inputs\n","    en_x = sents2seqs('source', en_text[i:i+bsize], onehot=True, reverse=True)\n","    # Get a single batch of decoder outputs\n","    de_y = sents2seqs('target', fr_text[i:i+bsize], onehot=True)\n","    \n","    # Train the model on a single batch of data\n","    nmt.train_on_batch(en_x, de_y)    \n","    # Obtain the eval metrics for the training data\n","    res = nmt.evaluate(en_x, de_y, batch_size=bsize, verbose=0)\n","    print(\"{} => Train Loss:{}, Train Acc: {}\".format(ei+1,res[0], res[1]*100.0))  "],"metadata":{"id":"TJrW_TixY4XK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Division des données en ensembles de formation et de validation**\n","\n","+ Vous avez appris que l'utilisation des seules données d'apprentissage sans ensemble de données de validation entraîne un problème appelé surajustement. \n","\n","+ Lorsque l'adaptation excessive se produit, le modèle est très bon pour prédire les données d'apprentissage, mais il se généralise très mal aux données non vues. \n","\n","+ Cela signifie que le modèle ne sera pas très utile, car il ne peut pas se généraliser. \n","\n","+ Pour éviter cela, vous pouvez utiliser un ensemble de données de validation.\n","\n","+ Dans cet exercice, vous allez créer un ensemble de données d'entraînement et de validation à partir de l'ensemble de données dont vous disposez (c'est-à-dire en_text contenant 1000 phrases anglaises et fr_text contenant les 1000 phrases françaises). \n","\n","+ Vous utiliserez 80 % de l'ensemble de données pour l'entraînement et 20 % comme données de validation.\n","\n","####**Instructions**\n","\n","+ Définissez une séquence d'indices en utilisant np.arange(), qui commence par 0 et a une taille de en_text.\n","+ Définissez valid_inds comme les derniers indices de taille valide de la séquence d'indices.\n","+ Définir tr_en et tf_fr, qui contiennent les phrases trouvées aux indices train_inds, dans les listes en_text et fr_text.\n","+ Définir v_en et v_fr qui contiennent les phrases trouvées dans les indices valid_inds, dans les listes en_text et fr_text."],"metadata":{"id":"IwWLDBD9pY4N"}},{"cell_type":"code","source":["train_size, valid_size = 800, 200\n","# Define a sequence of indices from 0 to len(en_text)\n","inds = np.arange(len(en_text))\n","np.random.shuffle(inds)\n","train_inds = inds[:train_size]\n","# Define valid_inds: last valid_size indices\n","valid_inds = inds[train_size:train_size+valid_size]\n","# Define tr_en (train EN sentences) and tr_fr (train FR sentences)\n","tr_en = [en_text[ti] for ti in train_inds]\n","tr_fr = [fr_text[ti] for ti in train_inds]\n","# Define v_en (valid EN sentences) and v_fr (valid FR sentences)\n","v_en = [en_text[vi] for vi in valid_inds]\n","v_fr = [fr_text[vi] for vi in valid_inds]\n","print('Training (EN):\\n', tr_en[:3], '\\nTraining (FR):\\n', tr_fr[:3])\n","print('\\nValid (EN):\\n', v_en[:3], '\\nValid (FR):\\n', v_fr[:3])"],"metadata":{"id":"QsEwZtvpY4bk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Formation du modèle avec validation**\n","\n","+ Vous apprendrez ici comment former le modèle de traduction par machine neuronale avec une étape de validation.\n","\n","+ Le modèle nmt que vous avez créé dans le dernier chapitre vous est fourni. \n","\n","+ En outre, vous entraînerez le modèle sur des phrases anglaises et françaises obtenues à partir du Repo Github d'Udacity. \n","\n","+ Vous disposez du texte anglais (tr_en) et du texte français (tf_fr) d'entraînement ainsi que du texte anglais (v_en) et du texte français (v_fr) de validation de l'exercice précédent.\n","\n","+ *L'entraînement du modèle prend un peu de temps, votre code prendra donc un peu plus de temps à s'exécuter.*\n","\n","####**Instructions**\n","\n","+ Créer des données de validation en transformant v_en et v_fr en utilisant la fonction sents2seqs.\n","+ Obtenez un lot correctement transformé d'entrées et de sorties en utilisant la fonction sents2seqs.\n","+ Utilisez les entrées (en_x) et les sorties (de_y) pour entraîner le nmt sur un seul lot.\n","+ Utilisez v_en_x et v_de_y avec valid_size comme batch_size pour évaluer le modèle nmt et obtenir la précision de validation."],"metadata":{"id":"08HJ-ICtp4tF"}},{"cell_type":"code","source":["# Convert validation data to onehot\n","v_en_x = sents2seqs('source', v_en, onehot=True, reverse=True)\n","v_de_y = sents2seqs('target', v_fr, onehot=True)\n","\n","n_epochs, bsize = 3, 250\n","for ei in range(n_epochs):\n","  for i in range(0,train_size,bsize):\n","    # Get a single batch of inputs and outputs\n","    en_x = sents2seqs('source', tr_en[i:i+bsize], onehot=True, reverse=True)\n","    de_y = sents2seqs('target', tr_fr[i:i+bsize], onehot=True)\n","    # Train the model on a single batch of data\n","    nmt.train_on_batch(en_x, de_y)    \n","  # Evaluate the trained model on the validation data\n","  res = nmt.evaluate(v_en_x, v_de_y, batch_size=valid_size, verbose=0)\n","  print(\"{} => Loss:{}, Val Acc: {}\".format(ei+1,res[0], res[1]*100.0))"],"metadata":{"id":"2Dt89lL_rB3Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Générer des traductions avec le NMT**\n","\n","####**1. Générer des traductions avec le NMT**\n","+ Dans cette leçon, vous allez générer des traductions à partir du modèle formé dans les exercices précédents.\n","\n","####**2. Motivation**\n","+ Vous avez un modèle qui a été formé et validé, mais comment vous assurez-vous qu’il peut fonctionner comme un traducteur quotidien utile et traduire des phrases anglaises inédites en Français? \n","\n","+ Le meilleur moyen serait de présenter un ensemble de test en plus du train et des données de validation et de mesurer la précision de cet ensemble. \n","\n","+ Ici, vous testerez le modèle uniquement sur une seule phrase de test et l’inspecterez visuellement.\n","\n","####**3. Transformer l’intrant**\n","\n","+ Prenons cette phrase comme exemple. \n","\n","+ La première chose que vous devrez faire est d’appliquer exactement la même transformation à la phrase source que vous avez appliquée pendant la formation. \n","\n","+ C’est-à-dire que vous convertirez des phrases anglaises en entrées codées onehot inversées. \n","\n","+ Vous pouvez ensuite imprimer les mots ID et faire une vérification rapide de la santé mentale. \n","\n","+ Le tokenizer Keras applique les ID de mots en fonction de leur fréquence dans le texte. \n","\n","+ Par conséquent, des mots plus fréquents comme « it », « the », « is » auront des identifiants plus petits. \n","\n","+ Si vous regardez les positions auxquelles ces petits ID de mots apparaissent, ils s’alignent sur les positions des mots dans la phrase anglaise inversée.\n","\n","####**4. Génération de la traduction**\n","+ Une fois la phrase anglaise convertie en séquence codée onehot, vous pouvez utiliser la fonction model dot predict pour obtenir la traduction Français. \n","\n","+ Cependant, comme vous l’avez vu précédemment, la sortie du modèle sera une distribution de probabilité sur Français vocabulaire pour chaque position de décodeur. \n","\n","+ Par conséquent, pour obtenir les ID de Français mot, vous devrez utiliser la fonction np dot argmax sur le dernier axe de fr_pred, ce qui donnera la séquence d’ID.\n","\n","####**5. Conversion de la prédiction en phrase**\n","+ Pour convertir les ID de séquence en mots réels, vous pouvez utiliser la compréhension de liste. \n","\n","+ Comme vous pouvez le voir, cela ressemble à une ligne de code complexe. Cependant, tout ce qu’il fait est de prendre tous les identifiants dans fr_seq qui ne sont pas des zéros et de convertir chaque ID en un mot en utilisant l’attribut index_word du tokenizer. \n","\n","+ Ne vous inquiétez pas si vous n’avez pas bien compris. Nous en discuterons en détail. \n","\n","+ Jetons d’abord un coup d’œil aux traductions produites par notre modèle. \n","\n","+ C’est ce que le modèle a produit comme traduction. \n","\n","+ Il s’agit d’un modèle qui a été formé sur 100 000 phrases et validé à l’aide de plus de 35 000 phrases. \n","\n","+ Ce modèle a atteint une précision d’environ 90% sur le jeu de validation. \n","\n","+ Si vous comparez cela à ce que Google translate produit, cela ressemble beaucoup.\n","\n","####**6. Énumérez la compréhension plus en détail**\n","+ Examinons maintenant la compréhension de la liste plus en détail. \n","\n","+ La compréhension de liste est une alternative à l’utilisation de boucles for et est en fait plus efficace que l’utilisation de boucles for. \n","\n","+ C’est ce que vous utilisez pour obtenir les peines. \n","\n","+ Ce qu’il fait peut être divisé en plusieurs lignes de code comme suit. \n","\n","+ Il passe en revue toutes les séquences dans les ID de mots Français et si l’ID n’est pas zéro, l’ID est converti en un mot à l’aide de l’attribut index_word du Tokenizer et ajouté à une liste.\n","\n","####**7. Entraînons-nous!**\n","+ Jusqu’à présent, vous avez appris à former un modèle de traduction automatique et à valider le modèle. \n","\n","+ Vous savez maintenant comment utiliser le modèle formé et générer des traductions. Entraînons-nous!"],"metadata":{"id":"ciRi7ALLrTD1"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Partie 1 : Chasse au trésor**\n","\n","+ Vous avez récemment gagné un voyage tous frais payés sur une île tropicale luxuriante. \n","\n","+ En vous baladant, vous avez trouvé une ancienne carte au trésor indiquant un grand trésor, qui contenait quelques messages secrets écrits à l'aide de 1 et de 0. \n","\n","+ Comme vous venez de suivre ce cours, vous reconnaissez instantanément qu'il s'agit d'une séquence de vecteurs codés en onehot. \n","\n","+ Vous avez également eu la chance de trouver la correspondance entre le mot et l'index pour savoir quel mot fait référence à quel ID.\n","\n","+ Vous devez maintenant décrypter le message secret et découvrir ce que dit cette carte. \n","\n","+ On vous a fourni une carte au trésor qui est une matrice de nombre de phrases par nombre de mots par longueur de vecteur unique. \n","\n","+ On vous a également fourni le dictionnaire Python index2word qui associe un ID à un mot.\n","\n","####**Instructions**\n","\n","+ Obtenir les ID des mots pour les vecteurs codés onehot dans la carte du trésor (la dimension du vecteur onehot est la dernière dimension).\n","\n","+ Obtenir la longueur de la séquence (c'est-à-dire le nombre de pas de temps) à partir de treasure_map et l'affecter à seq_len.\n","+ Obtenir l'ID du mot dans la i-ème phrase à la t-ème position.\n","+ Ajouter le mot String (c'est-à-dire pas l'ID du mot) correspondant à wid à la liste words."],"metadata":{"id":"5E0s1X8KsSlj"}},{"cell_type":"code","source":["treasure_map = np.array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n","\n","       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","\n","       [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"],"metadata":{"id":"M-u1KzdCs6bk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index2word= {0: 'PAD',\n"," 1: 'go',\n"," 2: 'to',\n"," 3: 'the',\n"," 4: 'cave',\n"," 5: 'find',\n"," 6: 'stone',\n"," 7: 'dragon',\n"," 8: 'push',\n"," 9: 'head',\n"," 10: 'down'}"],"metadata":{"id":"i0ujZD6xrB6e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the word IDs from the treasure map\n","word_ids = np.argmax(treasure_map, axis=-1)\n","# Get the sequence length from the treasure map\n","seq_len = treasure_map.shape[1]\n","\n","for i in range(treasure_map.shape[0]):\n","\twords = []\n","\tfor t in range(seq_len):\n","      \t# Get the word ID for the i-th sentence and t-th position\n","\t    wid = word_ids[i,t]\n","      if wid != 0:\n","        # Append the word corresponding to wid\n","        words.append(index2word[wid])\n","  print(\"Instruction \", i+1, \": \", ' '.join(words))"],"metadata":{"id":"zxBW8f1bpksj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Partie 2 : Chasse au trésor**\n","+ La chasse au trésor est un peu plus complexe. \n","\n","+ Vous avez oublié d'emporter votre ordinateur portable et vous n'avez sur vous qu'un appareil à la mémoire limitée. \n","\n","+ Le code que vous écrivez doit comporter moins de 4 lignes de code (sans compter les commentaires). \n","\n","+ Comme vous devez rendre le code aussi compact que possible, vous utiliserez la compréhension de liste.\n","\n","+ La compréhension de liste est un excellent moyen de boucler des données avec une seule ligne de code. \n","\n","+ Par exemple, si vous voulez obtenir tous les nombres pairs d'une liste de nombres, vous pouvez faire \n","\n","      [n for n in range(100) if n%2==0]. \n","\n","+ Comme vous pouvez le constater, la compréhension de liste vous permet de combiner des boucles for et des instructions if en une seule ligne de code.\n","\n","####**Instructions**\n","\n","+ Obtenez les IDs des mots pour les vecteurs codés en onehot dans le treasure_map.\n","+ Obtenez la taille du lot (la toute première dimension) de la carte au trésor et utilisez-la pour créer une boucle for.\n","+ Obtenez les mots de la i-ème phrase en itérant la i-ème ligne de word_ids tout en ignorant les word IDs égaux à zéro.\n","\n"],"metadata":{"id":"sjaRXVYXtOBm"}},{"cell_type":"code","source":["# Get the word IDs from the treasure map\n","word_ids = np.argmax(treasure_map, axis=-1)\n","# Get the batch size from the treasure map\n","for i in range(treasure_map.shape[0]):\n","  \t# Get all the words of the i-th sentence using list comprehension\n","\twords = [index2word[wid] for wid in word_ids[i] if wid != 0]\n","\tprint(\"Instruction \", i+1, \": \", ' '.join(words))"],"metadata":{"id":"DycBrtarpkvx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Générer des traductions anglais-français**\n","+ Saviez-vous que la banque HSBC a un jour dépensé 10 millions de dollars pour refaire son slogan, à cause d'une erreur de traduction ?\n","\n","+ Nous allons utiliser le modèle entraîné pour prédire la traduction française d'une phrase anglaise en utilisant model.predict(). \n","\n","+ Le modèle entraîné (model) vous est fourni. \n","\n","+ Ce modèle a été entraîné pendant 50 époques sur 100 000 phrases et a atteint une précision d'environ 90 % sur un ensemble de validation de plus de 35 000 mots. \n","\n","+ Le chargement de cet exercice peut prendre plus de temps car le modèle entraîné est chargé avant l'exercice. \n","\n","+ En outre, un dictionnaire (fr_id2word) vous sera fourni, que vous pourrez utiliser pour convertir les indices de mots en mots. \n","\n","+ Enfin, vous utiliserez la fonction sents2seqs que vous avez implémentée précédemment pour prétraiter les données avant de les introduire dans le modèle.\n","\n","+ Vous pouvez utiliser help(sents2seqs) pour vous rappeler ce qui est accepté par la fonction sents2seqs().\n","\n","####**Instructions**\n","\n","+ Prétraitez la source en_st afin qu'elle soit convertie en un tableau numpy encodé onehot en utilisant la fonction sents2seqs définie précédemment.\n","\n","\n","+ Prédire la sortie de fr_seq en utilisant le modèle entraîné fourni.\n","\n","\n","+ Extraire l'indice maximum pour chaque prédiction de fr_pred en utilisant np.argmax et l'affecter à fr_seq.\n","\n","\n","+ Convertir les ID de séquences françaises en une phrase en utilisant la compréhension de liste (n'oubliez pas d'ignorer les 0) et l'affecter à fr_sent."],"metadata":{"id":"Z4oltcOLt3vb"}},{"cell_type":"code","source":["fr_id2word= {1: 'UNK',\n"," 2: 'est',\n"," 3: 'sos',\n"," 4: 'eos',\n"," 5: 'en',\n"," 6: 'il',\n"," 7: 'les',\n"," 8: 'mais',\n"," 9: 'et',\n"," 10: 'la',\n"," 11: 'parfois',\n"," 12: 'jamais',\n"," 13: 'le',\n"," 14: \"l'\",\n"," 15: 'généralement',\n"," 16: 'moins',\n"," 17: 'aimé',\n"," 18: 'au',\n"," 19: 'fruit',\n"," 20: 'préféré',\n"," 21: 'agréable',\n"," 22: 'froid',\n"," 23: 'son',\n"," 24: 'chaud',\n"," 25: 'de',\n"," 26: 'plus',\n"," 27: 'automne',\n"," 28: 'mois',\n"," 29: 'à',\n"," 30: 'elle',\n"," 31: 'citrons',\n"," 32: 'paris',\n"," 33: 'inde',\n"," 34: 'unis',\n"," 35: 'états',\n"," 36: 'france',\n"," 37: 'jersey',\n"," 38: 'new',\n"," 39: 'chine',\n"," 40: 'pendant',\n"," 41: 'pamplemousse',\n"," 42: 'mon',\n"," 43: 'votre',\n"," 44: 'juin',\n"," 45: 'hiver',\n"," 46: 'printemps',\n"," 47: 'mars',\n"," 48: 'janvier',\n"," 49: 'septembre',\n"," 50: 'février',\n"," 51: 'mai',\n"," 52: 'décembre',\n"," 53: 'été',\n"," 54: 'juillet',\n"," 55: 'novembre',\n"," 56: 'avril',\n"," 57: 'aime',\n"," 58: 'octobre',\n"," 59: 'août',\n"," 60: 'merveilleux',\n"," 61: 'relaxant',\n"," 62: 'humide',\n"," 63: 'doux',\n"," 64: 'notre',\n"," 65: 'californie',\n"," 66: 'sec',\n"," 67: 'leur',\n"," 68: 'pluvieux',\n"," 69: 'occupé',\n"," 70: 'calme',\n"," 71: 'beau',\n"," 72: 'habituellement',\n"," 73: 'oranges',\n"," 74: 'pêches',\n"," 75: 'fraises',\n"," 76: 'bananes',\n"," 77: 'poires',\n"," 78: 'raisins',\n"," 79: 'pommes',\n"," 80: 'mangues',\n"," 81: 'verts',\n"," 82: \"d'\",\n"," 83: 'raisin',\n"," 84: 'pomme',\n"," 85: 'citron',\n"," 86: 'poire',\n"," 87: 'mangue',\n"," 88: 'fraise',\n"," 89: \"l'orange\",\n"," 90: 'gel',\n"," 91: 'pêche',\n"," 92: 'chaux',\n"," 93: 'banane',\n"," 94: 'pas',\n"," 95: 'enneigée',\n"," 96: 'favori',\n"," 97: 'déteste',\n"," 98: 'gèle',\n"," 99: 'voiture',\n"," 100: 'fruits',\n"," 101: \"l'automne\",\n"," 102: 'ils',\n"," 103: \"n'aime\",\n"," 104: 'california',\n"," 105: 'neige',\n"," 106: 'fait',\n"," 107: 'belle',\n"," 108: 'ne',\n"," 109: 'vous',\n"," 110: 'nous',\n"," 111: 'des',\n"," 112: 'animal',\n"," 113: 'cours',\n"," 114: 'camion',\n"," 115: 'neigeux',\n"," 116: 'conduit',\n"," 117: 'prochain',\n"," 118: 'je',\n"," 119: 'ce',\n"," 120: 'tranquille',\n"," 121: 'a',\n"," 122: 'cher',\n"," 123: 'une',\n"," 124: 'cette',\n"," 125: 'était',\n"," 126: 'aller',\n"," 127: 'aiment',\n"," 128: 'chaude',\n"," 129: \"n'aimez\",\n"," 130: 'aimons',\n"," 131: \"n'aiment\",\n"," 132: 'aimez',\n"," 133: 'leurs',\n"," 134: 'détestons',\n"," 135: 'sont',\n"," 136: 'rouge',\n"," 137: \"j'aime\",\n"," 138: 'jaune',\n"," 139: 'visiter',\n"," 140: 'sèche',\n"," 141: 'occupée',\n"," 142: 'frisquet',\n"," 143: 'animaux',\n"," 144: 'préférée',\n"," 145: 'dernier',\n"," 146: 'aimait',\n"," 147: 'un',\n"," 148: 'que',\n"," 149: 'conduisait',\n"," 150: 'nouvelle',\n"," 151: 'vieille',\n"," 152: 'petite',\n"," 153: 'verte',\n"," 154: 'vu',\n"," 155: 'noire',\n"," 156: 'nos',\n"," 157: 'blanche',\n"," 158: 'redouté',\n"," 159: \"n'aimait\",\n"," 160: 'brillant',\n"," 161: 'entre',\n"," 162: 'pense',\n"," 163: 'pamplemousses',\n"," 164: 'pleut',\n"," 165: 'bleue',\n"," 166: 'traduire',\n"," 167: 'nouveau',\n"," 168: 'rouillée',\n"," 169: 'bleu',\n"," 170: 'grande',\n"," 171: 'se',\n"," 172: 'rouillé',\n"," 173: 'ses',\n"," 174: \"qu'il\",\n"," 175: 'aux',\n"," 176: 'brillante',\n"," 177: 'blanc',\n"," 178: 'préférés',\n"," 179: 'noir',\n"," 180: 'étaient',\n"," 181: 'vert',\n"," 182: 'va',\n"," 183: 'envisage',\n"," 184: 'rendre',\n"," 185: 'pluies',\n"," 186: 'petit',\n"," 187: 'vieux',\n"," 188: 'chinois',\n"," 189: 'espagnol',\n"," 190: 'français',\n"," 191: 'anglais',\n"," 192: 'mes',\n"," 193: 'portugais',\n"," 194: 'mouillé',\n"," 195: 'glaciales',\n"," 196: 'traduction',\n"," 197: 'cet',\n"," 198: 'amusant',\n"," 199: 'comme',\n"," 200: 'facile',\n"," 201: 'automobile',\n"," 202: 'gros',\n"," 203: 'pourrait',\n"," 204: 'difficile',\n"," 205: 'veut',\n"," 206: 'voulait',\n"," 207: 'aimés',\n"," 208: 'pourquoi',\n"," 209: 'prévois',\n"," 210: 'souris',\n"," 211: 'prévoyons',\n"," 212: 'vos',\n"," 213: 'intention',\n"," 214: 'lapin',\n"," 215: 'ours',\n"," 216: 'clémentes',\n"," 217: 'singe',\n"," 218: 'lion',\n"," 219: 'serpent',\n"," 220: 'redoutés',\n"," 221: 'allé',\n"," 222: 'ont',\n"," 223: 'chat',\n"," 224: 'chien',\n"," 225: 'grosse',\n"," 226: 'cheval',\n"," 227: 'pluie',\n"," 228: 'requin',\n"," 229: 'trop',\n"," 230: 'monde',\n"," 231: 'maillot',\n"," 232: 'avez',\n"," 233: 'vont',\n"," 234: 'volant',\n"," 235: 'i',\n"," 236: 'allée',\n"," 237: 'allés',\n"," 238: 'veulent',\n"," 239: 'pourraient',\n"," 240: 'oiseau',\n"," 241: 'quand',\n"," 242: 'éléphant',\n"," 243: 'détendre',\n"," 244: 'aimée',\n"," 245: 'voulaient',\n"," 246: 'magnifique',\n"," 247: \"n'aimons\",\n"," 248: 'détestait',\n"," 249: \"l'automobile\",\n"," 250: 'gelé',\n"," 251: 'grand',\n"," 252: 'prévoit',\n"," 253: 'vers',\n"," 254: 'bien',\n"," 255: \"l'éléphant\",\n"," 256: 'chiens',\n"," 257: 'légère',\n"," 258: 'serpents',\n"," 259: 'lui',\n"," 260: 'comment',\n"," 261: 'cépage',\n"," 262: 'prévoient',\n"," 263: 'éléphants',\n"," 264: 'singes',\n"," 265: 'chats',\n"," 266: 'oiseaux',\n"," 267: 'requins',\n"," 268: \"l'école\",\n"," 269: 'chevaux',\n"," 270: 'visite',\n"," 271: \"l'ours\",\n"," 272: 'lions',\n"," 273: 'lapins',\n"," 274: \"l'épicerie\",\n"," 275: 'tour',\n"," 276: 'eiffel',\n"," 277: \"l'animal\",\n"," 278: 'terrain',\n"," 279: 'football',\n"," 280: 'lac',\n"," 281: \"l'oiseau\",\n"," 282: 'pensez',\n"," 283: 'allons',\n"," 284: \"n'est\",\n"," 285: 'pousse',\n"," 286: 'allez',\n"," 287: 'du',\n"," 288: 'temps',\n"," 289: 'at',\n"," 290: 'rouille',\n"," 291: 'peu',\n"," 292: 'sur',\n"," 293: \"qu'elle\",\n"," 294: 'petites',\n"," 295: 'voudrait',\n"," 296: 'êtes',\n"," 297: 'dernière',\n"," 298: 'vais',\n"," 299: 'manguiers',\n"," 300: 'frais',\n"," 301: 'détestez',\n"," 302: 'porcelaine',\n"," 303: 't',\n"," 304: 'préférées',\n"," 305: 'avons',\n"," 306: 'congélation',\n"," 307: \"c'est\",\n"," 308: 'aimeraient',\n"," 309: 'grandes',\n"," 310: 'proches',\n"," 311: 'durant',\n"," 312: 'dans',\n"," 313: 'où',\n"," 314: 'voulez',\n"," 315: 'douce',\n"," 316: 'limes',\n"," 317: \"n'a\",\n"," 318: 'plaît',\n"," 319: 'grosses',\n"," 320: 'enneigé',\n"," 321: 'envisagent',\n"," 322: 'petits',\n"," 323: 'grands',\n"," 324: 'mouillée',\n"," 325: 'tout',\n"," 326: 'conduite',\n"," 327: 'bénigne',\n"," 328: 'moindres',\n"," 329: \"n'êtes\",\n"," 330: 'redoutée',\n"," 331: 'etats',\n"," 332: 'tu',\n"," 333: 'qui',\n"," 334: 'vit',\n"," 335: 'gelés',\n"," 336: 'allions',\n"," 337: 'es',\n"," 338: 'trouvé',\n"," 339: 'ressort',\n"," 340: 'traduis',\n"," 341: 'souvent',\n"," 342: 'faire',\n"," 343: 'as',\n"," 344: 'moteur'}"],"metadata":{"id":"jHhgumOeuYme"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_st = ['the united states is sometimes chilly during december , but it is sometimes freezing in june .']\n","print('English: {}'.format(en_st))\n","\n","# Convert the English sentence to a sequence\n","en_seq = sents2seqs('source', en_st, onehot=True, reverse=True)\n","\n","# Predict probabilities of words using en_seq\n","fr_pred = model.predict(en_seq)\n","\n","# Get the sequence indices (max argument) of fr_pred\n","fr_seq = np.argmax(fr_pred, axis=-1)[0]\n","\n","# Convert the sequence of IDs to a sentence and print\n","fr_sent = [fr_id2word[i] for i in fr_seq if i != 0]\n","print(\"French (Custom): {}\".format(' '.join(fr_sent)))\n","print(\"French (Google Translate): les etats-unis sont parfois froids en décembre, mais parfois gelés en juin\")"],"metadata":{"id":"QhY_7juzuGcG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Introduction au forçage des enseignants**\n","\n","####**1. Introduction au forçage des enseignants**\n","+ ***Vous allez maintenant apprendre une technique appelée Teacher Forcing, qui est utilisée pour former des modèles de traduction automatique.***\n","\n","####**2. Le modèle de traducteur automatique précédent**\n","+ Dans le modèle précédent, l’encodeur prend une séquence de mots anglais codés onehot et produit un vecteur de contexte. \n","\n","+ Ensuite, le décodeur répète le vecteur de contexte et le consomme comme une séquence d’entrées pour produire une séquence de sorties GRU. \n","\n","+ Enfin, la couche de prédiction consomme la séquence des sorties GRU pour produire Français mots sous forme de distributions de probabilité.\n","\n","####**3. Analogie : Formation sans forcer l’enseignant**\n","+ Comprenons maintenant comment vous avez entraîné le modèle précédemment avec une analogie. \n","\n","+ Au départ, un enseignant ou l’encodeur dit à un élève qu’il doit traduire « J’aime les chats » en Français.\n","\n","####**4. Analogie : Formation sans forcer l’enseignant**\n","+ Ensuite, l’enseignant s’en va et l’élève, ou le décodeur, produit la traduction complète. \n","\n","+ Disons qu’il a produit « Je chats ».\n","\n","####**5. Analogie : Formation sans forcer l’enseignant**\n","+ Une fois que l’élève a produit la traduction complète, l’enseignant, ou les cibles du décodeur, apparaissent et disent, la traduction réelle aurait dû être « J’aime les chats », qui est utilisé pour former le modèle. Voyons maintenant comment la formation est modifiée lors de l’utilisation du forçage des enseignants.\n","\n","####**6. Analogie : Formation avec forçage de l’enseignant**\n","+ Comme précédemment, l’enseignant dira : traduisez « J’aime les chats » par Français.\n","\n","####**7. Analogie : Formation avec forçage de l’enseignant**\n","+ Ensuite, l’élève, ou le décodeur, produira un mot. \n","\n","+ Dès que l’élève produit le mot, l’enseignant vient et dit, le mot correct aurait dû être « J’aime ». \n","\n","+ Contrairement à l’exemple précédent, l’enseignant n’attend pas que l’élève produise la traduction complète, mais guide l’élève à chaque étape.\n","\n","####**8. Analogie : Formation avec Teacher Forcing**\n","+ Par conséquent, à l’étape suivante, l’étudiant pourrait en fait obtenir le mot suivant.\n","\n","####**9. Analogie : Formation avec Teacher Forcing**\n","+ Comme vous pouvez le constater, le forçage de l’enseignant aide le modèle à apprendre les choses plus rapidement car il y a plus de conseils pendant la formation et conduit à de meilleures performances.\n","\n","####**10. Le modèle de traducteur automatique précédent**\n","+ Du point de vue des modèles, lorsque le forçage de l’enseignant est utilisé, le décodeur consomme les mots Français comme entrée au lieu de consommer un vecteur de contexte répété. \n","\n","+ Les mots Français sont transmis au décodeur de sorte que, chaque position du décodeur aura un certain mot comme entrée et la cible sera le mot suivant dans la séquence. \n","\n","+ Par exemple, lorsque le mot « J’aime » est le mot d’entrée, la sortie sera « les ».\n","\n","####**11. Mise en œuvre du modèle avec le forçage des enseignants**\n","\n","+ Dans l’implémentation, l’encodeur sera identique à celui que vous avez implémenté précédemment et génère un vecteur de contexte. \n","\n","+ Le décodeur du nouveau modèle aura une nouvelle couche d’entrée. \n","\n","+ Cette couche d’entrée acceptera une séquence de mots codés en Français onehot. \n","\n","+ Notez que le calque prend en fait 1 mot de moins que la longueur totale.\n","\n","####**12. Entrées et sorties**\n","+ Comprenons cela à travers un exemple. Supposons la phrase Français « J’aime les chiens ». \n","\n","+ Les mots d’entrée seront « J’aime » et « les », où les mots de sortie correspondants seront « les » et « chiens ». \n","\n","+ Comme vous pouvez le voir, les entrées et les sorties n’auront que deux mots bien qu’il y ait trois mots Français.\n","\n","####**13. Mise en œuvre du modèle avec Teacher Forcing**\n","+ La couche de prédiction du décodeur est implémentée comme précédemment. C+ ’est-à-dire un calque dense avec fr_vocab nœuds et une activation softmax, enveloppé dans un calque TimeDistributed.\n","\n","####**14. Compilation du modèle**\n","+ Lors de la définition du modèle, il aura deux entrées: \n","  + **en_inputs et de_inputs qui seront données sous forme de liste, où la sortie sera de_pred**. \n","  \n","+ Enfin, vous compilez le modèle avec une fonction de perte, un optimiseur et une métrique.\n","\n","####**15. Prétraitement des données**\n","\n","+ Lors du prétraitement des données, les entrées du codeur seront codées à chaud et l’ordre sera inversé. \n","\n","+ Ensuite, vous obtiendrez les entrées et les sorties du décodeur à la fois et appellerez de_xy. \n","\n","+ Vous pouvez alors obtenir uniquement les entrées en utilisant deux-points moins 1 sur la dimension temporelle de de_xy, ce qui donnera tous les mots de la séquence à l’exception du dernier. \n","\n","+ Enfin, obtenez les sorties en définissant la plage comme un deux-points sur la dimension temporelle, qui retournera tous les mots sauf le premier.\n","\n","####**16. Entraînons-nous!**\n","+ Super, il est temps de mettre en pratique ce que vous avez appris."],"metadata":{"id":"KNYoongivSM-"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Définition des couches du modèle Teacher Forcing**\n","\n","+ Vous allez définir une version nouvelle et améliorée du modèle de traduction automatique que vous avez défini précédemment. \n","\n","+ Saviez-vous que des modèles tels que le Google Machine Translator utilisaient cette technique de Teacher Forcing pour former leur modèle ?\n","\n","+ Comme vous l'avez déjà vu, votre modèle précédent doit être légèrement modifié pour adopter le Teacher Forcing. \n","\n","+ Dans cet exercice, vous allez apporter les modifications nécessaires au modèle précédent. \n","\n","+ On vous a fourni les paramètres linguistiques en_len et fr_len (longueur des phrases anglaises/françaises paddées), en_vocab et fr_vocab (taille du vocabulaire des ensembles de données anglais/français) et hsize (taille de la couche cachée des couches GRU). \n","\n","+ Rappelez-vous que le décodeur acceptera une séquence française avec un élément de moins que fr_len.\n","\n","####**Instructions**\n","\n","+ Importez le sous-module layers de tensorflow.keras.\n","+ Obtenez les valeurs de sortie et d'état de l'encodeur et affectez-les respectivement à en_out et en_state.\n","+ Définissez une couche d'entrée de décodeur qui accepte une longue séquence fr_len-1 de mots français codés en onehot.\n","+ Définir une couche softmax TimeDistributed Dense avec des noeuds fr_vocab."],"metadata":{"id":"tXNQa6NqrnHW"}},{"cell_type":"code","source":["# Import the layers submodule from keras\n","import tensorflow.keras.layers as layers\n","\n","en_inputs = layers.Input(shape=(en_len, en_vocab))\n","en_gru = layers.GRU(hsize, return_state=True)\n","# Get the encoder output and state\n","en_out, en_state = en_gru(en_inputs)\n","\n","# Define the decoder input layer\n","de_inputs = layers.Input(shape=(fr_len-1, fr_vocab))\n","de_gru = layers.GRU(hsize, return_sequences=True)\n","de_out = de_gru(de_inputs, initial_state=en_state)\n","# Define a TimeDistributed Dense softmax layer with fr_vocab nodes\n","de_dense = layers.TimeDistributed(layers.Dense(fr_vocab, activation='softmax'))\n","de_pred = de_dense(de_out)"],"metadata":{"id":"TVWmTQpguGfZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Définition du modèle Teacher Forcing**\n","\n","+ Une fois toutes les couches créées, l'étape suivante consiste à définir un objet Modèle Keras. \n","\n","+ Ce modèle est légèrement différent de celui que vous avez défini précédemment, car le nouveau modèle a deux couches d'entrée.\n","\n","+ ***Les couches Keras que vous avez implémentées dans le dernier exercice vous ont été fournies, notamment en_inputs, en_gru, de_inputs, de_gru et de_pred.***\n","\n","####**Instructions**\n","\n","+ Importez l'objet Keras Model du sous-module models.\n","+ Définissez un modèle qui prend la couche d'entrée de l'encodeur et la couche d'entrée du décodeur comme entrées (dans cet ordre) et sort la prédiction finale.\n","+ Compilez le modèle en utilisant l'optimiseur adam et la fonction de perte categorical_crossentropy.\n","+ Imprimez le résumé du modèle."],"metadata":{"id":"heQs2PWHsh8U"}},{"cell_type":"code","source":["# Import the Keras Model object\n","from tensorflow.keras.models import Model\n","\n","# Define a model\n","nmt_tf = Model(inputs=[en_inputs, de_inputs], outputs=de_pred)\n","# Compile the model with optimizer and loss\n","nmt_tf.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n","# Print the summary of the model\n","nmt_tf.summary()"],"metadata":{"id":"NoTkYyhkuGjR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Prétraitement des données**\n","+ Vous devez maintenant traiter les données pour notre nouveau modèle qui a deux entrées et une seule sortie. \n","\n","+ Les deux entrées sont les mots anglais codés à un coup et les mots français codés à un coup, à l'exception du dernier mot.\n","\n","+ La sortie est constituée des mots français codés à un coup, à l'exception du premier mot. \n","\n","+ En d'autres termes, dans le décodeur, chaque mot français d'entrée a une sortie, qui est le mot suivant. Vous apprendrez ici comment mettre cela en œuvre.\n","\n","+ ***On vous a fourni la fonction sents2seqs(), en_text et fr_text.***\n","\n","####**Instructions**\n","+ Obtenez un lot d'entrées d'encodeur (de i à i+bsize) en utilisant la fonction sents2seqs() (unhot encodé et inversé).\n","+ Obtenir un lot d'entrées et de sorties de décodeur (de i à i+bsize) en utilisant la fonction sents2seqs() (codée une fois).\n","+ Séparer les entrées du décodeur (tous les mots français sauf le dernier) de de_xy en les découpant sur la dimension temporelle.\n","+ Séparer les sorties du décodeur (tous les mots français sauf le premier) de de_xy."],"metadata":{"id":"-YhGfOv_tO30"}},{"cell_type":"code","source":["bsize = 250\n","for i in range(0, len(en_text), bsize):\n","  # Get the encoder inputs using the sents2seqs() function\n","  en_x = sents2seqs('source', en_text[i:i+bsize], onehot=True, reverse=True)\n","  # Get the decoder inputs/outputs using the sents2seqs() function\n","  de_xy = sents2seqs('target', fr_text[i:i+bsize], onehot=True)\n","  # Separate the decoder inputs from de_xy\n","  de_x = de_xy[:,:-1,:]\n","  # Separate the decoder outputs from de_xy\n","  de_y = de_xy[:,1:,:]\n","  \n","  print(\"Data from \", i, \" to \", i+bsize)\n","  print(\"\\tnp.argmax() => en_x[0]: \", np.argmax(en_x[0], axis=-1))\n","  print(\"\\tnp.argmax() => de_x[0]: \", np.argmax(de_x[0], axis=-1))\n","  print(\"\\tnp.argmax() => de_y[0]: \", np.argmax(de_y[0], axis=-1))"],"metadata":{"id":"4KAAwN-gsvWm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Entraînement du modèle avec le Teacher Forcing**\n","\n","####**1. Entraînement du modèle avec le Teacher Forcing**\n","+ Apprenons maintenant comment vous pouvez entraîner le modèle que vous venez de définir.\n","\n","####**2. Modéliser la formation en détail**\n","\n","+ Vous avez brièvement vu ce qui se passe réellement dans la formation des modèles dans le chapitre précédent. \n","\n","+ Discutons-en en détail. Tout d’abord, l’apprentissage des modèles nécessite une fonction de perte et un optimiseur.\n","\n","####**3. Modéliser la formation en détail**\n","\n","+ La perte est calculée à l’aide de deux choses: \n","\n","  + ***les probabilités de prédiction générées par le modèle, qui seront une taille de lot par longueur de séquence par Français taille de vocabulaire, sortie dimensionnée, et le onehot réel encodé Français mots ou cibles qui seront de la même forme que les prédictions***. \n","  \n","+ Ensuite, dans ce modèle, ***la perte de crossentropie est calculée, ce qui mesure la différence entre les cibles et les mots prédits***. \n","\n","+ Enfin, la valeur de perte est transmise à un optimiseur comme « Adam » qui minimise cette perte en modifiant les paramètres du modèle. \n","\n","+ Les paramètres sont modifiés chaque fois que vous appelez **la fonction train_on_batch()** que vous avez vue précédemment.\n","\n","####**4. Entraînement du modèle avec le Teacher Forcing**\n","\n","+ Pendant la formation, vous parcourrez l’ensemble de données complet plusieurs fois, c’est-à-dire plusieurs époques, où à chaque époque, nous visitons toutes les données du jeu de données sous forme de lots de données. \n","\n","+ Vous pouvez obtenir le lot actuel de phrases anglaises et Français en prenant les données dans la plage « i » à « i + bsize » notée i + deux-points i+bsize. \n","\n","+ Vous encoderez onehot à la fois les mots de la langue source et de la langue cible, où vous inverserez également l’ordre des mots sources. \n","\n","+ Ensuite, vous allez générer les entrées et sorties du décodeur à partir de de_xy. \n","\n","+ Comme vous l’avez vu précédemment, les entrées du décodeur seront toutes Français mots sauf le dernier, où les cibles seront toutes Français mots sauf le premier dans les séquences. \n","\n","+ Cela se fait en découpant le tableau de_xy. Nous discuterons du découpage plus en détail sur la diapositive suivante. \n","\n","+ Ensuite, vous pouvez appeler train_on_batch avec les entrées, qui est une liste contenant en_x et de_x et les sorties, qui est de_y. \n","\n","+ Enfin, vous pouvez obtenir les métriques d’évaluation en transmettant les mêmes données à la fonction d’évaluation.\n","\n","####**5. Découpage de tableau en détail**\n","\n","+ de_xy contient tous les mots Français en tant que vecteurs onehot. \n","\n","+ de_x doit contenir tous les mots sauf le dernier. \n","\n","+ Vous pouvez le faire en découpant le tableau sur la dimension temporelle. \n","\n","+ Lorsque vous définissez la plage sur deux-points -1, il est dit, obtenez toutes les étapes de temps sauf la dernière. \n","\n","+Ensuite, vous pouvez créer de_y en définissant la plage à 1 deux-points sur la dimension temporelle, qui dit obtenir tous les pas de temps sauf le premier. \n","\n","+ Ceci est illustré dans la figure.\n","\n","####**6. Création de données de formation et de validation**\n","\n","\n","+ Vous avez déjà vu que l’utilisation d’un jeu de validation est une bonne idée et vous permet d’éviter le surajustement. \n","\n","+ ***Le surajustement est le phénomène, où la précision de l’entraînement ne cesse d’augmenter, mais la précision de validation commence à baisser***. \n","\n","+ Vous diviserez les données de sorte qu’il y aura 800 phrases de formation et 200 phrases de validation. \n","\n","+ Tout d’abord, vous allez créer une liste d’index de toutes les données et mélanger les indices de manière aléatoire. \n","\n","+ Ensuite, faites les 800 premiers indices, indices de formation et les 200 derniers, indices de validation. \n","\n","+ Le brassage permet d’éviter tout biais potentiel lors de la sélection des données. \n","\n","+ Enfin, vous pouvez utiliser la compréhension de liste pour obtenir les données en anglais et en Français correspondant aux indices d’apprentissage, et affecter les données extraites à tr_en et tr_fr respectivement. Vous faites ensuite de même avec le valid_inds et attribuez des données de validation aux v_en et aux v_fr.\n","\n","####**7. Formation avec validation**\n","+ À quoi ressemble la formation avec validation ? \n","\n","+ Vous devez d’abord faire la partie formation comme vous l’avez fait plus tôt.\n","\n","+  C’est-à-dire passer par plusieurs époques et au sein de chaque époque, plusieurs itérations. \n","\n","+ Et à chaque itération, vous entraînez le modèle sur un lot d’entrées et de sorties. \n","\n","+ Ensuite, vous appliquez les mêmes transformations que vous avez appliquées aux données d’apprentissage, au jeu de validation. \n","\n","+ Autrement dit, vous générez d’abord les représentations codées onehot des données de validation v_en_x et v_de_xy. \n","\n","+ Ensuite, vous créez v_de_x, qui contient tous les mots Français à l’exception du dernier et v_de_y, qui contient tous les mots Français à l’exception du premier. \n","\n","+ Enfin, vous utilisez v_en_x, v_de_x et v_de_y pour évaluer le modèle à chaque époque en obtenant la perte de validation et la précision de validation.\n","\n","####**8. Entraînons-nous!**\n","+ Entraînons maintenant notre modèle avec le forçage des enseignants."],"metadata":{"id":"an957Jbauj7M"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Formation du modèle**\n","+ Saviez-vous qu'en 2017, Google translate a servi plus de 500 millions d'utilisateurs par jour ?\n","\n","+ Ici, vous allez entraîner votre premier modèle Teacher Forced. \n","\n","+ Le Teacher Forcing est couramment utilisé dans les modèles de séquence à séquence comme votre traducteur automatique neuronal pour obtenir de meilleures performances.\n","\n","+ *On vous fournira la fonction sents2seqs(), des phrases anglaises en_text et des phrases françaises fr_text.*\n","\n","####**Instructions**\n","+ Obtenez l'entrée du décodeur qui contient les séquences de mots français codés en une seule fois (à l'exception du dernier mot de chaque séquence).\n","+ Obtenez la sortie du décodeur qui contient les séquences de mots français codés en une seule fois (à l'exception du premier mot de chaque séquence).\n","+ Entraîner le modèle sur un seul lot de données.\n","+ Obtenir les métriques d'évaluation (perte et précision) pour les données d'entraînement en_x, de_x et de_y."],"metadata":{"id":"EATm1RJ9wINU"}},{"cell_type":"code","source":["n_epochs, bsize = 3, 250\n","\n","for ei in range(n_epochs):\n","  for i in range(0,data_size,bsize):\n","    en_x = sents2seqs('source', en_text[i:i+bsize], onehot=True, reverse=True)\n","    de_xy = sents2seqs('target', fr_text[i:i+bsize], onehot=True)\n","    # Separate the decoder inputs from de_xy\n","    de_x = de_xy[:,:-1,:]\n","    # Separate the decoder outputs from de_xy\n","    de_y = de_xy[:,1:,:]\n","    # Train the model on a single batch of data    \n","    nmt_tf.train_on_batch([en_x,de_x], de_y)    \n","    # Obtain the eval metrics for the training data\n","    res = nmt_tf.evaluate([en_x,de_x], de_y, batch_size=bsize, verbose=0)\n","    print(\"{} => Train Loss:{}, Train Acc: {}\".format(ei+1,res[0], res[1]*100.0))  "],"metadata":{"id":"N_fYR5HSveZc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Séparation des données de formation et de validation**\n","+ Vous allez créer des ensembles de données de formation et de validation. \n","+ Garder un ensemble de données de validation et surveiller la performance du modèle sur cet ensemble est une bonne pratique pour éviter l'overfitting.\n","\n","+ *Pour cet exercice, nous vous avons fourni en_text (phrases anglaises) et fr_text (phrases françaises).*\n","\n","####**Instructions**\n","+ Définissez une séquence d'indices en utilisant np.arange(), qui commence avec 0 et a une taille de en_text.\n","+ Définissez train_inds comme le premier ensemble d'indices de taille train_s de la séquence d'indices.\n","+ Définir tr_en et tf_fr, qui contient les phrases trouvées aux indices spécifiés par train_inds dans les listes en_text et fr_text.\n","+ Définir v_en et v_fr qui contiennent les phrases trouvées aux indices spécifiés par valid_inds dans les listes en_text et fr_text."],"metadata":{"id":"mrbGLqX9wmJM"}},{"cell_type":"code","source":["train_size, valid_size = 800, 200\n","# Define a sequence of indices from 0 to size of en_text\n","inds = np.arange(len(en_text))\n","np.random.shuffle(inds)\n","# Define train_inds as first train_size indices\n","train_inds = inds[:train_size]\n","valid_inds = inds[train_size:train_size+valid_size]\n","# Define tr_en (train EN sentences) and tr_fr (train FR sentences)\n","tr_en = [en_text[ti] for ti in train_inds]\n","tr_fr = [fr_text[ti] for ti in train_inds]\n","# Define v_en (valid EN sentences) and v_fr (valid FR sentences)\n","v_en = [en_text[vi] for vi in valid_inds]\n","v_fr = [fr_text[vi] for vi in valid_inds]\n","print('Training (EN):\\n', tr_en[:3], '\\nTraining (FR):\\n', tr_fr[:3])\n","print('\\nValid (EN):\\n', v_en[:3], '\\nValid (FR):\\n', v_fr[:3])"],"metadata":{"id":"q3Jc18H2vec1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Entraînement du modèle avec validation**\n","\n","+ Ici, vous entraînerez le modèle en utilisant le forçage de l'enseignant et vous effectuerez également une étape de validation. \n","\n","+ Vous entraînerez le modèle pendant plusieurs époques et plusieurs itérations. \n","\n","+ Puis, à la fin de chaque époque, vous exécuterez l'étape de validation et obtiendrez les résultats.\n","\n","+ ***Pour cela, on vous a fourni en_text (phrases anglaises), fr_text (phrases françaises), la fonction sents2seqs() et nmt_tf (le modèle compilé). Vous avez également déjà chargé tr_en et tr_fr (données d'entraînement) et v_en et v_fr (données de validation).***\n","\n","####**Instructions**\n","+ Extrayez les entrées du décodeur (tous les mots sauf le dernier) et les sorties (tous les mots sauf le premier) de de_xy.\n","+ Entraînez le modèle sur un seul lot de données.\n","+ Créez les entrées et les sorties du décodeur à partir des données de validation de la même façon que vous l'avez fait pour les données d'entraînement.\n","+ Évaluez le modèle sur l'ensemble de données de validation pour obtenir la perte de validation et la précision."],"metadata":{"id":"ez_GrUgQw_Az"}},{"cell_type":"code","source":["for ei in range(n_epochs):\n","  for i in range(0,train_size,bsize):    \n","    en_x = sents2seqs('source', tr_en[i:i+bsize], onehot=True, reverse=True)\n","    de_xy = sents2seqs('target', tr_fr[i:i+bsize], onehot=True)\n","    # Create a single batch of decoder inputs and outputs\n","    de_x, de_y = de_xy[:,:-1,:], de_xy[:,1:,:]\n","    # Train the model on a single batch of data\n","    nmt_tf.train_on_batch([en_x, de_x], de_y)      \n","  v_en_x = sents2seqs('source', v_en, onehot=True, reverse=True)\n","  # Create a single batch of validation decoder inputs and outputs\n","  v_de_xy = sents2seqs('target', v_fr, onehot=True)\n","  v_de_x, v_de_y = v_de_xy[:,:-1,:], v_de_xy[:,1:,:]\n","  # Evaluate the trained model on the validation data\n","  res = nmt_tf.evaluate([v_en_x, v_de_x], v_de_y, batch_size=valid_size, verbose=0)\n","  print(\"{} => Loss:{}, Val Acc: {}\".format(ei+1,res[0], res[1]*100.0))"],"metadata":{"id":"7r-cwlf9vefv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Génération de traductions à partir du modèle**\n","\n","####**1. Génération de traductions à partir du modèle**\n","+ Dans cette leçon, vous apprendrez à générer des traductions à partir du modèle que vous avez formé.\n","\n","####**2. Modèle précédent vs nouveau modèle**\n","\n","+ Dans le modèle précédent, vous génériez la traduction complète immédiatement après avoir alimenté l’entrée de l’encodeur, car le décodeur ne dépendait que du vecteur de contexte, pour produire la traduction. \n","\n","+ Mais que pouvons-nous utiliser comme entrée de décodeur dans ce modèle?\n","\n","####**3. Modèle formé**\n","+ Lors de l’entraînement du modèle Teacher-Forced vous avez fourni les phrases Français au décodeur en entrées. \n","+ Quelles sont les entrées du décodeur lors de l’exécution d’une nouvelle traduction ? \n","+ Vous ne pouvez pas fournir la traduction en entrée, car c’est ce que vous voulez que le modèle génère.\n","\n","####**4. Décodeur du modèle d’inférence**\n","\n","+ Vous pouvez résoudre ce problème en construisant un décodeur récursif qui génère des prédictions pour un seul pas de temps. \n","\n","+ Tout d’abord, il prend un mot d’entrée codé onehot et un état précédent comme état initial. \n","\n","+ La couche GRU produit alors une sortie et un nouvel état. \n","\n","+ Ensuite, cette sortie GRU traverse une couche dense et produit un mot de sortie. \n","\n","+ Dans l’étape de temps suivante, la sortie et le nouvel état GRU de l’étape précédente deviennent des entrées pour le décodeur.\n","\n","####**5. Modèle d’inférence complète**\n","+ Ici, vous pouvez voir à quoi ressemble le modèle d’inférence complet par rapport au dernier modèle d’inférence que vous avez implémenté.\n","\n","####**6. Valeur des jetons SOS et EOS**\n","\n","+ Mais, que pouvez-vous alimenter comme première entrée? C’est là que le jeton « sos » brille. \n","\n","+ Comme il ne s’agit pas d’un mot réel dans la traduction et qu’il est utilisé uniquement pour marquer le début de la traduction, vous pouvez entrer « sos » comme premier mot au décodeur. \n","\n","+ Ensuite, vous générez récursivement Français mots, un à la fois. \n","\n","+ Ensuite, puisque vous avez utilisé « eos » pour marquer la fin d’une phrase, vous pouvez arrêter de générer des mots une fois que le modèle a généré « eos ». \n","\n","+ Mais par mesure de sécurité, vous devez également avoir une longueur maximale que le modèle peut choisir, au cas où le modèle ne produirait pas « eos ».\n","\n","####**7. Définition du codeur générateur**\n","\n","+ Le codeur sera identique au codeur du modèle précédent. \n","\n","+ Il a une couche d’entrée, en_inputs et une couche GRU qui renvoie le dernier état, en_state. \n","\n","+ Ensuite, vous créez un modèle qui prend en compte en_inputs et génère des en_state.\n","\n","####**8. Définition du décodeur du générateur**\n","\n","+ Dans le décodeur, vous allez d’abord définir deux couches d’entrée. \n","\n","+ La première couche d’entrée prendra un lot de mots co Français dés en un seul onehot. \n","\n","+ Mais comme la couche GRU attend une entrée de série chronologique, vous devez ajouter une dimension de longueur 1 comme première valeur à l’argument de forme. En d’autres termes, il s’agit d’une entrée de série chronologique de la longueur de séquence un. \n","\n","+ Ensuite, vous avez besoin d’une autre couche d’entrée pour alimenter l’état GRU précédent, qui sera un lot d’états masqués. \n","\n","+ Ensuite, vous définissez une couche GRU qui prend de_inputs et de_state_in comme état initial. \n","\n","+ Enfin, vous avez une couche dense qui prend la sortie GRU et produit les prédictions finales. \n","\n","+ Notez que vous n’avez pas de calque TimeDistributed puisque l’entrée est un seul mot.\n","\n","####**9. Copie des poids**\n","\n","+ L’une des étapes les plus importantes consiste à copier les poids du modèle entraîné dans le modèle d’inférence. \n","\n","+ Toutes les connaissances acquises à partir de l’entraînement sont codées dans les poids du modèle. \n","\n","+ ***Vous pouvez obtenir les poids d’une couche dans Keras à l’aide de la fonction get_weights()***. \n","\n","+ ***Vous pouvez définir les poids d’un calque avec ces poids à l’aide de la fonction set_weights()***. \n","\n","+ Vous devez le faire uniquement pour les couches qui ont des poids. \n","\n","+ Dans notre modèle de traduction automatique, il y a trois couches avec des poids ; la couche GRU du codeur, la couche GRU du décodeur et la couche dense du décodeur. \n","\n","+ Par exemple, si vous avez la couche GRU du codeur du modèle entraîné appelée tr_en_gru, vous pouvez copier les poids de cette couche dans la GRU de l’encodeur du modèle d’inférence appelée en_gru, à l’aide de cette syntaxe.\n","\n","####**10. Génération de traductions**\n","\n","\n","+ Générons maintenant une traduction. \n","\n","+ Tout d’abord, vous convertissez la phrase anglaise en une séquence codée onehot à l’aide de **la fonction sents2seqs**. \n","\n","+ N’oubliez pas d’inverser l’ordre des mots. \n","\n","+ Ensuite, vous pouvez obtenir le context_vector ou de_s_t en utilisant la fonction de prédiction sur l’encodeur. \n","\n","+ Ensuite, vous convertissez un seul jeton « sos » en une séquence codée onehot à l’aide de la fonction word2onehot. \n","\n","+ ***word2onehot est une fonction simple qui accepte un tokenizer, un mot et la taille du vocabulaire et génère une séquence codée onehot de ce mot.***\n","\n","####**11. Génération de traductions**\n","\n","+ Vous pouvez maintenant commencer à générer de manière récursive Français mots. \n","\n","+ Tout d’abord, vous définissez une variable fr_sent pour contenir la phrase complète. \n","\n","+ Ensuite, pour fr_len étapes d’une boucle, procédez comme suit. \n","\n","+ Tout d’abord, vous prédisez un mot à l’aide du décodeur. \n","\n","+ Rappelez-vous que, les entrées du décodeur sont, un mot du vocabulaire Français et de l’état précédent du décodeur. \n","\n","+ Dans la première étape, l’entrée sera « sos » et l’état d’entrée sera le vecteur de contexte de l’encodeur. \n","\n","+ Ce modèle produit ensuite un mot, sous la forme d’une distribution de probabilité et d’un nouvel état. \n","\n","+ Le nouvel état sera attribué de manière récursive à de_s_t. \n","\n","+ Cela signifie qu’à chaque pas de temps, l’état du décodeur précédent deviendra une entrée dans le modèle. \n","\n","+ Ensuite, à l’étape suivante, vous obtenez la chaîne de mots réelle en utilisant la fonction **probs2word(**). \n","\n","+ ***probs2word() est une fonction qui accepte une distribution de probabilité et un tokenizer et génère le mot Français correspondant***. \n","\n","+ ***Après cela, vous convertissez ce mot en une séquence codée onehot à l’aide de la fonction word2onehot()***. \n","\n","+ Ceci est réaffecté à de_seq qui devient une entrée du modèle à l’étape suivante. \n","\n","+ Et vous continuez à itérer ce processus jusqu’à ce que le mot de sortie soit « eos » ou, jusqu’à la fin de la boucle for.\n","\n","####**12. Il est temps de traduire!**\n","+ Génial! Générons maintenant quelques traductions."],"metadata":{"id":"yu6JMjfxxe1h"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","\n","####**Définition du décodeur du modèle d'inférence**\n","\n","+ *Le modèle d'inférence est le modèle qui sera utilisé dans la nature pour effectuer des traductions lorsque l'utilisateur le demandera.* \n","\n","+ Dans cet exercice, vous devrez implémenter le décodeur du modèle d'inférence.\n","\n","+ *Le décodeur du modèle d'inférence est différent du décodeur du modèle de formation.* \n","\n","+ Nous ne pouvons pas alimenter le décodeur avec des mots français car c'est ce que nous voulons prédire. \n","\n","+ Heureusement, il existe une solution. \n","\n","+ Nous pouvons utiliser le mot français prédit lors du pas de temps précédent pour alimenter le décodeur du modèle d'inférence. \n","\n","+ Par conséquent, lorsque vous voulez générer une traduction, le décodeur doit générer un mot à la fois, tout en consommant la sortie précédente comme entrée.\n","\n","+ *Pour cet exercice, les variables hsize (taille cachée de la couche GRU), fr_len et fr_vocab ont été importées.*\n","\n","\n","![image.png](data:image/png;base64,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)\n","\n","####**Instructions**\n","\n","+ Définissez une couche d'entrée qui accepte un lot de séquences de mots français codés en une seule fois (longueur de séquence 1).\n","\n","+ Définir une autre couche d'entrée qui accepte un lot d'état de taille h, que vous utiliserez pour alimenter l'état précédent au décodeur.\n","\n","\n","+ Obtenez la sortie et l'état du décodeur GRU.\n","\n","+ Définissez un modèle qui accepte les mots français en entrée et l'état précédent en entrée et qui sort la prédiction finale et le nouvel état du GRU."],"metadata":{"id":"2L6I6Cp4y4uV"}},{"cell_type":"code","source":["import tensorflow.keras.layers as layers\n","from tensorflow.keras.models import Model\n","# Define an input layer that accepts a single onehot encoded word\n","de_inputs = layers.Input(shape=(1, fr_vocab))\n","# Define an input to accept the t-1 state\n","de_state_in = layers.Input(shape=(hsize,))\n","de_gru = layers.GRU(hsize, return_state=True)\n","# Get the output and state from the GRU layer\n","de_out, de_state_out = de_gru(de_inputs, initial_state=de_state_in)\n","de_dense = layers.Dense(fr_vocab, activation='softmax')\n","de_pred = de_dense(de_out)\n","\n","# Define a model\n","decoder = Model(inputs=[de_inputs, de_state_in], outputs=[de_pred, de_state_out])\n","print(decoder.summary())"],"metadata":{"id":"gUkaS9husvZw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Lien entre le modèle entraîné et le modèle d'inférence**\n","+ Ici, vous allez transférer les poids formés du modèle formé au modèle d'inférence. \n","\n","+ Dans le modèle codeur-décodeur, il y a trois couches avec des paramètres. \n","\n","+ Il s'agit de ,\n","\n","  + La couche GRU de l'encodeur\n","  + La couche GRU du décodeur\n","  + La couche Dense du décodeur\n","\n","\n","+ *Les autres couches, telles que TimeDistributed, n'ont pas de paramètres et ne nécessitent donc pas la copie des poids.*\n","\n","+ *Pour cet exercice, on vous a fourni la couche GRU encodeur entraînée (tr_en_gru), la couche GRU décodeur entraînée (tr_de_gru) et la couche Dense entraînée (tr_de_dense). Vous avez également accès à toutes les couches du modèle d'inférence (y compris l'encodeur) telles que la couche GRU de l'encodeur (en_gru), la couche GRU du décodeur (de_gru) et la couche Dense (de_dense).*\n","\n","####**Instructions**\n","\n","+ Chargez les poids de la couche GRU de l'encodeur entraînée.\n","+ Définissez les poids de la couche GRU de l'encodeur du modèle d'inférence.\n","+ Charger les poids de la couche GRU du décodeur (entraînée) et définir les poids dans le modèle d'inférence.\n","+ Charger les poids de la couche Dense du décodeur (entraînée) et définir les poids dans le modèle d'inférence."],"metadata":{"id":"KrikFCuDBEwZ"}},{"cell_type":"code","source":["# Load the weights to the encoder GRU from the trained model\n","en_gru_w = tr_en_gru.get_weights()\n","# Set the weights of the encoder GRU of the inference model\n","en_gru.set_weights(en_gru_w)\n","# Load and set the weights to the decoder GRU\n","de_gru.set_weights(tr_de_gru.get_weights())\n","# Load and set the weights to the decoder Dense\n","de_dense.set_weights(tr_de_dense.get_weights())"],"metadata":{"id":"Yv82uiBVBZo2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Générer des traductions**\n","+ Vous allez maintenant générer des traductions en français à l'aide d'un modèle d'inférence entraîné avec Teacher Forcing.\n","\n","+ Ce modèle (nmt_tf) a été entraîné pendant 50 époques sur 100 000 phrases et a obtenu une précision d'environ 98 % sur un ensemble de validation de plus de 35 000 phrases. \n","\n","+ L'initialisation de cet exercice peut prendre plus de temps car le modèle entraîné doit être chargé. La fonction sents2seqs() vous est fournie. Deux nouvelles fonctions vous ont également été fournies :\n","\n","        word2onehot(tokenizer, word, vocab_size) \n","        \n","+ qui accepte :\n","\n","  + tokenizer - Un objet Keras Tokenizer\n","  + word - Une chaîne représentant un mot du vocabulaire (par exemple, 'apple').\n","  + vocab_size - La taille du vocabulaire\n","probs2word(probs, tok) qui accepte :\n","\n","  + probs - Une sortie du modèle de la forme [1,<Taille du vocabulaire français>].\n","  + tok - Un objet Tokenizer Keras\n","Vous pouvez consulter le code source de ces fonctions en tapant print(inspect. getsource(word2onehot)) et print(inspect.getsource(probs2word)) dans la console.\n","\n","####**Instructions**\n","\n","+ Prédire l'état initial du décodeur (de_s_t) avec l'encodeur.\n","+ nPrédire la sortie et le nouvel état du décodeur en utilisant la prédiction précédente (sortie) et l'état précédent comme entrées. N'oubliez pas de générer récursivement le nouvel état.\n","+ Obtenez la chaîne de mots à partir de la sortie de probabilité en utilisant la fonction probs2word().\n","+ Convertissez la chaîne de mots en une séquence à un coup en utilisant la fonction word2onehot()."],"metadata":{"id":"q-oql0N6CDVU"}},{"cell_type":"code","source":["print(inspect. getsource(word2onehot))"],"metadata":{"id":"M9INhr9QCve8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def word2onehot(tokenizer, word, vocab_size):\n","    de_seq = tokenizer.texts_to_sequences([[word]])\n","    de_onehot = to_categorical(de_seq, num_classes=vocab_size)\n","    de_onehot = np.expand_dims(de_onehot, axis=1)    \n","    return de_onehot"],"metadata":{"id":"FOWRfVAwBZxk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(inspect.getsource(probs2word))"],"metadata":{"id":"Jza4pkirCxoQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def probs2word(probs, tok):\n","    wid = np.argmax(probs[0,:], axis=-1)\n","    w = tok.index_word[wid]\n","    return w"],"metadata":{"id":"1j-QQN6-CzWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_sent = ['the united states is sometimes chilly during december , but it is sometimes freezing in june .']\n","print('English: {}'.format(en_sent))\n","en_seq = sents2seqs('source', en_sent, onehot=True, reverse=True)\n","# Predict the initial decoder state with the encoder\n","de_s_t = encoder.predict(en_seq)\n","de_seq = word2onehot(fr_tok, 'sos', fr_vocab)\n","fr_sent = ''\n","for i in range(fr_len):    \n","  # Predict from the decoder and recursively assign the new state to de_s_t\n","  de_prob, de_s_t = decoder.predict([de_seq,de_s_t])\n","  # Get the word from the probability output using probs2word\n","  de_w = probs2word(de_prob, fr_tok)\n","  # Convert the word to a onehot sequence using word2onehot\n","  de_seq = word2onehot(fr_tok, de_w, fr_vocab)\n","  if de_w == 'eos': break\n","  fr_sent += de_w + ' '\n","print(\"French (Ours): {}\".format(fr_sent))\n","print(\"French (Google Translate): les etats-unis sont parfois froids en décembre, mais parfois gelés en juin\")"],"metadata":{"id":"OyUP0HRjC3c5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Utilisation de l’incorporation de mots pour la traduction automatique**\n","\n","####**1. Utilisation de l’incorporation de mots pour la traduction automatique**\n","\n","+ Dans les exercices précédents, vous avez appris le forçage du professeur. \n","\n","+ Vous allez maintenant explorer les intégrations de mots et comment elles peuvent être utilisées dans la traduction automatique.\n","\n","####**2. Introduction à l’incorporation de mots**\n","\n","+ ***Les intégrations de mots sont parfois appelées vecteurs de mots***. L\n","\n","+ ***es vecteurs de mots sont des représentations numériques qui capturent le sens des mots***. \n","\n","+ ***Les vecteurs onehot que vous avez utilisés précédemment ne peuvent pas capturer le sens des mots***. \n","\n","+ Pour comprendre les vecteurs de mots, imaginez un supermarché. \n","\n","+ Des choses similaires, comme le saumon et le poulet, seront placées dans la section réfrigérée, où les articles de nettoyage sont placés loin de la nourriture. \n","\n","+ Les vecteurs de mots se comportent de la même manière. \n","\n","+ Par exemple, la similitude entre les vecteurs de mots « chat » et « chien » sera élevée, tandis que « chat » et « fenêtre » auront une similitude plus faible.\n","\n","####**3. Similitude entre les vecteurs de mots**\n","+ Calculons la similitude cosinus entre les vecteurs du chat, du chien et de la fenêtre. \n","\n","+ Pour ce faire, nous utiliserons une liste de vecteurs de mots publiée par le groupe NLP de Stanford, apprises à l’aide d’un très grand corpus. \n","\n","+ La similitude cosinus donne une valeur plus élevée aux vecteurs ayant une similitude d’élément plus élevée (par exemple, chat et chien), **ce qui signifie que ces mots ont une signification ou une sémantique similaire**. \n","\n","+ Par conséquent, l’utilisation de l’incorporation de mots facilite la capture par le modèle de la signification des mots, ce qui améliore les performances.\n","\n","  + https://nlp.stanford.edu/projects/glove/\n","\n","####**4. Mise en œuvre des intégrations pour l’encodeur**\n","+ Voyons comment utiliser les intégrations pour la traduction automatique.\n","\n","+  Jusqu’à présent, vous avez implémenté la couche d’entrée en tant qu’entrée 3D de la taille du lot de forme par longueur de séquence par taille de vocabulaire, où chaque mot est représenté comme un vecteur onehot.\n","\n","####**5. Mise en œuvre des intégrations pour l’encodeur**\n","+ Toutefois, lors de l’utilisation d’un calque d’incorporation, les mots sont conservés en tant qu’index de mots. \n","\n","+ Par conséquent, la couche d’entrée sera une entrée bidimensionnelle de la taille du lot par longueur de séquence, où chaque valeur représente un mot. \n","\n","+ Ces index sont transmis à une couche Keras Embedding qui apprendra les vecteurs de mots pendant la tâche de traduction.\n","\n","####**6. Mise en œuvre d’intégrations pour l’encodeur**\n","+ La couche d’incorporation convertit les index de mots en une sortie tridimensionnelle de la taille du lot par longueur de séquence par taille d’incorporation, capturée dans en_emb. \n","\n","+ ***Lors de la définition d’une couche d’incorporation, vous devez fournir trois arguments : la taille du vocabulaire, la taille d’incorporation, définie ici comme 96, et la longueur de la séquence d’entrée***. \n","\n","+ La couche d’incorporation est une matrice qui a un seul vecteur pour chaque mot du vocabulaire. \n","\n","+ Dans cet exemple, pour un vocabulaire de 100 mots, ce sera une matrice de 100 par 96.\n","\n","####**7. Mise en œuvre de l’encodeur avec intégration**\n","+ Une fois que les index de mots sont convertis en vecteurs de mots via le calque d’intégration, tout le reste de l’encodeur devient identique à ce que vous avez fait jusqu’à présent, où la sortie de la couche d’incorporation est transmise à une couche GRU.\n","\n","####**8. Mise en œuvre du décodeur avec intégration**\n","+ Les entrées du décodeur doivent être modifiées de la même manière que les entrées du codeur. \n","\n","+ Notez que vous spécifiez deux couches d’incorporation différentes pour l’encodeur et le décodeur, car il s’agit de deux langages différents et ont des tailles de vocabulaire et des longueurs de séquence différentes.\n","\n","####**9. Formation du modèle**\n","\n","+ Ce modèle utilisera à la fois l’intégration de mots et le forçage de l’enseignant. \n","\n","+ Pendant la formation, **vous traversez plusieurs époques et plusieurs itérations à chaque époque**. \n","\n","+ ***Tout d’abord, vous obtenez les entrées de l’encodeur en utilisant la fonction sents2seqs***. \n","\n","+ Assurez-vous de définir onehot est égal à False car vous avez besoin des mots IDs, pas des vecteurs onehot. \n","\n","+ Ensuite, vous obtenez également les entrées du décodeur sous la forme d’une séquence d’ID de mots. \n","\n","+ Vous pouvez ensuite créer l’entrée du décodeur en découpant le tableau de sorte que tous les ID de mots sauf le dernier soient inclus. \n","\n","+ Ici, la dimension temporelle est le dernier axe du tableau. \n","\n","+ Vous obtenez ensuite les cibles du décodeur qui seront codées onehot et ne devraient inclure que les ID de mots sauf le premier. \n","\n","+ Enfin, comme vous avez toutes les entrées et cibles requises, vous pouvez entraîner le modèle en appelant la fonction train_on_batch avec les entrées et sorties nécessaires.\n","\n","####**10. Entraînons-nous!**\n","+ Génial! Voyons l’intégration de mots en action."],"metadata":{"id":"VKzY1FdVDFPA"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Mesure de la similarité des vecteurs de mots**\n","+ Dans cette leçon, nous allons comprendre la puissance des vecteurs de mots en utilisant des vecteurs de mots entraînés dans le monde réel. \n","\n","+ Il s'agit de vecteurs de mots extraits d'une liste de vecteurs de mots publiée par le groupe NLP de Stanford(https://nlp.stanford.edu/projects/glove/). \n","\n","+ Un vecteur de mots est une séquence ou un vecteur de valeurs numériques. \n","\n","+ Par exemple, chien = (0.31, 0.92, 0.13)\n","\n","+ La distance entre les vecteurs de mots peut être mesurée en utilisant une métrique de similarité par paire. \n","\n","+ Ici, nous allons utiliser ***sklearn.metrics.pairwise.cosine_similarity***. \n","\n","+ La similarité en cosinus produit des valeurs plus élevées lorsque la similarité entre les éléments de deux vecteurs est élevée et vice-versa.\n","\n","####**Instructions**\n","\n","+ Imprimer la longueur du vecteur_chat en utilisant l'attribut ndarray.size.\n","\n","+ Calculer et imprimer la similarité entre le vecteur chat et le vecteur fenêtre en utilisant la cosinusité.\n","+ Calculer et imprimer la similarité entre le vecteur chat et le vecteur chien en utilisant la cosinusité."],"metadata":{"id":"R181I4IGFfph"}},{"cell_type":"code","source":["cat_vector = np.array([[ 0.39394888, -0.26333705,  0.08621896,  0.01091912, -0.32225883,\n","        -0.10658745, -0.25810188,  0.35068503, -0.21361879,  0.04625478,\n","         0.27992395,  0.34801784, -0.16187142, -0.52442133,  0.305441  ,\n","         0.2697149 ,  0.13099045, -0.13699648,  0.22602458,  0.4918219 ,\n","        -0.321026  ,  0.0057017 , -0.04981493, -0.02993789,  0.29878485,\n","        -0.3817054 , -0.05704023, -0.23727393,  0.08146162, -0.40114117,\n","         0.15975171,  0.23145257,  0.3185359 , -0.18709224, -0.2787781 ,\n","         0.21370722,  0.00497514,  0.04430564, -0.02908332, -0.17749819,\n","        -0.30718255, -0.25935414,  0.10115459,  0.01766969, -0.16098014,\n","         0.3519572 , -0.0734664 , -0.3723043 ,  0.37262923, -0.34300864,\n","        -0.07277397, -0.00659163,  0.23748   ,  0.13399196,  0.5749845 ,\n","         0.18539067,  0.20504089, -0.3285161 ,  0.12926023, -0.3795821 ,\n","         0.3177269 ,  0.03064232,  0.1554114 , -0.00926715,  0.02937708,\n","         0.16277929,  0.392671  ,  0.53800666, -0.45575112,  0.38556987,\n","         0.06706808, -0.3802721 ,  0.03560793, -0.46856695, -0.2644591 ,\n","        -0.14335115,  0.10971718, -0.06499432,  0.26991028, -0.32314897,\n","        -0.07378025,  0.3670569 ,  0.15895942,  0.4204117 ,  0.00254397,\n","        -0.31696656,  0.04942322,  0.1372362 ,  0.4173302 , -0.29748875,\n","        -0.0426416 ,  0.2565474 , -0.3946782 ,  0.0325617 ,  0.15673377,\n","         0.38802406]])"],"metadata":{"id":"shLyU6cRGJvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["window_vector = np.array([[ 0.13325554,  0.14915967, -0.30721307,  0.09023898, -0.14277737,\n","        -0.3429877 ,  0.6591184 ,  0.22567806,  0.50057876, -0.14418888,\n","         0.7266859 ,  0.31579646, -0.04160513,  0.21206841,  0.53187066,\n","         0.04340999, -0.2023547 , -0.28836393, -0.03026843,  0.09326456,\n","        -0.15379508,  0.41042185, -0.3575508 ,  0.33814973, -0.03736347,\n","        -0.5686376 , -0.35828388, -0.09262004, -0.04406314, -0.30181015,\n","         0.02286413,  0.30441186,  0.05470408, -0.71816754,  0.13778108,\n","        -0.16295761,  0.09613513, -0.55940634, -0.57205784, -0.7506126 ,\n","        -0.31361568,  0.13012886,  0.57220346, -0.13439907, -0.22363257,\n","         0.42024654,  0.01096254, -0.2432713 ,  0.5192242 ,  0.28016105,\n","        -0.4941133 ,  0.39157686,  0.119226  , -0.35288376,  0.05466123,\n","        -0.0957669 , -0.0585629 ,  0.20194787, -0.03544503,  0.12973273,\n","         0.12909019,  0.03881926,  0.41618073, -0.31265515,  0.40158305,\n","         0.16749044, -0.25229704, -0.18045057, -0.11000848,  0.3967997 ,\n","         0.71698666, -0.7267666 , -0.08943647, -0.90438217, -0.07253361,\n","         0.00425288,  0.12160529,  0.02097287,  0.23188019, -0.22092348,\n","        -0.07865301,  0.27505714, -0.38818485, -0.37019807,  0.3313728 ,\n","        -0.03597212,  0.12701605, -0.7077018 ,  0.7482011 ,  0.24647832,\n","        -0.46840447, -0.314954  , -0.85316503, -0.2805526 , -0.08966991,\n","         0.5265477 ]])"],"metadata":{"id":"G5UUj3XBGa_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dog_vector = np.array([[ 0.3996625 , -0.30058518,  0.04715299, -0.05910603, -0.11148381,\n","         0.1093993 ,  0.01090461,  0.23533289,  0.23022532, -0.10736388,\n","         0.27194744,  0.0234511 , -0.31267357, -0.3329223 ,  0.5383476 ,\n","         0.01967983, -0.01314637, -0.47769648,  0.21548632,  0.09172583,\n","        -0.21391751,  0.06045289, -0.33278054, -0.03726481,  0.3942353 ,\n","        -0.22838424, -0.14873335, -0.2946241 , -0.30747628,  0.01201936,\n","         0.3984858 ,  0.17620644,  0.4095585 , -0.27740127, -0.01438677,\n","        -0.12329695, -0.04173272, -0.10615015, -0.07224224, -0.48236308,\n","        -0.53165466, -0.22681382, -0.04323539,  0.36861056,  0.12315456,\n","         0.11744846,  0.10699135, -0.23141243,  0.61972225, -0.3322037 ,\n","        -0.33399817,  0.14830801,  0.5658622 , -0.11296458,  0.16682227,\n","        -0.09137795,  0.10273071, -0.25096542,  0.29488757, -0.2795514 ,\n","         0.30368486, -0.27580926, -0.14012972, -0.24056736,  0.24908563,\n","         0.14914584, -0.11725031,  0.24276581, -0.00545608,  0.45917222,\n","         0.03866611, -0.38174465, -0.36502177, -0.4143763 , -0.1863586 ,\n","        -0.45668072,  0.3324825 ,  0.12192825,  0.47594503, -0.18364649,\n","         0.42104712, -0.01100355, -0.18209179,  0.28632256, -0.00409962,\n","        -0.394309  , -0.00906276, -0.23715773,  0.3950311 , -0.5642396 ,\n","         0.42861956, -0.46919912, -0.3660173 , -0.05302884,  0.11614416,\n","         0.03718512]])"],"metadata":{"id":"IwjDFe8HGi8w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Print the length of the cat_vector\n","print('Length of the cat_vector: ', cat_vector.size)\n","\n","# Compute and print the similarity between cat and window vectors\n","dist_cat_window = cosine_similarity(cat_vector, window_vector)\n","print('Similarity(cat, window): ', dist_cat_window)\n","\n","# Compute and print the similarity between cat and dog vectors\n","print('Similarity(cat,dog): ', cosine_similarity(cat_vector, dog_vector))"],"metadata":{"id":"2fdaF5hUE4uV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Définition du modèle d'incorporation**\n","\n","+ Vous allez définir un modèle Keras qui :\n","\n","  + Utilise des couches d'incorporation\n","Sera entraîné avec Teacher Forcing\n","  + Ce modèle aura deux couches d'incorporation ; \n","    + une couche d'incorporation d'encodeur et une couche d'incorporation de décodeur. \n","    \n","+ En outre, comme le modèle est formé à l'aide du Teacher Forcing, il utilisera une longueur de séquence de fr_len-1 dans la couche d'entrée du décodeur.\n","\n","+ Pour cet exercice, vous avez importé tous les keras.layers et Model nécessaires. \n","\n","+ De plus, les variables, en_len (longueur de la séquence anglaise), fr_len (longueur de la séquence française), en_vocab (taille du vocabulaire anglais), fr_vocab (taille du vocabulaire français) et hsize (taille cachée) ont été définies.\n","\n","####**Instructions**\n","\n","+ Définir une couche d'entrée qui accepte une séquence d'identifiants de mots.\n","+ Définir une couche d'incorporation qui incorpore des mots en_vocab, a une longueur de 96 et peut accepter une séquence d'IDs (la longueur de la séquence est spécifiée en utilisant l'argument input_length).\n","+ Définir une couche d'incorporation qui incorpore des mots fr_vocab, a une longueur de 96 et peut accepter une séquence d'identifiants fr_len-1.\n","+ Définissez un modèle qui prend une entrée de l'encodeur et une entrée du décodeur (dans cet ordre) et produit les prédictions de mots."],"metadata":{"id":"H2UgoBvdGzTn"}},{"cell_type":"code","source":["# Define an input layer which accepts a sequence of word IDs\n","en_inputs = Input(shape=(en_len,))\n","# Define an Embedding layer which accepts en_inputs\n","en_emb = Embedding(en_vocab, 96, input_length=en_len)(en_inputs)\n","en_out, en_state = GRU(hsize, return_state=True)(en_emb)\n","\n","de_inputs = Input(shape=(fr_len-1,))\n","# Define an Embedding layer which accepts de_inputs\n","de_emb = Embedding(fr_vocab, 96, input_length=fr_len-1)(de_inputs)\n","de_out, _ = GRU(hsize, return_sequences=True, return_state=True)(de_emb, initial_state=en_state)\n","de_pred = TimeDistributed(Dense(fr_vocab, activation='softmax'))(de_out)\n","\n","# Define the Model which accepts encoder/decoder inputs and outputs predictions \n","nmt_emb = Model([en_inputs, de_inputs], de_pred)\n","nmt_emb.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"],"metadata":{"id":"CxCnz0gME4y7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Formation du modèle basé sur l'intégration de mots**\n","+ Vous apprendrez ici comment mettre en œuvre le processus d'entraînement d'un modèle de traducteur automatique qui utilise les encastrements de mots. \n","\n","+ Un mot est représenté par un seul nombre au lieu d'un vecteur codé à un coup comme dans les exercices précédents. Vous entraînerez le modèle pendant plusieurs époques en parcourant l'ensemble de données complet par lots.\n","\n","+ Pour cet exercice, les données d'entraînement (tr_fr et tr_en) vous sont fournies sous la forme d'une liste de phrases. Vous n'utiliserez qu'un très petit échantillon (1000 phrases) des données réelles, car sinon l'entraînement peut être très long. Vous disposez également de la fonction sents2seqs() et du modèle, nmt_emb, que vous avez implémenté dans l'exercice précédent.\n","\n","\n","####**Instructions**\n","\n","+ Obtenez un lot unique de phrases françaises sans encodage onehot en utilisant la fonction sents2seqs().\n","+ Obtenez tous les mots sauf le dernier de de_xy.\n","+ Obtenez tous les mots sauf le premier de de_xy_oh (mots français avec encodage onehot).\n","+ Entraîner le modèle en utilisant un seul lot de données"],"metadata":{"id":"8mVH3dHnHYAJ"}},{"cell_type":"code","source":["for ei in range(3):\n","  for i in range(0, train_size, bsize):    \n","    en_x = sents2seqs('source', tr_en[i:i+bsize], onehot=False, reverse=True)\n","    # Get a single batch of French sentences with no onehot encoding\n","    de_xy = sents2seqs('target', tr_fr[i:i+bsize], onehot=False)\n","    # Get all words except the last word in that batch\n","    de_x = de_xy[:,:-1]\n","    de_xy_oh = sents2seqs('target', tr_fr[i:i+bsize], onehot=True)\n","    # Get all words except the first from de_xy_oh\n","    de_y = de_xy_oh[:,1:,:]\n","    # Training the model on a single batch of data\n","    nmt_emb.train_on_batch([en_x, de_x], de_y)    \n","    res = nmt_emb.evaluate([en_x, de_x], de_y, batch_size=bsize, verbose=0)\n","    print(\"{} => Loss:{}, Train Acc: {}\".format(ei+1,res[0], res[1]*100.0))"],"metadata":{"id":"hERNT4ttHipw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QRAjouEaHi4A"},"execution_count":null,"outputs":[]}]}